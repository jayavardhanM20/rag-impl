{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adidam/rag-impl/blob/main/Real_World_RAG_Impl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uvehsMmEj1VX",
        "outputId": "1e6188b1-6fab-433d-ab33-2354345c329a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "Installing collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.12.0\n",
            "    Uninstalling fsspec-2024.12.0:\n",
            "      Successfully uninstalled fsspec-2024.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2024.9.0\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.27.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n",
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank-bm25) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.12.14)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.13 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.13)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.28)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.7.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (0.3.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (2.27.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.2.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.27.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install sentence-transformers\n",
        "!pip install rank-bm25\n",
        "!pip install torch transformers\n",
        "!pip install huggingface_hub\n",
        "!pip install langchain-community\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB2Z_NqbITiu"
      },
      "source": [
        "## **Adding the Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDgFWjrAobFl",
        "outputId": "76086e4f-dec0-4ce0-eafd-fb9c939b489f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import random_split\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElTrjfs7EHcP"
      },
      "source": [
        "## **Loading the RAGBench Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uqtM7INEMVA"
      },
      "source": [
        "## **Chunking the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "Ph7IQ753Okxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a537014f-4daf-413a-f31f-b8199de7e5f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# New code - 12/4 10 pm\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/LLM-Embedder\")\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Sliding window configuration\n",
        "TOKEN_LIMIT = 512\n",
        "SLIDING_WINDOW_OVERLAP = 100  # Overlap between consecutive chunks (in tokens)\n",
        "\n",
        "# Function for chunking with token limit and sliding window\n",
        "def chunk_with_token_limit(text, token_limit, overlap):\n",
        "    sentences = sent_tokenize(text)  # Split text into sentences\n",
        "    chunks = []  # Store resulting chunks\n",
        "    current_chunk = []  # Temporarily hold sentences for the current chunk\n",
        "    current_chunk_tokens = 0  # Token count for the current chunk\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # Tokenize the sentence and calculate its token count\n",
        "        sentence_tokens = tokenizer.tokenize(sentence)\n",
        "        num_tokens = len(sentence_tokens)\n",
        "\n",
        "        # print(f\"Tokens: {sentence_tokens[0]}\")\n",
        "\n",
        "        # If adding this sentence exceeds the token limit\n",
        "        if current_chunk_tokens + num_tokens > token_limit:\n",
        "            # Save the current chunk\n",
        "            chunk_text = \" \".join(current_chunk)\n",
        "            chunks.append(chunk_text)\n",
        "\n",
        "            # Prepare the next chunk with overlap\n",
        "            overlap_tokens = tokenizer.tokenize(\" \".join(current_chunk[-1:]))\n",
        "            current_chunk = [sentence for sentence in current_chunk[-(overlap // len(overlap_tokens)) :]] if current_chunk else []\n",
        "            current_chunk_tokens = sum(len(tokenizer.tokenize(sent)) for sent in current_chunk)\n",
        "\n",
        "        # Add the sentence to the current chunk\n",
        "        current_chunk.append(sentence)\n",
        "        current_chunk_tokens += num_tokens\n",
        "\n",
        "    # Add the last chunk if it exists\n",
        "    if current_chunk:\n",
        "        chunk_text = \" \".join(current_chunk)\n",
        "        chunks.append(chunk_text)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def process_document_with_identifiers(document):\n",
        "    processed_data = []\n",
        "    title_count = -1  # to start from 0\n",
        "    print(\"document>>>>>>>\",document)\n",
        "    for section in document:\n",
        "        section_chunks = []\n",
        "        passage_count = [ord('a')]  # Passage identifier as a list to handle nested increments\n",
        "        title_count += 1  # Increment title count\n",
        "\n",
        "        # Tokenize the section into sentences\n",
        "        sentences = sent_tokenize(section)\n",
        "        for sentence in sentences:\n",
        "            if sentence.startswith(\"Title:\"):\n",
        "                # New document detected\n",
        "                identifier = f\"{title_count}{''.join(chr(c) for c in passage_count)}\"  # Identifier for the title\n",
        "                chunked_texts = chunk_with_token_limit(sentence, TOKEN_LIMIT, SLIDING_WINDOW_OVERLAP)\n",
        "                for chunk in chunked_texts:\n",
        "                    section_chunks.append([identifier, chunk])\n",
        "                passage_count = [ord('a')]  # Reset passage count for the new document\n",
        "            else:\n",
        "                # Sentence under the current document\n",
        "                identifier = f\"{title_count}{''.join(chr(c) for c in passage_count)}\"\n",
        "                chunked_texts = chunk_with_token_limit(sentence, TOKEN_LIMIT, SLIDING_WINDOW_OVERLAP)\n",
        "                #print(\"chunked_texts>>>>process_document_with_identifiers>>>>> \"+ \"\".join(chunked_texts))\n",
        "                for chunk in chunked_texts:\n",
        "                    section_chunks.append([identifier, chunk])\n",
        "\n",
        "                # Increment passage_count intelligently\n",
        "                i = len(passage_count) - 1\n",
        "                while i >= 0:\n",
        "                    passage_count[i] += 1\n",
        "                    if passage_count[i] > ord('z'):\n",
        "                        passage_count[i] = ord('a')\n",
        "                        if i == 0:\n",
        "                            passage_count.insert(0, ord('a'))  # Add a new character to the identifier\n",
        "                        i -= 1\n",
        "                    else:\n",
        "                        break\n",
        "\n",
        "\n",
        "        print(\"section_chunks>>>>>>>\",section_chunks)\n",
        "        processed_data.append(section_chunks)\n",
        "\n",
        "    return processed_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra7a_G_8eisJ"
      },
      "source": [
        "# **Load and view first 5 rows of the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcxTIV72eisJ",
        "outputId": "436afb65-06a1-48d2-ee44-298354d993bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row 1:\n",
            "  id: techqa_TRAIN_Q337\n",
            "  question: Why does the other instance of my multi-instance qmgr seem to hang after a failover? Queue manager will not start after failover.\n",
            "  documents: ['HL083112 mqlpgrlg ZX000001 ExecCtrlrMain lpiRC_LOG_NOT_AVAILABLE mscs TECHNOTE (TROUBLESHOOTING)\\n\\nPROBLEM(ABSTRACT)\\n You attempt to failover from the primary to secondary node under MSCS. Your WebSphere MQ queue manager fails to come up on the secondary node, and errors are generated. \\n\\nSYMPTOM\\nThe sequence seen in the FDC files show:\\n\\n\\nProbe Id :- HL083112 \\nComponent :- mqlpgrlg \\nProcess Name :- D:\\\\Programs\\\\MQSeries\\\\bin\\\\amqzxma0.exe \\nMajor Errorcode :- hrcE_MQLO_UNEXPECTED_OS_ERROR \\nMQM Function Stack\\nkpiStartup\\napiStartup\\nalmPerformReDoPass\\nhlgScanLogBegin\\nmqlpgrlg\\nxcsFFST\\n\\n\\nProbe Id :- ZX000001\\nComponent :- ExecCtrlrMain \\nProcess Name :- D:\\\\Programs\\\\MQSeries\\\\bin\\\\amqzxma0.exe \\nMajor Errorcode :- xecF_E_UNEXPECTED_RC \\nMinor Errorcode :- lpiRC_LOG_NOT_AVAILABLE \\nProbe Description :- AMQ6118: An internal WebSphere MQ error has occurred \\n(7017) \\nArith1 :- 28695 7017 \\nMQM Function Stack\\nxcsFFST\\n\\n\\nCAUSE\\nThis is caused by a logger failure at restart due to missing or damaged logs.\\n\\n\\nRESOLVING THE PROBLEM\\nRename the file amqalchk.fil, which is found under mq\\\\qmgrs\\\\qmgrname\\\\ on the shared drive (to something like amqalchk.fil_OLD); then restart the queue manager.\\n\\n\\n\\nPRODUCT ALIAS/SYNONYM\\n WMQ / MQ', ' SUBSCRIBE TO THIS APAR\\nBy subscribing, you receive periodic emails alerting you to the status of the APAR, along with a link to the fix after it becomes available. You can track this item individually or track all items by product.\\n\\nNotify me when this APAR changes.\\n\\nNotify me when an APAR for this component changes.\\n\\n\\n\\nAPAR STATUS\\n * CLOSED AS PROGRAM ERROR.\\n    \\n   \\n   \\n\\nERROR DESCRIPTION\\n *  If the return value from onstat is used to determine when\\n   applications can be started in a hardware failover, the\\n   applications can be started prior to the engine allowing\\n   connections if ER needs to sync at start up.  In this case ,the\\n   application may hang requiring manual intervention in what\\n   should be an automated process which will cause a greater amount\\n   of downtime.  If the mode is not set until after ER has finished\\n   syncing and connections are accepted or a new return value is\\n   used to indicate that the instance is on-line and accepting\\n   connections this would resolve the problem.\\n   \\n   \\n    \\n   \\n   \\n\\nLOCAL FIX\\n *  Use onstat -g ntd , grep for sqlexec client type and when the\\n   next column is \"yes\" the instance will be ready to accept\\n   connections.\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM SUMMARY\\n *  ****************************************************************\\n   * USERS AFFECTED:                                              *\\n   * Users with an HDR pair that is an ER participant             *\\n   ****************************************************************\\n   * PROBLEM DESCRIPTION:                                         *\\n   * After failover, the primary shows online mode but the        *\\n   * clients are not able to connect to the server.               *\\n   ****************************************************************\\n   * RECOMMENDATION:                                              *\\n   * Upgrade to 11.50.xC7 and above.                              *\\n   ****************************************************************\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM CONCLUSION\\n *  Problem is first fixed in 11.50.xC7\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n\\nCOMMENTS\\n\\nAPAR INFORMATION\\n * APAR NUMBER\\n   IC64588\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   IBM IDS ENTRP E\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5724L2304\\n   \\n   \\n * REPORTED RELEASE\\n   B15\\n   \\n   \\n * STATUS\\n   CLOSED PER\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   NoHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt\\n   \\n   \\n * SUBMITTED DATE\\n   2009-11-16\\n   \\n   \\n * CLOSED DATE\\n   2010-10-01\\n   \\n   \\n * LAST MODIFIED DATE\\n   2010-10-01\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n\\nFIX INFORMATION\\n * FIXED COMPONENT NAME\\n   IBM IDS ENTRP E\\n   \\n   \\n * FIXED COMPONENT ID\\n   5724L2304\\n   \\n   \\n\\nAPPLICABLE COMPONENT LEVELS\\n * RB15 PSY\\n   UP', 'z/os  A FIX IS AVAILABLE\\nObtain the fix for this APAR.\\n\\n\\nSUBSCRIBE\\nYou can track all active APARs for this component.\\n\\n\\n\\nAPAR STATUS\\n * CLOSED AS UNREPRODUCIBLE IN NEXT RELEASE.\\n    \\n   \\n   \\n\\nERROR DESCRIPTION\\n *  Development Fixes\\n   \\n   \\n    \\n   \\n   \\n\\nLOCAL FIX\\n\\nPROBLEM SUMMARY\\n *  ****************************************************************\\n   * USERS AFFECTED:                                              *\\n   * All users of the IBM z/OS Communications Server for z/OS     *\\n   * Version 2 Release 1                                          *\\n   * E2827/K                                                      *\\n   ****************************************************************\\n   * PROBLEM DESCRIPTION:                                         *\\n   * 13245 EZBSRUTL(HIP6210 13.058)+00EE4A S0C4/00000010          *\\n   * 14704 AB/S0C4 EZBSRWCX +1D1E in TCPIP                        *\\n   * 14540 Stopped PFID(6) killed workloads running on PFID(5)    *\\n   * 14544 Symmetric links does not switch when primary PFID die  *\\n   * 13366 EZASATC2 EZASASUB PER DIRTSTOR ipsa sweden             *\\n   * 14347 FTP client connect fails when a link is available, but *\\n   * the fail over link is not correctly configured.              *\\n   * 14487 AB/S00C4 IEACSS1 +0D9A EZBRCSTG AFTER P TCPSVT2        *\\n   * 14591 ABEND S4c5 EZBSRUTL(HIP6210 13.092)+007DC6             *\\n   * S4C5/74300402                                                *\\n   * 14820 invalid mtu value on accept and confirm                *\\n   * 15149 Urgent data broken                                     *\\n   * 14037 Java readUTF() failed                                  *\\n   * 14680 error detection                                        *\\n   * 15085 remove traps for 8481 and 8552                         *\\n   ****************************************************************\\n   * RECOMMENDATION:                                              *\\n   * Apply fix.                                                   *\\n   ****************************************************************\\n   13245 A 64-bit memory region associated with buffer was freed\\n   prior to the storage being de-registered to the devices. This\\n   can cause result in an Abend in EZBSRUTL (TCP/IP stack) or a DC2\\n   Abend registered by IOS\\'\\n   14704 abend in EZBSRWCX caused by residual data in reg 15 during\\n   inline ITLOCK release which the downlevel SYSEVENT macro does\\n   not clear\\n   14540 - device outage caused stack to initiate failover. We\\n   first saw the error on a Test Link signal and, as part of\\n   failover, replayed the Test Link over the other link. When we\\n   got a test link reply over the other link we weren\\'t expecting\\n   it and failed that link also.\\n   14544 The stack processing for an INOP is incorrect. A link\\n   INOPed when the stack had an alternate. The stack is incorrectly\\n   resetting the TCP connections associated with the failed link.\\n   \\n   13366 The SNMP TCP/IP subagent was not checking whether an\\n   instance value had been specified for an SNMP Getnext request.\\n   If no instance value had been specified, the subagent to\\n   accessed low core when trying to use the instance value.\\n   14347 Timing window during link group establishment after\\n   alternate link fails due to a switch misconfiguration.\\n   14487 Abend S0C4 ocurrs when a STOP TCPIP is issued when tracing\\n   is active.\\n   14591Running short lived streaming jobs there were observed\\n   Abends during the de-activation of one or more of the links.\\n   14820 Packet trace is formatting the MTU field in all ACCEPT and\\n   CONFIRM messages. However, only for the connection that causes\\n   the link to be set up is the MTU valid. For cases where the MTU\\n   is not used packet trace should not format it.\\n   15149 The sender stopped sending data after sending urgent data\\n   because it did not recognize that the urgent data had been\\n   consumed by the receiver.\\n   14037 Code did not properly handle IOV64 structures passed from\\n   the application on send/receive calls.\\n   14680 New Function.\\n   15085 During the release, we had written several traps to catch\\n   particular problems that occur infrequently during stress runs.\\n   Those traps were implemented with defects 8481 and 8552. This\\n   defect is to remove those traps.\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM CONCLUSION\\n *  13245 Code was changed in EZBSRUTL de-register only after a\\n   DM_Act_REQ Function(DEREGISTER) has been performed for each\\n   associated link. Additionally logic was added to make sure that\\n   when the VTAM had issues with the de-registration of a buffer\\n   that it is not freed until VTAM completes \"force close\"\\n   processing for the associated link.\\n   14704 change EZBSRWCX to use out-of-line ITLOCK release instead\\n   14540 Change EZBSRUTL to not retransmit Test Link LLC signal\\n   during link failover processing. A Test Link is only meaningful\\n   over the link where it was originally sent so we should never\\n   retransmit these during failover.\\n   14544 Change EZBSRUTL to allow link failover processing to occur\\n   after an INOP.\\n   13366 The SNMP TCP/IP subagent has been changed to verify that\\n   an instance value has been specified for an SNMP Getnext\\n   request, before using the instance value.\\n   14347 Send a Delete Link LLC signal when cleaning up after an\\n   alternate link failure.\\n   14487 There is a timing window where the SRB routine to copy\\n   trace data to user storage where\\n   the trace collection buffer has been freed.\\n   14591 Changed EZBSRUTL to correctly de-register buffers from\\n   links and IOS\\'. Fixed race conditions where buffer pool\\n   expansion and link inactivation could be happening\\n   simultaneously.\\n   14820 Packet trace will now bypass formatting the MTU field if\\n   it is not set (0). Additionally,\\n   the psn field is valid only on first connection and will also be\\n   bypassed by packet\\n   trace when it is not set.\\n   15149 EZBSCINB is changed to check for urgent data being\\n   consumed when there is not data on the send queue.\\n   14037 EZBTSFWR and EZBTCFRD were updated to properly handle\\n   IOV64 structures.\\n   14680 New Function.\\n   15085 Removed 2 traps\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n\\nCOMMENTS\\n *  No additional comments.\\n   \\n   \\n    \\n   \\n   \\n\\nAPAR INFORMATION\\n * APAR NUMBER\\n   PM88813\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   TCP/IP V3 MVS\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5655HAL00\\n   \\n   \\n * REPORTED RELEASE\\n   210\\n   \\n   \\n * STATUS\\n   CLOSED UR1\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   NoHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt\\n   \\n   \\n * SUBMITTED DATE\\n   2013-05-10\\n   \\n   \\n * CLOSED DATE\\n   2013-05-31\\n   \\n   \\n * LAST MODIFIED DATE\\n   2013-08-19\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n    UK94777\\n   \\n   \\n\\nMODULES/MACROS\\n *  EZBSRWCX EZBSCINB EZBCTFME EZBSRUTL EZASAIP  EZBRCINI EZASATCP\\n   EZASAUDP EZBRCSTG EZASATC2 EZASADV  EZASAIP2 EZASASYS EZBTSFWR\\n   EZASAINT EZBTSCON EZBSRLLC EZBPTSMC EZASAICM EZASAPOR EZBTCFRD\\n   EZBIFIUM EZBIFIUT\\n   \\n   \\n    \\n   \\n   \\n\\nFIX INFORMATION\\n * FIXED COMPONENT NAME\\n   TCP/IP V3 MVS\\n   \\n   \\n * FIXED COMPONENT ID\\n   5655HAL00\\n   \\n   \\n\\nAPPLICABLE COMPONENT LEVELS\\n * R210 PSY UK94777 [HTTPS://WWW14.SOFTWARE.IBM.COM/WEBAPP/SET2/ORDERMEDIA/SHOPCART?PTFS=UK94777]\\n   UP13/06/21 P F306\\n   \\n   \\n\\nFIX IS AVAILABLE\\n * SELECT THE PTF APPROPRIATE FOR YOUR COMPONENT LEVEL. YOU WILL BE REQUIRED TO SIGN IN. DISTRIBUTION ON PHYSICAL MEDIA IS NOT AVAILABLE IN ALL COUNTRIES.', \"z/os  A FIX IS AVAILABLE\\nObtain the fix for this APAR.\\n\\n\\nSUBSCRIBE\\nYou can track all active APARs for this component.\\n\\n\\n\\nAPAR STATUS\\n * CLOSED AS PROGRAM ERROR.\\n    \\n   \\n   \\n\\nERROR DESCRIPTION\\n *  The problem is as follows:\\n   .\\n   Two queue managers (QMA and QMB) are members\\n   of a QSG and are also members of a cluster.\\n   The QSG has a shared queue (SQ1) which is defined\\n   as being in the cluster. This results in both\\n   queue managers advertising an instance of that\\n   queue to other members of the cluster.\\n   .\\n   SQ1 is then deleted. This should cause both\\n   queue managers to send an update to the cluster\\n   to notify other members that the queue manager\\n   no longer hosts an instance of that clustered\\n   queue. However, for shared queues this update\\n   does not happen (at least, not straight away).\\n   .\\n   The result of this is that the cluster cache\\n   on each qmgr has two records for the queue\\n   (one for each qmgr), but neither has an instance\\n   of the queue to put messages to.\\n   .\\n   When a message is put with a queue name\\n   SQ1 on QMA, it detects that there isn't a local\\n   queue instance, so it uses the cluster cache to\\n   resolve the location of the queue name.\\n   As no local instance exists, it selects the only\\n   other entry for the queue (QMB) and puts the\\n   message to the SYSTEM.CLUSTER.TRANSMIT.QUEUE to\\n   be sent to QMB.\\n   .\\n   When the message is sent over the channel,\\n   QMB also detects that there is no local instance\\n   of the queue, so goes to the cluster cache and\\n   determines that QMA is the only available instance.\\n   .\\n   The message loops between the two qmgrs. This\\n   causes high CPU, and if the message is persistent\\n   then it also causes the high logging volume\\n   seen by the customer.\\n   .\\n   Additional Symptom(s) Search Keyword(s):\\n   \\n   \\n    \\n   \\n   \\n\\nLOCAL FIX\\n *  Restart the QMQRs. The cache did get updated after the queue\\n   managers were restarted.\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM SUMMARY\\n *  ****************************************************************\\n   * USERS AFFECTED: All users of WebSphere MQ for z/OS Version 8 *\\n   *                 Release 0 Modification 0.                    *\\n   ****************************************************************\\n   * PROBLEM DESCRIPTION: Deleting a shared cluster queue may     *\\n   *                      result in the cluster definitions for   *\\n   *                      the shared queue remaining in the       *\\n   *                      cluster after a successful shared queue *\\n   *                      delete.                                 *\\n   ****************************************************************\\n   * RECOMMENDATION:                                              *\\n   ****************************************************************\\n   If multiple members of a QSG are also members of the same\\n   cluster, when a shared cluster queue is deleted, the cluster\\n   records for the queue may continue to exist in the cluster. This\\n   can result the cluster hosting records for queues which no\\n   longer are valid. If messages are put to one of these queues,\\n   cluster resolution will attempt to put the message to another\\n   QMGR in the cluster where the queue was previously hosted, which\\n   result in further cluster resolution and subsequent puts to\\n   other cluster QMGRs, which can result in infinite loop of\\n   cluster resolution and puts to other QMGRs. This is due to\\n   shared queue deletes not correctly broadcasting the delete of\\n   the cluster queue in this case.\\n   \\n   The looping between QMGRs can result in high CPU usage on all\\n   the QMGRs involved. If the message put was persistent, this will\\n   also result in high logging volumes. When this scenario is\\n   encountered, a cancel may be required to stop the QMGR.\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM CONCLUSION\\n *  Shared queue delete broadcast for cluster queues has been\\n   corrected to ensure cluster records are correctly deleted when a\\n   delete shared queue command is issued.\\n   000Y\\n   CSQMUQLC\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n *  *********\\n   * HIPER *\\n   *********\\n   \\n   \\n    \\n   \\n   \\n\\nCOMMENTS\\n\\nAPAR INFORMATION\\n * APAR NUMBER\\n   PI76942\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   WMQ Z/OS 8\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5655W9700\\n   \\n   \\n * REPORTED RELEASE\\n   000\\n   \\n   \\n * STATUS\\n   CLOSED PER\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   YesHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt / Xsystem\\n   \\n   \\n * SUBMITTED DATE\\n   2017-02-21\\n   \\n   \\n * CLOSED DATE\\n   2017-04-13\\n   \\n   \\n * LAST MODIFIED DATE\\n   2017-09-16\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n    PI79259 [http://www-01.ibm.com/support/docview.wss?uid=swg1PI79259] UI46399\\n   \\n   \\n\\nMODULES/MACROS\\n *  CSQMUQLC\\n   \\n   \\n    \\n   \\n   \\n\\nFIX INFORMATION\\n * FIXED COMPONENT NAME\\n   WMQ Z/OS 8\\n   \\n   \\n * FIXED COMPONENT ID\\n   5655W9700\\n   \\n   \\n\\nAPPLICABLE COMPONENT LEVELS\\n * R000 PSY UI46399 [HTTPS://WWW14.SOFTWARE.IBM.COM/WEBAPP/SET2/ORDERMEDIA/SHOPCART?PTFS=UI46399]\\n   UP17/06/06 P F706 \\n   \\n   \\n\\nFIX IS AVAILABLE\\n * SELECT THE PTF APPROPRIATE FOR YOUR COMPONENT LEVEL. YOU WILL BE REQUIRED TO SIGN IN. DISTRIBUTION ON PHYSICAL MEDIA IS NOT AVAILABLE IN ALL COUNTRIES.\", 'Performance Tuning; STERLINGNFX TECHNOTE (TROUBLESHOOTING)\\n\\nPROBLEM(ABSTRACT)\\n How do Sterling SCA/MCF/MCSF applications handle Integration Server JMS failover? \\n\\nSYMPTOM\\n\\n\\nProblem Statement: To achieve JMS failover in Integration Server configuration, so that messages do not backup in any particular queue. Problem Description: There are two JMS Servers forming a virtual cluster as in reality they are on independent machines. These servers have identical Queues, and a load balancer farms messages into either of the Queues. \\nAn Integration Server runs on each of these servers and they expect to read and process messages from both the queues, so that if any one of the queue goes down, then the JMSReceiver/Sterling service can continue to read from the other backup queue. \\nIn the service definition of the JMS Receiver component, the Provider URL is a comma-separated entry e.g. Provider URL = JMSServer1, JMSServer2 \\nRESOLVING THE PROBLEM\\n\\n\\nThe product does not support this configuration of comma-separated URLs for active-active failover.\\n\\n \\n\\n If the JMS Server is outside a cluster, the JMS Receiver Provider URL identifies one machine to which the Integration Server will connect. \\n(This configuration might work, in the sense, some threads might latch on and listen on Queue1, and some threads listen on Queue2. Once this happens, they will stay in that specific pattern/ratio for the lifetime of that Integration Server JVM. However, it is more of a lottery system than logic, the way the threads are farmed out. It therefore is not sensible to depend on this comma-separated URL logic to achieve division of labor between the threads.) \\n\\nThe CORRECT process configuration on how to achieve active-active JMS failover configuration for Integration Server is: Create a clone of the existing service. \\n\\n\\nService 1 will listen on JMSQueue1; \\nService 2 will listen on JMSQueue2. \\n\\nIf for any reason, Queue on JMSServer1 goes down, it is expected that the load balancer that feeds messages knows that Queue1 is down and to start pumping messages to Queue2. \\n\\nWith the new configuration, Service2 will now take the brunt of processing these messages at double the load.\\nTo implement the new configuration modify the existing service from\\n\\n \"JMSReceiver (1, 2) -> XSL -> api ->parse+manipulate+etc -> end,\\n\\nso that the processing part of the service is a Reusable Service (sync) \\nand \\nService 1 = JMSReceiver (1) -> Reusable SyncService -> End \\nService 2 = JMSReceiver (2) -> Reusable SyncService -> End \\n\\nWhy is failover required for Integration Server scenario? \\n\\n\\nFailover is required in an environment where two separate WAS instances (active-active, separate physical locations) exist, and WAS 1 is brought down, then the Integration services that were using the JMS destination associated with WAS 1 can use the WAS 2 JMS destination instead.\\n\\nHow, then is the failover scenario handled for Integration Servers by the Sterling SCA product?\\n\\nAn Integration Server, by nature, is always in an active-passive mode of failover. Sterling does not provide a setting or a property that can support an active-active failover mode like it does for agents. \\n\\nTo implement the failover scenario for Integration Servers, customers can duplicate the set of services that are running on their current environment and copy it over to the backup environment. Each duplicate service can point to a new queue that will receive the same messages that the original queue belonging to the original service was receiving. This will thus, result in an active-active failover scenario.\\n\\n \\n\\nWhy has Sterling not implemented Integration Server failover mechanism as for Agents through backup Provider URLs?\\n\\nIn case of Agent failover, all the active-active Agents must connect to the same JMS Queue. The JMS queue contains a unique message for each transaction that the Agent has to process. All threads of a particular Agent (across physical servers and JVMs) read off one message at a time from the queue - thus avoiding conflicting/overlapping transactions. \\n\\n\\nHence, the single point of failure in this solution is the Queue itself. If the queue fails, all instances of the agent will fail as well, with no option to handle failovers. To address this problem, Sterling provided a mechanism of assigning backup provider URLs to support failovers. \\nHowever, in the case of Integration Servers, one can pull the same message from multiple queues using duplicate services. Hence, there is a good option present to configure the failover scenario as previously described.\\n\\nWhat are the technical challenges of coming up with failover mechanism for Integration Servers similar to Agent Servers? \\n\\n\\nTechnically, one can configure Integration Servers to read off the backup provider URL in the same manner as Agent Servers. However, some inherent problems go along with it.\\nIn the case of Agent Servers, Sterling did not have a choice but to provide a fix because of the JMS queue being the single point of failure. In case of Integration services, however, one can configure multiple queues to work on incoming messages eliminating queues as a single point of failure. \\n\\nIf the change is to redirect all messages to a backup queue, then configure multiple services to receive from the same queue using individual message selectors. However, this can cause a drag on the system and result in performance issues.\\n\\nIn addition, in future Sterling would like to implement the Message Driven Beans (MDB) mechanism for pulling messages from the queues. Since this involves a third-party established standard for processing queues and the Application Server drives it, Sterling will have minimal control over it.\\n\\nHow can the customers best implement the workaround suggested by Sterling? \\n\\n\\nOne does not need to duplicate synchronous services. In this case, the Application Server will take care of the failover scenario. Apply this workaround only to mission-critical, asynchronous services since this is where the business logic will reside. \\n\\nThe best way to achieve the duplication would be abstract the services that contain complex business logic and model them as composite services within Sterling. This will make it easy for customers to get the duplication implemented since the crucial business logic will be independent of the queues narrowing down the components, which need change. Needless to state, this logic needs to be well tested before deployment.\\n\\nAre there any advantages of implementing the workaround as opposed to fixing it similar to Agent Server failover? \\n\\n\\nWith the duplication of the services workaround, customers will get an active-active failover mode as opposed to the active-passive mode when providing a backup provider URL.\\n\\n\\n\\nHISTORICAL NUMBER\\n NFX4092 \\n\\nPRODUCT ALIAS/SYNONYM\\n \\n\\nFunction Area\\n\\n\\nIntegration Server\\n\\n\\nSeverity\\n\\n\\nNormal\\n\\n\\nType\\n\\n\\nNormalFix']\n",
            "  response: The other instance of the multi-instance queue manager may be hanging after a failover because of a logger failure at restart due to missing or damaged logs. This can cause the queue manager to fail to come up on the secondary node and generate errors. To resolve this issue, it is recommended to rename the file `amqalchk.fil` found under `mq\\qmgrs\\qmgrname\\` on the shared drive to something like `amqalchk.fil_OLD` and then restart the queue manager. This action should address the logger failure and allow the queue manager to start successfully after the failover.\n",
            "  generation_model_name: gpt-3.5-turbo-0125\n",
            "  annotating_model_name: gpt-4-turbo-2024-04-09\n",
            "  dataset_name: techqa_train\n",
            "  documents_sentences: [[['0a', 'HL083112 mqlpgrlg ZX000001 ExecCtrlrMain lpiRC_LOG_NOT_AVAILABLE mscs TECHNOTE (TROUBLESHOOTING) PROBLEM(ABSTRACT)'], ['0b', ' You attempt to failover from the primary to secondary node under MSCS.'], ['0c', 'Your WebSphere MQ queue manager fails to come up on the secondary node, and errors are generated. SYMPTOM'], ['0d', 'The sequence seen in the FDC files show:'], ['0e', 'Probe Id :- HL083112'], ['0f', 'Component :- mqlpgrlg'], ['0g', 'Process Name :- D:\\\\Programs\\\\MQSeries\\\\bin\\\\amqzxma0.exe'], ['0h', 'Major Errorcode :- hrcE_MQLO_UNEXPECTED_OS_ERROR'], ['0i', 'MQM Function Stack kpiStartup apiStartup almPerformReDoPass hlgScanLogBegin mqlpgrlg xcsFFST'], ['0j', 'Probe Id :- ZX000001'], ['0k', 'Component :- ExecCtrlrMain'], ['0l', 'Process Name :- D:\\\\Programs\\\\MQSeries\\\\bin\\\\amqzxma0.exe'], ['0m', 'Major Errorcode :- xecF_E_UNEXPECTED_RC'], ['0n', 'Minor Errorcode :- lpiRC_LOG_NOT_AVAILABLE'], ['0o', 'Probe Description :- AMQ6118: An internal WebSphere MQ error has occurred (7017)'], ['0p', 'Arith1 :- 28695 7017'], ['0q', 'MQM Function Stack xcsFFST CAUSE'], ['0r', 'This is caused by a logger failure at restart due to missing or damaged logs.'], ['0s', 'RESOLVING THE PROBLEM'], ['0t', 'Rename the file amqalchk.fil, which is found under mq\\\\qmgrs\\\\qmgrname\\\\ on the shared drive (to something like amqalchk.fil_OLD); then restart the queue manager. PRODUCT ALIAS/SYNONYM'], ['0u', ' WMQ / MQ']], [['1a', ' SUBSCRIBE TO THIS APAR'], ['1b', 'By subscribing, you receive periodic emails alerting you to the status of the APAR, along with a link to the fix after it becomes available.'], ['1c', 'You can track this item individually or track all items by product.'], ['1d', 'Notify me when this APAR changes.'], ['1e', 'Notify me when an APAR for this component changes. APAR STATUS'], ['1f', ' * CLOSED AS PROGRAM ERROR. ERROR DESCRIPTION'], ['1g', ' *  If the return value from onstat is used to determine when'], ['1h', '   applications can be started in a hardware failover, the'], ['1i', '   applications can be started prior to the engine allowing'], ['1j', '   connections if ER needs to sync at start up.'], ['1k', 'In this case ,the'], ['1l', '   application may hang requiring manual intervention in what'], ['1m', '   should be an automated process which will cause a greater amount'], ['1n', '   of downtime.'], ['1o', 'If the mode is not set until after ER has finished'], ['1p', '   syncing and connections are accepted or a new return value is'], ['1q', '   used to indicate that the instance is on-line and accepting'], ['1r', '   connections this would resolve the problem. LOCAL FIX'], ['1s', ' *  Use onstat -g ntd , grep for sqlexec client type and when the'], ['1t', '   next column is \"yes\" the instance will be ready to accept'], ['1u', '   connections. PROBLEM SUMMARY'], ['1v', ' *  ****************************************************************'], ['1w', '   * USERS AFFECTED:                                              *'], ['1x', '   * Users with an HDR pair that is an ER participant             *'], ['1y', '   ****************************************************************'], ['1z', '   * PROBLEM DESCRIPTION:                                         *'], ['1aa', '   * After failover, the primary shows online mode but the        *'], ['1ab', '   * clients are not able to connect to the server. *'], ['1ac', '   ****************************************************************'], ['1ad', '   * RECOMMENDATION:                                              *'], ['1ae', '   * Upgrade to 11.50.xC7 and above. *'], ['1af', '   **************************************************************** PROBLEM CONCLUSION'], ['1ag', ' *  Problem is first fixed in 11.50.xC7 TEMPORARY FIX COMMENTS APAR INFORMATION'], ['1ah', ' * APAR NUMBER'], ['1ai', '   IC64588'], ['1aj', ' * REPORTED COMPONENT NAME'], ['1ak', '   IBM IDS ENTRP E'], ['1al', ' * REPORTED COMPONENT ID'], ['1am', '   5724L2304'], ['1an', ' * REPORTED RELEASE'], ['1ao', '   B15'], ['1ap', ' * STATUS'], ['1aq', '   CLOSED PER'], ['1ar', ' * PE'], ['1as', '   NoPE'], ['1at', ' * HIPER'], ['1au', '   NoHIPER'], ['1av', ' * SPECIAL ATTENTION'], ['1aw', '   NoSpecatt'], ['1ax', ' * SUBMITTED DATE'], ['1ay', '   2009-11-16'], ['1az', ' * CLOSED DATE'], ['1ba', '   2010-10-01'], ['1bb', ' * LAST MODIFIED DATE'], ['1bc', '   2010-10-01'], ['1bd', ' * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:'], ['1be', ' * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING: FIX INFORMATION'], ['1bf', ' * FIXED COMPONENT NAME'], ['1bg', '   IBM IDS ENTRP E'], ['1bh', ' * FIXED COMPONENT ID'], ['1bi', '   5724L2304'], ['1bj', 'APPLICABLE COMPONENT LEVELS'], ['1bk', ' * RB15 PSY'], ['1bl', '   UP']], [['2a', 'z/os  A FIX IS AVAILABLE'], ['2b', 'Obtain the fix for this APAR. SUBSCRIBE'], ['2c', 'You can track all active APARs for this component. APAR STATUS'], ['2d', ' * CLOSED AS UNREPRODUCIBLE IN NEXT RELEASE. ERROR DESCRIPTION'], ['2e', ' *  Development Fixes LOCAL FIX PROBLEM SUMMARY'], ['2f', ' *  ****************************************************************'], ['2g', '   * USERS AFFECTED:                                              *'], ['2h', '   * All users of the IBM z/OS Communications Server for z/OS     *'], ['2i', '   * Version 2 Release 1                                          *'], ['2j', '   * E2827/K                                                      *'], ['2k', '   ****************************************************************'], ['2l', '   * PROBLEM DESCRIPTION:                                         *'], ['2m', '   * 13245 EZBSRUTL(HIP6210 13.058)+00EE4A S0C4/00000010          *'], ['2n', '   * 14704 AB/S0C4 EZBSRWCX +1D1E in TCPIP                        *'], ['2o', '   * 14540 Stopped PFID(6) killed workloads running on PFID(5)    *'], ['2p', '   * 14544 Symmetric links does not switch when primary PFID die  *'], ['2q', '   * 13366 EZASATC2 EZASASUB PER DIRTSTOR ipsa sweden             *'], ['2r', '   * 14347 FTP client connect fails when a link is available, but *'], ['2s', '   * the fail over link is not correctly configured. *'], ['2t', '   * 14487 AB/S00C4 IEACSS1 +0D9A EZBRCSTG AFTER P TCPSVT2        *'], ['2u', '   * 14591 ABEND S4c5 EZBSRUTL(HIP6210 13.092)+007DC6             *'], ['2v', '   * S4C5/74300402                                                *'], ['2w', '   * 14820 invalid mtu value on accept and confirm                *'], ['2x', '   * 15149 Urgent data broken                                     *'], ['2y', '   * 14037 Java readUTF() failed                                  *'], ['2z', '   * 14680 error detection                                        *'], ['2aa', '   * 15085 remove traps for 8481 and 8552                         *'], ['2ab', '   ****************************************************************'], ['2ac', '   * RECOMMENDATION:                                              *'], ['2ad', '   * Apply fix. *'], ['2ae', '   ****************************************************************'], ['2af', '   13245 A 64-bit memory region associated with buffer was freed'], ['2ag', '   prior to the storage being de-registered to the devices. This'], ['2ah', '   can cause result in an Abend in EZBSRUTL (TCP/IP stack) or a DC2'], ['2ai', \"   Abend registered by IOS'\"], ['2aj', '   14704 abend in EZBSRWCX caused by residual data in reg 15 during'], ['2ak', '   inline ITLOCK release which the downlevel SYSEVENT macro does'], ['2al', '   not clear'], ['2am', '   14540 - device outage caused stack to initiate failover. We'], ['2an', '   first saw the error on a Test Link signal and, as part of'], ['2ao', '   failover, replayed the Test Link over the other link. When we'], ['2ap', \"   got a test link reply over the other link we weren't expecting\"], ['2aq', '   it and failed that link also.'], ['2ar', '   14544 The stack processing for an INOP is incorrect. A link'], ['2as', '   INOPed when the stack had an alternate.'], ['2at', 'The stack is incorrectly'], ['2au', '   resetting the TCP connections associated with the failed link.'], ['2av', '   13366 The SNMP TCP/IP subagent was not checking whether an'], ['2aw', '   instance value had been specified for an SNMP Getnext request.'], ['2ax', '   If no instance value had been specified, the subagent to'], ['2ay', '   accessed low core when trying to use the instance value.'], ['2az', '   14347 Timing window during link group establishment after'], ['2ba', '   alternate link fails due to a switch misconfiguration.'], ['2bb', '   14487 Abend S0C4 ocurrs when a STOP TCPIP is issued when tracing'], ['2bc', '   is active.'], ['2bd', '   14591Running short lived streaming jobs there were observed'], ['2be', '   Abends during the de-activation of one or more of the links.'], ['2bf', '   14820 Packet trace is formatting the MTU field in all ACCEPT and'], ['2bg', '   CONFIRM messages.'], ['2bh', 'However, only for the connection that causes'], ['2bi', '   the link to be set up is the MTU valid.'], ['2bj', 'For cases where the MTU'], ['2bk', '   is not used packet trace should not format it.'], ['2bl', '   15149 The sender stopped sending data after sending urgent data'], ['2bm', '   because it did not recognize that the urgent data had been'], ['2bn', '   consumed by the receiver.'], ['2bo', '   14037 Code did not properly handle IOV64 structures passed from'], ['2bp', '   the application on send/receive calls.'], ['2bq', '   14680 New Function.'], ['2br', '   15085 During the release, we had written several traps to catch'], ['2bs', '   particular problems that occur infrequently during stress runs.'], ['2bt', '   Those traps were implemented with defects 8481 and 8552. This'], ['2bu', '   defect is to remove those traps. PROBLEM CONCLUSION'], ['2bv', ' *  13245 Code was changed in EZBSRUTL de-register only after a'], ['2bw', '   DM_Act_REQ Function(DEREGISTER) has been performed for each'], ['2bx', '   associated link.'], ['2by', 'Additionally logic was added to make sure that'], ['2bz', '   when the VTAM had issues with the de-registration of a buffer'], ['2ca', '   that it is not freed until VTAM completes \"force close\"'], ['2cb', '   processing for the associated link.'], ['2cc', '   14704 change EZBSRWCX to use out-of-line ITLOCK release instead'], ['2cd', '   14540 Change EZBSRUTL to not retransmit Test Link LLC signal'], ['2ce', '   during link failover processing.'], ['2cf', 'A Test Link is only meaningful'], ['2cg', '   over the link where it was originally sent so we should never'], ['2ch', '   retransmit these during failover.'], ['2ci', '   14544 Change EZBSRUTL to allow link failover processing to occur'], ['2cj', '   after an INOP.'], ['2ck', '   13366 The SNMP TCP/IP subagent has been changed to verify that'], ['2cl', '   an instance value has been specified for an SNMP Getnext'], ['2cm', '   request, before using the instance value.'], ['2cn', '   14347 Send a Delete Link LLC signal when cleaning up after an'], ['2co', '   alternate link failure.'], ['2cp', '   14487 There is a timing window where the SRB routine to copy'], ['2cq', '   trace data to user storage where'], ['2cr', '   the trace collection buffer has been freed.'], ['2cs', '   14591 Changed EZBSRUTL to correctly de-register buffers from'], ['2ct', \"   links and IOS'.\"], ['2cu', 'Fixed race conditions where buffer pool'], ['2cv', '   expansion and link inactivation could be happening'], ['2cw', '   simultaneously.'], ['2cx', '   14820 Packet trace will now bypass formatting the MTU field if'], ['2cy', '   it is not set (0). Additionally,'], ['2cz', '   the psn field is valid only on first connection and will also be'], ['2da', '   bypassed by packet'], ['2db', '   trace when it is not set.'], ['2dc', '   15149 EZBSCINB is changed to check for urgent data being'], ['2dd', '   consumed when there is not data on the send queue.'], ['2de', '   14037 EZBTSFWR and EZBTCFRD were updated to properly handle'], ['2df', '   IOV64 structures.'], ['2dg', '   14680 New Function.'], ['2dh', '   15085 Removed 2 traps TEMPORARY FIX COMMENTS'], ['2di', ' *  No additional comments. APAR INFORMATION'], ['2dj', ' * APAR NUMBER'], ['2dk', '   PM88813'], ['2dl', ' * REPORTED COMPONENT NAME'], ['2dm', '   TCP/IP V3 MVS'], ['2dn', ' * REPORTED COMPONENT ID'], ['2do', '   5655HAL00'], ['2dp', ' * REPORTED RELEASE'], ['2dq', '   210'], ['2dr', ' * STATUS'], ['2ds', '   CLOSED UR1'], ['2dt', ' * PE'], ['2du', '   NoPE'], ['2dv', ' * HIPER'], ['2dw', '   NoHIPER'], ['2dx', ' * SPECIAL ATTENTION'], ['2dy', '   NoSpecatt'], ['2dz', ' * SUBMITTED DATE'], ['2ea', '   2013-05-10'], ['2eb', ' * CLOSED DATE'], ['2ec', '   2013-05-31'], ['2ed', ' * LAST MODIFIED DATE'], ['2ee', '   2013-08-19'], ['2ef', ' * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:'], ['2eg', ' * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:'], ['2eh', '    UK94777 MODULES/MACROS'], ['2ei', ' *  EZBSRWCX EZBSCINB EZBCTFME EZBSRUTL EZASAIP  EZBRCINI EZASATCP'], ['2ej', '   EZASAUDP EZBRCSTG EZASATC2 EZASADV  EZASAIP2 EZASASYS EZBTSFWR'], ['2ek', '   EZASAINT EZBTSCON EZBSRLLC EZBPTSMC EZASAICM EZASAPOR EZBTCFRD'], ['2el', '   EZBIFIUM EZBIFIUT FIX INFORMATION'], ['2em', ' * FIXED COMPONENT NAME'], ['2en', '   TCP/IP V3 MVS'], ['2eo', ' * FIXED COMPONENT ID'], ['2ep', '   5655HAL00'], ['2eq', 'APPLICABLE COMPONENT LEVELS'], ['2er', ' * R210 PSY UK94777 [HTTPS://WWW14.SOFTWARE.IBM.COM/WEBAPP/SET2/ORDERMEDIA/SHOPCART?PTFS=UK94777]'], ['2es', '   UP13/06/21 P F306'], ['2et', 'FIX IS AVAILABLE'], ['2eu', ' * SELECT THE PTF APPROPRIATE FOR YOUR COMPONENT LEVEL.'], ['2ev', 'YOU WILL BE REQUIRED TO SIGN IN.'], ['2ew', 'DISTRIBUTION ON PHYSICAL MEDIA IS NOT AVAILABLE IN ALL COUNTRIES.']], [['3a', 'z/os  A FIX IS AVAILABLE'], ['3b', 'Obtain the fix for this APAR. SUBSCRIBE'], ['3c', 'You can track all active APARs for this component. APAR STATUS'], ['3d', ' * CLOSED AS PROGRAM ERROR. ERROR DESCRIPTION'], ['3e', ' *  The problem is as follows:'], ['3f', '   .'], ['3g', '   Two queue managers (QMA and QMB) are members'], ['3h', '   of a QSG and are also members of a cluster.'], ['3i', '   The QSG has a shared queue (SQ1) which is defined'], ['3j', '   as being in the cluster.'], ['3k', 'This results in both'], ['3l', '   queue managers advertising an instance of that'], ['3m', '   queue to other members of the cluster.'], ['3n', '   .'], ['3o', '   SQ1 is then deleted.'], ['3p', 'This should cause both'], ['3q', '   queue managers to send an update to the cluster'], ['3r', '   to notify other members that the queue manager'], ['3s', '   no longer hosts an instance of that clustered'], ['3t', '   queue.'], ['3u', 'However, for shared queues this update'], ['3v', '   does not happen (at least, not straight away).'], ['3w', '   .'], ['3x', '   The result of this is that the cluster cache'], ['3y', '   on each qmgr has two records for the queue'], ['3z', '   (one for each qmgr), but neither has an instance'], ['3aa', '   of the queue to put messages to.'], ['3ab', '   .'], ['3ac', '   When a message is put with a queue name'], ['3ad', \"   SQ1 on QMA, it detects that there isn't a local\"], ['3ae', '   queue instance, so it uses the cluster cache to'], ['3af', '   resolve the location of the queue name.'], ['3ag', '   As no local instance exists, it selects the only'], ['3ah', '   other entry for the queue (QMB) and puts the'], ['3ai', '   message to the SYSTEM.CLUSTER.TRANSMIT.QUEUE to'], ['3aj', '   be sent to QMB.'], ['3ak', '   .'], ['3al', '   When the message is sent over the channel,'], ['3am', '   QMB also detects that there is no local instance'], ['3an', '   of the queue, so goes to the cluster cache and'], ['3ao', '   determines that QMA is the only available instance.'], ['3ap', '   .'], ['3aq', '   The message loops between the two qmgrs. This'], ['3ar', '   causes high CPU, and if the message is persistent'], ['3as', '   then it also causes the high logging volume'], ['3at', '   seen by the customer.'], ['3au', '   .'], ['3av', '   Additional Symptom(s) Search Keyword(s): LOCAL FIX'], ['3aw', ' *  Restart the QMQRs.'], ['3ax', 'The cache did get updated after the queue'], ['3ay', '   managers were restarted. PROBLEM SUMMARY'], ['3az', ' *  ****************************************************************'], ['3ba', '   * USERS AFFECTED: All users of WebSphere MQ for z/OS Version 8 *'], ['3bb', '   *                 Release 0 Modification 0. *'], ['3bc', '   ****************************************************************'], ['3bd', '   * PROBLEM DESCRIPTION: Deleting a shared cluster queue may     *'], ['3be', '   *                      result in the cluster definitions for   *'], ['3bf', '   *                      the shared queue remaining in the       *'], ['3bg', '   *                      cluster after a successful shared queue *'], ['3bh', '   *                      delete. *'], ['3bi', '   ****************************************************************'], ['3bj', '   * RECOMMENDATION:                                              *'], ['3bk', '   ****************************************************************'], ['3bl', '   If multiple members of a QSG are also members of the same'], ['3bm', '   cluster, when a shared cluster queue is deleted, the cluster'], ['3bn', '   records for the queue may continue to exist in the cluster. This'], ['3bo', '   can result the cluster hosting records for queues which no'], ['3bp', '   longer are valid.'], ['3bq', 'If messages are put to one of these queues,'], ['3br', '   cluster resolution will attempt to put the message to another'], ['3bs', '   QMGR in the cluster where the queue was previously hosted, which'], ['3bt', '   result in further cluster resolution and subsequent puts to'], ['3bu', '   other cluster QMGRs, which can result in infinite loop of'], ['3bv', '   cluster resolution and puts to other QMGRs.'], ['3bw', 'This is due to'], ['3bx', '   shared queue deletes not correctly broadcasting the delete of'], ['3by', '   the cluster queue in this case.'], ['3bz', '   The looping between QMGRs can result in high CPU usage on all'], ['3ca', '   the QMGRs involved.'], ['3cb', 'If the message put was persistent, this will'], ['3cc', '   also result in high logging volumes.'], ['3cd', 'When this scenario is'], ['3ce', '   encountered, a cancel may be required to stop the QMGR. PROBLEM CONCLUSION'], ['3cf', ' *  Shared queue delete broadcast for cluster queues has been'], ['3cg', '   corrected to ensure cluster records are correctly deleted when a'], ['3ch', '   delete shared queue command is issued.'], ['3ci', '   000Y'], ['3cj', '   CSQMUQLC TEMPORARY FIX'], ['3ck', ' *  *********'], ['3cl', '   * HIPER *'], ['3cm', '   ********* COMMENTS APAR INFORMATION'], ['3cn', ' * APAR NUMBER'], ['3co', '   PI76942'], ['3cp', ' * REPORTED COMPONENT NAME'], ['3cq', '   WMQ Z/OS 8'], ['3cr', ' * REPORTED COMPONENT ID'], ['3cs', '   5655W9700'], ['3ct', ' * REPORTED RELEASE'], ['3cu', '   000'], ['3cv', ' * STATUS'], ['3cw', '   CLOSED PER'], ['3cx', ' * PE'], ['3cy', '   NoPE'], ['3cz', ' * HIPER'], ['3da', '   YesHIPER'], ['3db', ' * SPECIAL ATTENTION'], ['3dc', '   NoSpecatt / Xsystem'], ['3dd', ' * SUBMITTED DATE'], ['3de', '   2017-02-21'], ['3df', ' * CLOSED DATE'], ['3dg', '   2017-04-13'], ['3dh', ' * LAST MODIFIED DATE'], ['3di', '   2017-09-16'], ['3dj', ' * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:'], ['3dk', ' * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:'], ['3dl', '    PI79259 [http://www-01.ibm.com/support/docview.wss?uid=swg1PI79259] UI46399 MODULES/MACROS'], ['3dm', ' *  CSQMUQLC FIX INFORMATION'], ['3dn', ' * FIXED COMPONENT NAME'], ['3do', '   WMQ Z/OS 8'], ['3dp', ' * FIXED COMPONENT ID'], ['3dq', '   5655W9700'], ['3dr', 'APPLICABLE COMPONENT LEVELS'], ['3ds', ' * R000 PSY UI46399 [HTTPS://WWW14.SOFTWARE.IBM.COM/WEBAPP/SET2/ORDERMEDIA/SHOPCART?PTFS=UI46399]'], ['3dt', '   UP17/06/06 P F706 '], ['3du', 'FIX IS AVAILABLE'], ['3dv', ' * SELECT THE PTF APPROPRIATE FOR YOUR COMPONENT LEVEL.'], ['3dw', 'YOU WILL BE REQUIRED TO SIGN IN.'], ['3dx', 'DISTRIBUTION ON PHYSICAL MEDIA IS NOT AVAILABLE IN ALL COUNTRIES.']], [['4a', 'Performance Tuning; STERLINGNFX TECHNOTE (TROUBLESHOOTING) PROBLEM(ABSTRACT)'], ['4b', ' How do Sterling SCA/MCF/MCSF applications handle Integration Server JMS failover? SYMPTOM'], ['4c', 'Problem Statement: To achieve JMS failover in Integration Server configuration, so that messages do not backup in any particular queue.'], ['4d', 'Problem Description: There are two JMS Servers forming a virtual cluster as in reality they are on independent machines.'], ['4e', 'These servers have identical Queues, and a load balancer farms messages into either of the Queues.'], ['4f', 'An Integration Server runs on each of these servers and they expect to read and process messages from both the queues, so that if any one of the queue goes down, then the JMSReceiver/Sterling service can continue to read from the other backup queue.'], ['4g', 'In the service definition of the JMS Receiver component, the Provider URL is a comma-separated entry e.g. Provider URL = JMSServer1, JMSServer2'], ['4h', 'RESOLVING THE PROBLEM'], ['4i', 'The product does not support this configuration of comma-separated URLs for active-active failover.'], ['4j', ' If the JMS Server is outside a cluster, the JMS Receiver Provider URL identifies one machine to which the Integration Server will connect.'], ['4k', '(This configuration might work, in the sense, some threads might latch on and listen on Queue1, and some threads listen on Queue2.'], ['4l', 'Once this happens, they will stay in that specific pattern/ratio for the lifetime of that Integration Server JVM.'], ['4m', 'However, it is more of a lottery system than logic, the way the threads are farmed out.'], ['4n', 'It therefore is not sensible to depend on this comma-separated URL logic to achieve division of labor between the threads.)'], ['4o', 'The CORRECT process configuration on how to achieve active-active JMS failover configuration for Integration Server is: Create a clone of the existing service.'], ['4p', 'Service 1 will listen on JMSQueue1;'], ['4q', 'Service 2 will listen on JMSQueue2.'], ['4r', 'If for any reason, Queue on JMSServer1 goes down, it is expected that the load balancer that feeds messages knows that Queue1 is down and to start pumping messages to Queue2.'], ['4s', 'With the new configuration, Service2 will now take the brunt of processing these messages at double the load.'], ['4t', 'To implement the new configuration modify the existing service from'], ['4u', ' \"JMSReceiver (1, 2) -> XSL -> api ->parse+manipulate+etc -> end,'], ['4v', 'so that the processing part of the service is a Reusable Service (sync) and'], ['4w', 'Service 1 = JMSReceiver (1) -> Reusable SyncService -> End'], ['4x', 'Service 2 = JMSReceiver (2) -> Reusable SyncService -> End'], ['4y', 'Why is failover required for Integration Server scenario?'], ['4z', 'Failover is required in an environment where two separate WAS instances (active-active, separate physical locations) exist, and WAS 1 is brought down, then the Integration services that were using the JMS destination associated with WAS 1 can use the WAS 2 JMS destination instead.'], ['4aa', 'How, then is the failover scenario handled for Integration Servers by the Sterling SCA product?'], ['4ab', 'An Integration Server, by nature, is always in an active-passive mode of failover.'], ['4ac', 'Sterling does not provide a setting or a property that can support an active-active failover mode like it does for agents.'], ['4ad', 'To implement the failover scenario for Integration Servers, customers can duplicate the set of services that are running on their current environment and copy it over to the backup environment.'], ['4ae', 'Each duplicate service can point to a new queue that will receive the same messages that the original queue belonging to the original service was receiving.'], ['4af', 'This will thus, result in an active-active failover scenario.'], ['4ag', 'Why has Sterling not implemented Integration Server failover mechanism as for Agents through backup Provider URLs?'], ['4ah', 'In case of Agent failover, all the active-active Agents must connect to the same JMS Queue.'], ['4ai', 'The JMS queue contains a unique message for each transaction that the Agent has to process.'], ['4aj', 'All threads of a particular Agent (across physical servers and JVMs) read off one message at a time from the queue - thus avoiding conflicting/overlapping transactions.'], ['4ak', 'Hence, the single point of failure in this solution is the Queue itself.'], ['4al', 'If the queue fails, all instances of the agent will fail as well, with no option to handle failovers.'], ['4am', 'To address this problem, Sterling provided a mechanism of assigning backup provider URLs to support failovers.'], ['4an', 'However, in the case of Integration Servers, one can pull the same message from multiple queues using duplicate services.'], ['4ao', 'Hence, there is a good option present to configure the failover scenario as previously described.'], ['4ap', 'What are the technical challenges of coming up with failover mechanism for Integration Servers similar to Agent Servers?'], ['4aq', 'Technically, one can configure Integration Servers to read off the backup provider URL in the same manner as Agent Servers.'], ['4ar', 'However, some inherent problems go along with it.'], ['4as', 'In the case of Agent Servers, Sterling did not have a choice but to provide a fix because of the JMS queue being the single point of failure.'], ['4at', 'In case of Integration services, however, one can configure multiple queues to work on incoming messages eliminating queues as a single point of failure.'], ['4au', 'If the change is to redirect all messages to a backup queue, then configure multiple services to receive from the same queue using individual message selectors.'], ['4av', 'However, this can cause a drag on the system and result in performance issues.'], ['4aw', 'In addition, in future Sterling would like to implement the Message Driven Beans (MDB) mechanism for pulling messages from the queues.'], ['4ax', 'Since this involves a third-party established standard for processing queues and the Application Server drives it, Sterling will have minimal control over it.'], ['4ay', 'How can the customers best implement the workaround suggested by Sterling?'], ['4az', 'One does not need to duplicate synchronous services.'], ['4ba', 'In this case, the Application Server will take care of the failover scenario.'], ['4bb', 'Apply this workaround only to mission-critical, asynchronous services since this is where the business logic will reside.'], ['4bc', 'The best way to achieve the duplication would be abstract the services that contain complex business logic and model them as composite services within Sterling.'], ['4bd', 'This will make it easy for customers to get the duplication implemented since the crucial business logic will be independent of the queues narrowing down the components, which need change.'], ['4be', 'Needless to state, this logic needs to be well tested before deployment.'], ['4bf', 'Are there any advantages of implementing the workaround as opposed to fixing it similar to Agent Server failover?'], ['4bg', 'With the duplication of the services workaround, customers will get an active-active failover mode as opposed to the active-passive mode when providing a backup provider URL. HISTORICAL NUMBER  NFX4092 PRODUCT ALIAS/SYNONYM Function Area Integration Server Severity Normal Type NormalFix']]]\n",
            "  response_sentences: [['a', 'The other instance of the multi-instance queue manager may be hanging after a failover because of a logger failure at restart due to missing or damaged logs.'], ['b', 'This can cause the queue manager to fail to come up on the secondary node and generate errors.'], ['c', 'To resolve this issue, it is recommended to rename the file `amqalchk.fil` found under `mq\\\\qmgrs\\\\qmgrname\\\\` on the shared drive to something like `amqalchk.fil_OLD` and then restart the queue manager.'], ['d', 'This action should address the logger failure and allow the queue manager to start successfully after the failover.']]\n",
            "  sentence_support_information: [{'explanation': 'This sentence is supported by Document 0, which explains that a logger failure at restart due to missing or damaged logs happens when failing over from a primary to a secondary node.', 'fully_supported': None, 'response_sentence_key': 'a', 'supporting_sentence_keys': ['0b', '0r']}, {'explanation': 'This sentence is supported as it explains the consequence of the logger failure mentioned in Document 0 where the queue manager fails to start on the secondary node.', 'fully_supported': None, 'response_sentence_key': 'b', 'supporting_sentence_keys': ['0c']}, {'explanation': 'This sentence is directly supported by Document 0, which recommends renaming a specific file to help resolve the issue.', 'fully_supported': None, 'response_sentence_key': 'c', 'supporting_sentence_keys': ['0t']}, {'explanation': 'This sentence is a general conclusion based on the action recommended in Document 0, assuming the action resolves the logger failure.', 'fully_supported': None, 'response_sentence_key': 'd', 'supporting_sentence_keys': ['general']}]\n",
            "  unsupported_response_sentence_keys: []\n",
            "  adherence_score: True\n",
            "  overall_supported_explanation: The overall response is supported by the documents. Document 0 specifically outlines problems involving queue manager failures during failover scenarios and describes a relevant solution involving the renaming of a particular file associated with these failures.\n",
            "  relevance_explanation: Document 0 contains all the relevant information for answering the question. It specifically addresses issues experienced during failover processes, mentioning specific error codes and files associated with these problems. Sentences from this document describe symptoms, causes, and resolutions regarding failures in queue manager startup on a secondary node, directly correlating to the scenario of interest. Document 1 focuses on application behaviors during failovers but doesn't match the specifics about queue managers and loggers, hence not relevant. Documents 2, 3, and 4 deal with unrelated software and systems issues and have no information related to queue managers failing after failover due to logger issues.\n",
            "  all_relevant_sentence_keys: ['0b', '0c', '0d', '0r', '0s', '0t']\n",
            "  all_utilized_sentence_keys: ['0b', '0c', '0r', '0t']\n",
            "  trulens_groundedness: None\n",
            "  trulens_context_relevance: None\n",
            "  ragas_faithfulness: None\n",
            "  ragas_context_relevance: None\n",
            "  gpt3_adherence: None\n",
            "  gpt3_context_relevance: None\n",
            "  gpt35_utilization: None\n",
            "  relevance_score: 0.01411764705882353\n",
            "  utilization_score: 0.009411764705882352\n",
            "  completeness_score: 0.6666666666666666\n",
            "\n",
            "Row 2:\n",
            "  id: techqa_TRAIN_Q430\n",
            "  question: DASH 3.1.2.1 to 3.1.3.0 taking long time DASH 3.1.2.1 to 3.1.3.0 taking long time. How to fix this?\n",
            "  documents: [' SUBSCRIBE TO THIS APAR\\nBy subscribing, you receive periodic emails alerting you to the status of the APAR, along with a link to the fix after it becomes available. You can track this item individually or track all items by product.\\n\\nNotify me when this APAR changes.\\n\\nNotify me when an APAR for this component changes.\\n\\n\\n\\nAPAR STATUS\\n * CLOSED AS PROGRAM ERROR.\\n    \\n   \\n   \\n\\nERROR DESCRIPTION\\n *  DASH menu hiding behind AEL in IE 11 Windows Server 2012 R2,\\n   Windows 2010\\n   \\n   Reproduced from DASH 3.1.1.x, DASH 3.1.2 including CP5 (WebGUI\\n   8.1 FP4). to DASH 3.1.3.0 but NOT on DASH 3.1.0.3 (WebGUI\\n   8.1.0)\\n   \\n   Per WebGUI L3, there are no changes in AEL html from 8.1 to 8.1\\n   FP4.\\n   \\n   \\n    \\n   \\n   \\n\\nLOCAL FIX\\n *  No workaround found.\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM SUMMARY\\n *  Please follow below link\\n   http://www-01.ibm.com/support/docview.wss?uid=swg22011801 [http://www-01.ibm.com/support/docview.wss?uid=swg22011801]\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM CONCLUSION\\n *  http://www-01.ibm.com/support/docview.wss?uid=swg22011801 [http://www-01.ibm.com/support/docview.wss?uid=swg22011801]\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n\\nCOMMENTS\\n\\nAPAR INFORMATION\\n * APAR NUMBER\\n   IV90226\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   JAZZ SM TIP DAS\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5724C04JD\\n   \\n   \\n * REPORTED RELEASE\\n   110\\n   \\n   \\n * STATUS\\n   CLOSED PER\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   NoHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt / Xsystem\\n   \\n   \\n * SUBMITTED DATE\\n   2016-10-26\\n   \\n   \\n * CLOSED DATE\\n   2017-12-26\\n   \\n   \\n * LAST MODIFIED DATE\\n   2017-12-26\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n\\nFIX INFORMATION\\n * FIXED COMPONENT NAME\\n   JAZZ SM TIP DAS\\n   \\n   \\n * FIXED COMPONENT ID\\n   5724C04JD\\n   \\n   \\n\\nAPPLICABLE COMPONENT LEVELS\\n * R110 PSY\\n   UP', 'jazzsm1120relnotes jazzsm1101relnotes jazzsm1102relnotes jazzsm1103relnotes jazzsm1110relnotes jazzsm1120relnotes DASH TECHNOTE (TROUBLESHOOTING)\\n\\nPROBLEM(ABSTRACT)\\n After rolling back an upgrade installation, the Dashboard Application Services Hub consolecli.sh command does not work on UNIX-based systems. \\n\\nCAUSE\\nWhen you roll back a Jazz for Service Management upgrade installation, which includes Dashboard Application Service Hub, a path variable contained in consoleSetupEnv.sh is not updated with the actual path value. \\n\\nENVIRONMENT\\nUNIX-based systems\\n\\nRESOLVING THE PROBLEM\\nThis issue will be resolved with the release of Dashboard Application Services Hub Version 3.1.2.1, which will be delivered in Jazz for Service Management 1.1.2.1. When rolling back from this release or later releases, the problem will not occur.\\n\\n\\n\\n\\nIf you roll back and then upgrade again, the problem is resolved. \\n\\nAlternatively, if you do not want to upgrade again to the new version, then to resolve the problem, do the following: \\n\\n 1. Open consoleSetupEnv.sh in a text editor. \\n 2. Locate the following line of code:\\n    TIP_HOME=@TIP_HOME@ \\n 3. Replace the @TIP_HOME@ string with the actual path to the Dashboard Application Services Hub. \\n 4. When you have completed your edits, the updated line would look similar to the following:\\n    TIP_HOME=/opt/IBM/JazzSM/ui \\n 5. Save the updated consoleSetupEnv.sh.', ' SUBSCRIBE\\nYou can track all active APARs for this component.\\n\\n\\n\\nAPAR STATUS\\n * CLOSED AS PERMANENT RESTRICTION.\\n    \\n   \\n   \\n\\nERROR DESCRIPTION\\n *  Issue on Rave Line Chart (Dash 3.1.2.1). All ascending\\n   and\\n   descending option is not working.\\n   \\n   For example\\n   \\n   \\n   Rave Line Chart released in Dash 3.1.2.1 is showing dates from\\n   18th May\\n   to 31st May then 1st and 2nd June. Client is not accepting this\\n   format when descending\\n   it should be like from 2nd June, 1st June, 31st May, 30th, May,\\n   29th May\\n   and so on.\\n   \\n   Data Model is showing descending order:\\n   \\n   \\n    \\n   \\n   \\n\\nLOCAL FIX\\n *  Change the date data type as varchar/string, which is not\\n   acceptable by all customer\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM SUMMARY\\n *  THis is the limitation with Rave feature. Also Rave is not in\\n   support.\\n   \\n   As alternative workaround is suggested in the published technote\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM CONCLUSION\\n *  Please check below technote for published technote.\\n   \\n   http://www.ibm.com/support/docview.wss?uid=swg21992959 [http://www.ibm.com/support/docview.wss?uid=swg21992959]\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n\\nCOMMENTS\\n\\nAPAR INFORMATION\\n * APAR NUMBER\\n   IV85353\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   JAZZ SM TIP DAS\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5724C04JD\\n   \\n   \\n * REPORTED RELEASE\\n   110\\n   \\n   \\n * STATUS\\n   CLOSED PRS\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   NoHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt / Xsystem\\n   \\n   \\n * SUBMITTED DATE\\n   2016-06-05\\n   \\n   \\n * CLOSED DATE\\n   2016-10-26\\n   \\n   \\n * LAST MODIFIED DATE\\n   2016-10-26\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n\\nFIX INFORMATION\\n\\nAPPLICABLE COMPONENT LEVELS', 'jazzsm1130relnotes TECHNOTE (TROUBLESHOOTING)\\n\\nPROBLEM(ABSTRACT)\\n When upgrading Jazz for Service Management to Version 1.1.3.0 using Installation Manager, the installation fails with the following error:\\n\\nCannot run program \"/space/IBM/JazzSM/ui/bin/wrapper.sh\" (in directory \"/space/IBM/JazzSM/ui/bin\"): error=13, Permission denied [/space/IBM/JazzSM/install/tip/tipWrapp\\nerInstall.xml:215] \\n\\nCAUSE\\nDuring the upgrade process the non-root user does not have the correct permissions to run the shell script. This is due to the following:\\n1. Jazz for Service Management is installed as a non-root user\\n2. Installation Manager is installed in user mode through root user\\n\\n\\nRESOLVING THE PROBLEM\\nThe upgrade must be initiated by using the attached script, which gives the non-root user (who originally installed this Jazz for Service Management instance) the correct permissions for the upgrade process. \\n\\n\\nThe script takes two mandatory arguments and one optional argument.\\n\\nUsage: ./JazzSMgrpModeUpgrade.sh \"IM_Install_Location\" \\n\"JazzSM_Install_Location [http://www.ibm.com/support/knowledgecenter/SSEKCU_1.1.3.0/com.ibm.psc.doc/ref/psc_r_pathnames.html]\"\"[Response_file_with_absolute_Path]\"\\n\\nFor example (showing default installation paths): ./JazzSMgrpModeUpgrade.sh \"/home/root/IBM/InstallManager/\" \"/opt/IBM/JazzSM/\" \"/opt/Download/dash_upgrade_rsp.xml\"\\n\\n\\nFor IM GUI mode installation, provide the 2 mandatory arguments; IM_Install_Location and JazzSM_Install_Location. \\nThis argument combination invokes Installation Manager in GUI mode and lead you through the rest of the upgrade process.\\n\\nFor IM Silent installation, provide all 3 arguments; IM_Install_Location , JazzSM_Install_Location, and Response_file_with_absolute_Path.\\nThis argument combination invokes Installation Manager in silent mode to upgrade JazzSM.\\n\\nJazzSMgrpModeUpgrade.sh [/support/docview.wss?uid=swg21985946&aid=2]JazzSMgrpModeUpgrade.sh [/support/docview.wss?uid=swg21985946&aid=1]', ' SUBSCRIBE TO THIS APAR\\nBy subscribing, you receive periodic emails alerting you to the status of the APAR, along with a link to the fix after it becomes available. You can track this item individually or track all items by product.\\n\\nNotify me when this APAR changes.\\n\\nNotify me when an APAR for this component changes.\\n\\n\\n\\nAPAR STATUS\\n * CLOSED AS PROGRAM ERROR.\\n    \\n   \\n   \\n\\nERROR DESCRIPTION\\n *  When the user creats and clones widgets in rapid succession,\\n   sometimes we get a widget with incomplete data (the \"mode\" is\\n   missing, and should typically be \"view\").\\n   \\n   \\n    \\n   \\n   \\n\\nLOCAL FIX\\n *  When the javascript widget object is created, we now check that\\n   its mode exists, and if not go ahead and create it as\\n   mode=\"view\".\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM SUMMARY\\n *  ****************************************************************\\n   * USERS AFFECTED:                                              *\\n   * All Jazz for SM users                                        *\\n   ****************************************************************\\n   * PROBLEM DESCRIPTION:                                         *\\n   * DASH widget not able to load or save                         *\\n   ****************************************************************\\n   * RECOMMENDATION:                                              *\\n   * Fixed issue by provind fix as a part of DASH 3.1.2.1         *\\n   ****************************************************************\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM CONCLUSION\\n *  Fixed issue by provind fix as a part of DASH 3.1.2.1\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n\\nCOMMENTS\\n\\nAPAR INFORMATION\\n * APAR NUMBER\\n   IV74740\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   JAZZ SM TIP DAS\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5724C04JD\\n   \\n   \\n * REPORTED RELEASE\\n   110\\n   \\n   \\n * STATUS\\n   CLOSED PER\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   NoHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt\\n   \\n   \\n * SUBMITTED DATE\\n   2015-07-01\\n   \\n   \\n * CLOSED DATE\\n   2015-08-03\\n   \\n   \\n * LAST MODIFIED DATE\\n   2015-08-03\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n\\nMODULES/MACROS\\n *  RAVE\\n   \\n   \\n    \\n   \\n   \\n\\nFIX INFORMATION\\n * FIXED COMPONENT NAME\\n   JAZZ SM TIP DAS\\n   \\n   \\n * FIXED COMPONENT ID\\n   5724C04JD\\n   \\n   \\n\\nAPPLICABLE COMPONENT LEVELS\\n * R110 PSY\\n   UP']\n",
            "  response: Based on the provided context, the issue of DASH 3.1.2.1 to 3.1.3.0 taking a long time has not been specifically addressed in the given information. However, the recommended action for resolving issues related to upgrades in general is to follow the instructions provided in the documentation, as well as any relevant technote or troubleshooting guides.\n",
            "\n",
            "In this case, it is recommended to refer to the IBM support documentation, specifically related to the upgrade process from DASH 3.1.2.1 to 3.1.3.0. Additionally, subscribing to the APAR (Authorized Program Analysis Report) for updates and fixes related to this specific version upgrade may provide further insights or solutions to the issue of the upgrade taking a long time.\n",
            "  generation_model_name: gpt-3.5-turbo-0125\n",
            "  annotating_model_name: gpt-4-turbo-2024-04-09\n",
            "  dataset_name: techqa_train\n",
            "  documents_sentences: [[['0a', ' SUBSCRIBE TO THIS APAR'], ['0b', 'By subscribing, you receive periodic emails alerting you to the status of the APAR, along with a link to the fix after it becomes available.'], ['0c', 'You can track this item individually or track all items by product.'], ['0d', 'Notify me when this APAR changes.'], ['0e', 'Notify me when an APAR for this component changes. APAR STATUS'], ['0f', ' * CLOSED AS PROGRAM ERROR. ERROR DESCRIPTION'], ['0g', ' *  DASH menu hiding behind AEL in IE 11 Windows Server 2012 R2,'], ['0h', '   Windows 2010'], ['0i', '   Reproduced from DASH 3.1.1.x, DASH 3.1.2 including CP5 (WebGUI'], ['0j', '   8.1 FP4).'], ['0k', 'to DASH 3.1.3.0 but NOT on DASH 3.1.0.3 (WebGUI'], ['0l', '   8.1.0)'], ['0m', '   Per WebGUI L3, there are no changes in AEL html from 8.1 to 8.1'], ['0n', '   FP4. LOCAL FIX'], ['0o', ' *  No workaround found. PROBLEM SUMMARY'], ['0p', ' *  Please follow below link'], ['0q', '   http://www-01.ibm.com/support/docview.wss?uid=swg22011801 [http://www-01.ibm.com/support/docview.wss?uid=swg22011801] PROBLEM CONCLUSION'], ['0r', ' *  http://www-01.ibm.com/support/docview.wss?uid=swg22011801 [http://www-01.ibm.com/support/docview.wss?uid=swg22011801] TEMPORARY FIX COMMENTS APAR INFORMATION'], ['0s', ' * APAR NUMBER'], ['0t', '   IV90226'], ['0u', ' * REPORTED COMPONENT NAME'], ['0v', '   JAZZ SM TIP DAS'], ['0w', ' * REPORTED COMPONENT ID'], ['0x', '   5724C04JD'], ['0y', ' * REPORTED RELEASE'], ['0z', '   110'], ['0aa', ' * STATUS'], ['0ab', '   CLOSED PER'], ['0ac', ' * PE'], ['0ad', '   NoPE'], ['0ae', ' * HIPER'], ['0af', '   NoHIPER'], ['0ag', ' * SPECIAL ATTENTION'], ['0ah', '   NoSpecatt / Xsystem'], ['0ai', ' * SUBMITTED DATE'], ['0aj', '   2016-10-26'], ['0ak', ' * CLOSED DATE'], ['0al', '   2017-12-26'], ['0am', ' * LAST MODIFIED DATE'], ['0an', '   2017-12-26'], ['0ao', ' * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:'], ['0ap', ' * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING: FIX INFORMATION'], ['0aq', ' * FIXED COMPONENT NAME'], ['0ar', '   JAZZ SM TIP DAS'], ['0as', ' * FIXED COMPONENT ID'], ['0at', '   5724C04JD'], ['0au', 'APPLICABLE COMPONENT LEVELS'], ['0av', ' * R110 PSY'], ['0aw', '   UP']], [['1a', 'jazzsm1120relnotes jazzsm1101relnotes jazzsm1102relnotes jazzsm1103relnotes jazzsm1110relnotes jazzsm1120relnotes DASH TECHNOTE (TROUBLESHOOTING) PROBLEM(ABSTRACT)'], ['1b', ' After rolling back an upgrade installation, the Dashboard Application Services Hub consolecli.sh command does not work on UNIX-based systems. CAUSE'], ['1c', 'When you roll back a Jazz for Service Management upgrade installation, which includes Dashboard Application Service Hub, a path variable contained in consoleSetupEnv.sh is not updated with the actual path value. ENVIRONMENT UNIX-based systems'], ['1d', 'RESOLVING THE PROBLEM'], ['1e', 'This issue will be resolved with the release of Dashboard Application Services Hub Version 3.1.2.1, which will be delivered in Jazz for Service Management 1.1.2.1.'], ['1f', 'When rolling back from this release or later releases, the problem will not occur.'], ['1g', 'If you roll back and then upgrade again, the problem is resolved.'], ['1h', 'Alternatively, if you do not want to upgrade again to the new version, then to resolve the problem, do the following:  1.'], ['1i', 'Open consoleSetupEnv.sh in a text editor.  2.'], ['1j', 'Locate the following line of code:'], ['1k', '    TIP_HOME=@TIP_HOME@  3.'], ['1l', 'Replace the @TIP_HOME@ string with the actual path to the Dashboard Application Services Hub.  4.'], ['1m', 'When you have completed your edits, the updated line would look similar to the following:'], ['1n', '    TIP_HOME=/opt/IBM/JazzSM/ui  5.'], ['1o', 'Save the updated consoleSetupEnv.sh.']], [['2a', ' SUBSCRIBE You can track all active APARs for this component. APAR STATUS'], ['2b', ' * CLOSED AS PERMANENT RESTRICTION. ERROR DESCRIPTION'], ['2c', ' *  Issue on Rave Line Chart (Dash 3.1.2.1). All ascending'], ['2d', '   and'], ['2e', '   descending option is not working.'], ['2f', '   For example'], ['2g', '   Rave Line Chart released in Dash 3.1.2.1 is showing dates from'], ['2h', '   18th May'], ['2i', '   to 31st May then 1st and 2nd June.'], ['2j', 'Client is not accepting this'], ['2k', '   format when descending'], ['2l', '   it should be like from 2nd June, 1st June, 31st May, 30th, May,'], ['2m', '   29th May'], ['2n', '   and so on.'], ['2o', '   Data Model is showing descending order: LOCAL FIX'], ['2p', ' *  Change the date data type as varchar/string, which is not'], ['2q', '   acceptable by all customer PROBLEM SUMMARY'], ['2r', ' *  THis is the limitation with Rave feature.'], ['2s', 'Also Rave is not in'], ['2t', '   support.'], ['2u', '   As alternative workaround is suggested in the published technote PROBLEM CONCLUSION'], ['2v', ' *  Please check below technote for published technote.'], ['2w', '   http://www.ibm.com/support/docview.wss?uid=swg21992959 [http://www.ibm.com/support/docview.wss?uid=swg21992959] TEMPORARY FIX COMMENTS APAR INFORMATION'], ['2x', ' * APAR NUMBER'], ['2y', '   IV85353'], ['2z', ' * REPORTED COMPONENT NAME'], ['2aa', '   JAZZ SM TIP DAS'], ['2ab', ' * REPORTED COMPONENT ID'], ['2ac', '   5724C04JD'], ['2ad', ' * REPORTED RELEASE'], ['2ae', '   110'], ['2af', ' * STATUS'], ['2ag', '   CLOSED PRS'], ['2ah', ' * PE'], ['2ai', '   NoPE'], ['2aj', ' * HIPER'], ['2ak', '   NoHIPER'], ['2al', ' * SPECIAL ATTENTION'], ['2am', '   NoSpecatt / Xsystem'], ['2an', ' * SUBMITTED DATE'], ['2ao', '   2016-06-05'], ['2ap', ' * CLOSED DATE'], ['2aq', '   2016-10-26'], ['2ar', ' * LAST MODIFIED DATE'], ['2as', '   2016-10-26'], ['2at', ' * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:'], ['2au', ' * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING: FIX INFORMATION'], ['2av', 'APPLICABLE COMPONENT LEVELS']], [['3a', 'jazzsm1130relnotes TECHNOTE (TROUBLESHOOTING) PROBLEM(ABSTRACT)'], ['3b', ' When upgrading Jazz for Service Management to Version 1.1.3.0 using Installation Manager, the installation fails with the following error:'], ['3c', 'Cannot run program \"/space/IBM/JazzSM/ui/bin/wrapper.sh\" (in directory \"/space/IBM/JazzSM/ui/bin\"): error=13, Permission denied [/space/IBM/JazzSM/install/tip/tipWrapp erInstall.xml:215] CAUSE'], ['3d', 'During the upgrade process the non-root user does not have the correct permissions to run the shell script.'], ['3e', 'This is due to the following: 1.'], ['3f', 'Jazz for Service Management is installed as a non-root user 2.'], ['3g', 'Installation Manager is installed in user mode through root user'], ['3h', 'RESOLVING THE PROBLEM'], ['3i', 'The upgrade must be initiated by using the attached script, which gives the non-root user (who originally installed this Jazz for Service Management instance) the correct permissions for the upgrade process.'], ['3j', 'The script takes two mandatory arguments and one optional argument.'], ['3k', 'Usage: ./JazzSMgrpModeUpgrade.sh \"IM_Install_Location\" \"JazzSM_Install_Location [http://www.ibm.com/support/knowledgecenter/SSEKCU_1.1.3.0/com.ibm.psc.doc/ref/psc_r_pathnames.html]\"\"[Response_file_with_absolute_Path]\"'], ['3l', 'For example (showing default installation paths): ./JazzSMgrpModeUpgrade.sh \"/home/root/IBM/InstallManager/\" \"/opt/IBM/JazzSM/\" \"/opt/Download/dash_upgrade_rsp.xml\"'], ['3m', 'For IM GUI mode installation, provide the 2 mandatory arguments; IM_Install_Location and JazzSM_Install_Location.'], ['3n', 'This argument combination invokes Installation Manager in GUI mode and lead you through the rest of the upgrade process.'], ['3o', 'For IM Silent installation, provide all 3 arguments; IM_Install_Location , JazzSM_Install_Location, and Response_file_with_absolute_Path.'], ['3p', 'This argument combination invokes Installation Manager in silent mode to upgrade JazzSM.'], ['3q', 'JazzSMgrpModeUpgrade.sh [/support/docview.wss?uid=swg21985946&aid=2]JazzSMgrpModeUpgrade.sh [/support/docview.wss?uid=swg21985946&aid=1]']], [['4a', ' SUBSCRIBE TO THIS APAR'], ['4b', 'By subscribing, you receive periodic emails alerting you to the status of the APAR, along with a link to the fix after it becomes available.'], ['4c', 'You can track this item individually or track all items by product.'], ['4d', 'Notify me when this APAR changes.'], ['4e', 'Notify me when an APAR for this component changes. APAR STATUS'], ['4f', ' * CLOSED AS PROGRAM ERROR. ERROR DESCRIPTION'], ['4g', ' *  When the user creats and clones widgets in rapid succession,'], ['4h', '   sometimes we get a widget with incomplete data (the \"mode\" is'], ['4i', '   missing, and should typically be \"view\"). LOCAL FIX'], ['4j', ' *  When the javascript widget object is created, we now check that'], ['4k', '   its mode exists, and if not go ahead and create it as'], ['4l', '   mode=\"view\". PROBLEM SUMMARY'], ['4m', ' *  ****************************************************************'], ['4n', '   * USERS AFFECTED:                                              *'], ['4o', '   * All Jazz for SM users                                        *'], ['4p', '   ****************************************************************'], ['4q', '   * PROBLEM DESCRIPTION:                                         *'], ['4r', '   * DASH widget not able to load or save                         *'], ['4s', '   ****************************************************************'], ['4t', '   * RECOMMENDATION:                                              *'], ['4u', '   * Fixed issue by provind fix as a part of DASH 3.1.2.1         *'], ['4v', '   **************************************************************** PROBLEM CONCLUSION'], ['4w', ' *  Fixed issue by provind fix as a part of DASH 3.1.2.1 TEMPORARY FIX COMMENTS APAR INFORMATION'], ['4x', ' * APAR NUMBER'], ['4y', '   IV74740'], ['4z', ' * REPORTED COMPONENT NAME'], ['4aa', '   JAZZ SM TIP DAS'], ['4ab', ' * REPORTED COMPONENT ID'], ['4ac', '   5724C04JD'], ['4ad', ' * REPORTED RELEASE'], ['4ae', '   110'], ['4af', ' * STATUS'], ['4ag', '   CLOSED PER'], ['4ah', ' * PE'], ['4ai', '   NoPE'], ['4aj', ' * HIPER'], ['4ak', '   NoHIPER'], ['4al', ' * SPECIAL ATTENTION'], ['4am', '   NoSpecatt'], ['4an', ' * SUBMITTED DATE'], ['4ao', '   2015-07-01'], ['4ap', ' * CLOSED DATE'], ['4aq', '   2015-08-03'], ['4ar', ' * LAST MODIFIED DATE'], ['4as', '   2015-08-03'], ['4at', ' * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:'], ['4au', ' * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING: MODULES/MACROS'], ['4av', ' *  RAVE FIX INFORMATION'], ['4aw', ' * FIXED COMPONENT NAME'], ['4ax', '   JAZZ SM TIP DAS'], ['4ay', ' * FIXED COMPONENT ID'], ['4az', '   5724C04JD'], ['4ba', 'APPLICABLE COMPONENT LEVELS'], ['4bb', ' * R110 PSY'], ['4bc', '   UP']]]\n",
            "  response_sentences: [['a', 'Based on the provided context, the issue of DASH 3.1.2.1 to 3.1.3.0 taking a long time has not been specifically addressed in the given information.'], ['b', 'However, the recommended action for resolving issues related to upgrades in general is to follow the instructions provided in the documentation, as well as any relevant technote or troubleshooting guides.'], ['c', 'In this case, it is recommended to refer to the IBM support documentation, specifically related to the upgrade process from DASH 3.1.2.1 to 3.1.3.0.'], ['d', 'Additionally, subscribing to the APAR (Authorized Program Analysis Report) for updates and fixes related to this specific version upgrade may provide further insights or solutions to the issue of the upgrade taking a long time.']]\n",
            "  sentence_support_information: [{'explanation': 'This sentence is not directly supported by any sentences in the documents; no document mentions the issue of long upgrade times between versions 3.1.2.1 to 3.1.3.0.', 'fully_supported': None, 'response_sentence_key': 'a', 'supporting_sentence_keys': []}, {'explanation': \"This sentence is not supported; while the documents discuss some general upgrade issues, none provide blanket 'recommended actions' for resolving upgrade issues as noted in the response.\", 'fully_supported': None, 'response_sentence_key': 'b', 'supporting_sentence_keys': []}, {'explanation': 'This sentence is not supported; there are no specific documents cited or existing in the provided text that are particularly about upgrading from DASH 3.1.2.1 to 3.1.3.0.', 'fully_supported': None, 'response_sentence_key': 'c', 'supporting_sentence_keys': []}, {'explanation': 'Though the documents include instructions about subscribing to APAR, they do not support the claim that doing so would specifically address the issue of upgrade duration between these versions.', 'fully_supported': None, 'response_sentence_key': 'd', 'supporting_sentence_keys': []}]\n",
            "  unsupported_response_sentence_keys: ['a', 'b', 'c', 'd']\n",
            "  adherence_score: False\n",
            "  overall_supported_explanation: The response is not supported by the documents because there is no mention of the issue of taking a long time between upgrades from DASH 3.1.2.1 to 3.1.3.0 or any instructions specific to this scenario. The documents discuss various other issues and general upgrade instructions, but not specifically the issue or resolution methods relevant to the query.\n",
            "  relevance_explanation: The question specifically addresses an issue with a long upgrade time between DASH versions 3.1.2.1 and 3.1.3.0. Relevant information must directly mention these versions or generally discuss upgrades in this context. None of the documents directly mention the issue of long upgrade times between these versions nor do they suggest solutions specifically for speeding up the process between these two versions.\n",
            "  all_relevant_sentence_keys: []\n",
            "  all_utilized_sentence_keys: []\n",
            "  trulens_groundedness: None\n",
            "  trulens_context_relevance: None\n",
            "  ragas_faithfulness: None\n",
            "  ragas_context_relevance: None\n",
            "  gpt3_adherence: None\n",
            "  gpt3_context_relevance: None\n",
            "  gpt35_utilization: None\n",
            "  relevance_score: 0.0\n",
            "  utilization_score: 0.0\n",
            "  completeness_score: 1.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print the top 5 rows of the dataset, for debugging purpose, we only generate embeddings for these 5 rows\n",
        "from datasets import load_dataset\n",
        "datasets = ['techqa']\n",
        "data = load_dataset(\"rungalileo/ragbench\", datasets[0], split=\"train\")\n",
        "top_5_rows = data.select(range(2))\n",
        "\n",
        "for i, row in enumerate(top_5_rows):\n",
        "    print(f\"Row {i + 1}:\")\n",
        "    for field, value in row.items():\n",
        "        print(f\"  {field}: {value}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVSDJMXKESqL"
      },
      "source": [
        "## **Generate Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329,
          "referenced_widgets": [
            "624381b929444c309b853f19975cf29a",
            "89960f40d92d44ac87ca63087126314f",
            "d72eef68e9974ae9865046ad2221ee7c",
            "f5d957782ed54eeebe823b4b7ad7188a",
            "41d676734897484d907f74160f3ad61d",
            "845cce0c0b404bb9b52906822318337e",
            "ecab979901b849c28e9f7a4667829434",
            "a4c3dcd889cd49008d1fa9c961bffdd3",
            "5a60c0cd3b0b4e378d02dc0b9f92b87c",
            "7c45eff45c39470ea7b7ee804747e071",
            "41eaba06b7f940d0b812767d1242ec7d"
          ]
        },
        "id": "K6EmB_fgcG4v",
        "outputId": "2594460b-ec6a-4f56-bf3d-5a22104ba9e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing techqa: 2it [00:00, 15.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "document>>>>>>> ['HL083112 mqlpgrlg ZX000001 ExecCtrlrMain lpiRC_LOG_NOT_AVAILABLE mscs TECHNOTE (TROUBLESHOOTING)\\n\\nPROBLEM(ABSTRACT)\\n You attempt to failover from the primary to secondary node under MSCS. Your WebSphere MQ queue manager fails to come up on the secondary node, and errors are generated. \\n\\nSYMPTOM\\nThe sequence seen in the FDC files show:\\n\\n\\nProbe Id :- HL083112 \\nComponent :- mqlpgrlg \\nProcess Name :- D:\\\\Programs\\\\MQSeries\\\\bin\\\\amqzxma0.exe \\nMajor Errorcode :- hrcE_MQLO_UNEXPECTED_OS_ERROR \\nMQM Function Stack\\nkpiStartup\\napiStartup\\nalmPerformReDoPass\\nhlgScanLogBegin\\nmqlpgrlg\\nxcsFFST\\n\\n\\nProbe Id :- ZX000001\\nComponent :- ExecCtrlrMain \\nProcess Name :- D:\\\\Programs\\\\MQSeries\\\\bin\\\\amqzxma0.exe \\nMajor Errorcode :- xecF_E_UNEXPECTED_RC \\nMinor Errorcode :- lpiRC_LOG_NOT_AVAILABLE \\nProbe Description :- AMQ6118: An internal WebSphere MQ error has occurred \\n(7017) \\nArith1 :- 28695 7017 \\nMQM Function Stack\\nxcsFFST\\n\\n\\nCAUSE\\nThis is caused by a logger failure at restart due to missing or damaged logs.\\n\\n\\nRESOLVING THE PROBLEM\\nRename the file amqalchk.fil, which is found under mq\\\\qmgrs\\\\qmgrname\\\\ on the shared drive (to something like amqalchk.fil_OLD); then restart the queue manager.\\n\\n\\n\\nPRODUCT ALIAS/SYNONYM\\n WMQ / MQ', ' SUBSCRIBE TO THIS APAR\\nBy subscribing, you receive periodic emails alerting you to the status of the APAR, along with a link to the fix after it becomes available. You can track this item individually or track all items by product.\\n\\nNotify me when this APAR changes.\\n\\nNotify me when an APAR for this component changes.\\n\\n\\n\\nAPAR STATUS\\n * CLOSED AS PROGRAM ERROR.\\n    \\n   \\n   \\n\\nERROR DESCRIPTION\\n *  If the return value from onstat is used to determine when\\n   applications can be started in a hardware failover, the\\n   applications can be started prior to the engine allowing\\n   connections if ER needs to sync at start up.  In this case ,the\\n   application may hang requiring manual intervention in what\\n   should be an automated process which will cause a greater amount\\n   of downtime.  If the mode is not set until after ER has finished\\n   syncing and connections are accepted or a new return value is\\n   used to indicate that the instance is on-line and accepting\\n   connections this would resolve the problem.\\n   \\n   \\n    \\n   \\n   \\n\\nLOCAL FIX\\n *  Use onstat -g ntd , grep for sqlexec client type and when the\\n   next column is \"yes\" the instance will be ready to accept\\n   connections.\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM SUMMARY\\n *  ****************************************************************\\n   * USERS AFFECTED:                                              *\\n   * Users with an HDR pair that is an ER participant             *\\n   ****************************************************************\\n   * PROBLEM DESCRIPTION:                                         *\\n   * After failover, the primary shows online mode but the        *\\n   * clients are not able to connect to the server.               *\\n   ****************************************************************\\n   * RECOMMENDATION:                                              *\\n   * Upgrade to 11.50.xC7 and above.                              *\\n   ****************************************************************\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM CONCLUSION\\n *  Problem is first fixed in 11.50.xC7\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n\\nCOMMENTS\\n\\nAPAR INFORMATION\\n * APAR NUMBER\\n   IC64588\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   IBM IDS ENTRP E\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5724L2304\\n   \\n   \\n * REPORTED RELEASE\\n   B15\\n   \\n   \\n * STATUS\\n   CLOSED PER\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   NoHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt\\n   \\n   \\n * SUBMITTED DATE\\n   2009-11-16\\n   \\n   \\n * CLOSED DATE\\n   2010-10-01\\n   \\n   \\n * LAST MODIFIED DATE\\n   2010-10-01\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n\\nFIX INFORMATION\\n * FIXED COMPONENT NAME\\n   IBM IDS ENTRP E\\n   \\n   \\n * FIXED COMPONENT ID\\n   5724L2304\\n   \\n   \\n\\nAPPLICABLE COMPONENT LEVELS\\n * RB15 PSY\\n   UP', 'z/os  A FIX IS AVAILABLE\\nObtain the fix for this APAR.\\n\\n\\nSUBSCRIBE\\nYou can track all active APARs for this component.\\n\\n\\n\\nAPAR STATUS\\n * CLOSED AS UNREPRODUCIBLE IN NEXT RELEASE.\\n    \\n   \\n   \\n\\nERROR DESCRIPTION\\n *  Development Fixes\\n   \\n   \\n    \\n   \\n   \\n\\nLOCAL FIX\\n\\nPROBLEM SUMMARY\\n *  ****************************************************************\\n   * USERS AFFECTED:                                              *\\n   * All users of the IBM z/OS Communications Server for z/OS     *\\n   * Version 2 Release 1                                          *\\n   * E2827/K                                                      *\\n   ****************************************************************\\n   * PROBLEM DESCRIPTION:                                         *\\n   * 13245 EZBSRUTL(HIP6210 13.058)+00EE4A S0C4/00000010          *\\n   * 14704 AB/S0C4 EZBSRWCX +1D1E in TCPIP                        *\\n   * 14540 Stopped PFID(6) killed workloads running on PFID(5)    *\\n   * 14544 Symmetric links does not switch when primary PFID die  *\\n   * 13366 EZASATC2 EZASASUB PER DIRTSTOR ipsa sweden             *\\n   * 14347 FTP client connect fails when a link is available, but *\\n   * the fail over link is not correctly configured.              *\\n   * 14487 AB/S00C4 IEACSS1 +0D9A EZBRCSTG AFTER P TCPSVT2        *\\n   * 14591 ABEND S4c5 EZBSRUTL(HIP6210 13.092)+007DC6             *\\n   * S4C5/74300402                                                *\\n   * 14820 invalid mtu value on accept and confirm                *\\n   * 15149 Urgent data broken                                     *\\n   * 14037 Java readUTF() failed                                  *\\n   * 14680 error detection                                        *\\n   * 15085 remove traps for 8481 and 8552                         *\\n   ****************************************************************\\n   * RECOMMENDATION:                                              *\\n   * Apply fix.                                                   *\\n   ****************************************************************\\n   13245 A 64-bit memory region associated with buffer was freed\\n   prior to the storage being de-registered to the devices. This\\n   can cause result in an Abend in EZBSRUTL (TCP/IP stack) or a DC2\\n   Abend registered by IOS\\'\\n   14704 abend in EZBSRWCX caused by residual data in reg 15 during\\n   inline ITLOCK release which the downlevel SYSEVENT macro does\\n   not clear\\n   14540 - device outage caused stack to initiate failover. We\\n   first saw the error on a Test Link signal and, as part of\\n   failover, replayed the Test Link over the other link. When we\\n   got a test link reply over the other link we weren\\'t expecting\\n   it and failed that link also.\\n   14544 The stack processing for an INOP is incorrect. A link\\n   INOPed when the stack had an alternate. The stack is incorrectly\\n   resetting the TCP connections associated with the failed link.\\n   \\n   13366 The SNMP TCP/IP subagent was not checking whether an\\n   instance value had been specified for an SNMP Getnext request.\\n   If no instance value had been specified, the subagent to\\n   accessed low core when trying to use the instance value.\\n   14347 Timing window during link group establishment after\\n   alternate link fails due to a switch misconfiguration.\\n   14487 Abend S0C4 ocurrs when a STOP TCPIP is issued when tracing\\n   is active.\\n   14591Running short lived streaming jobs there were observed\\n   Abends during the de-activation of one or more of the links.\\n   14820 Packet trace is formatting the MTU field in all ACCEPT and\\n   CONFIRM messages. However, only for the connection that causes\\n   the link to be set up is the MTU valid. For cases where the MTU\\n   is not used packet trace should not format it.\\n   15149 The sender stopped sending data after sending urgent data\\n   because it did not recognize that the urgent data had been\\n   consumed by the receiver.\\n   14037 Code did not properly handle IOV64 structures passed from\\n   the application on send/receive calls.\\n   14680 New Function.\\n   15085 During the release, we had written several traps to catch\\n   particular problems that occur infrequently during stress runs.\\n   Those traps were implemented with defects 8481 and 8552. This\\n   defect is to remove those traps.\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM CONCLUSION\\n *  13245 Code was changed in EZBSRUTL de-register only after a\\n   DM_Act_REQ Function(DEREGISTER) has been performed for each\\n   associated link. Additionally logic was added to make sure that\\n   when the VTAM had issues with the de-registration of a buffer\\n   that it is not freed until VTAM completes \"force close\"\\n   processing for the associated link.\\n   14704 change EZBSRWCX to use out-of-line ITLOCK release instead\\n   14540 Change EZBSRUTL to not retransmit Test Link LLC signal\\n   during link failover processing. A Test Link is only meaningful\\n   over the link where it was originally sent so we should never\\n   retransmit these during failover.\\n   14544 Change EZBSRUTL to allow link failover processing to occur\\n   after an INOP.\\n   13366 The SNMP TCP/IP subagent has been changed to verify that\\n   an instance value has been specified for an SNMP Getnext\\n   request, before using the instance value.\\n   14347 Send a Delete Link LLC signal when cleaning up after an\\n   alternate link failure.\\n   14487 There is a timing window where the SRB routine to copy\\n   trace data to user storage where\\n   the trace collection buffer has been freed.\\n   14591 Changed EZBSRUTL to correctly de-register buffers from\\n   links and IOS\\'. Fixed race conditions where buffer pool\\n   expansion and link inactivation could be happening\\n   simultaneously.\\n   14820 Packet trace will now bypass formatting the MTU field if\\n   it is not set (0). Additionally,\\n   the psn field is valid only on first connection and will also be\\n   bypassed by packet\\n   trace when it is not set.\\n   15149 EZBSCINB is changed to check for urgent data being\\n   consumed when there is not data on the send queue.\\n   14037 EZBTSFWR and EZBTCFRD were updated to properly handle\\n   IOV64 structures.\\n   14680 New Function.\\n   15085 Removed 2 traps\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n\\nCOMMENTS\\n *  No additional comments.\\n   \\n   \\n    \\n   \\n   \\n\\nAPAR INFORMATION\\n * APAR NUMBER\\n   PM88813\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   TCP/IP V3 MVS\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5655HAL00\\n   \\n   \\n * REPORTED RELEASE\\n   210\\n   \\n   \\n * STATUS\\n   CLOSED UR1\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   NoHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt\\n   \\n   \\n * SUBMITTED DATE\\n   2013-05-10\\n   \\n   \\n * CLOSED DATE\\n   2013-05-31\\n   \\n   \\n * LAST MODIFIED DATE\\n   2013-08-19\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n    UK94777\\n   \\n   \\n\\nMODULES/MACROS\\n *  EZBSRWCX EZBSCINB EZBCTFME EZBSRUTL EZASAIP  EZBRCINI EZASATCP\\n   EZASAUDP EZBRCSTG EZASATC2 EZASADV  EZASAIP2 EZASASYS EZBTSFWR\\n   EZASAINT EZBTSCON EZBSRLLC EZBPTSMC EZASAICM EZASAPOR EZBTCFRD\\n   EZBIFIUM EZBIFIUT\\n   \\n   \\n    \\n   \\n   \\n\\nFIX INFORMATION\\n * FIXED COMPONENT NAME\\n   TCP/IP V3 MVS\\n   \\n   \\n * FIXED COMPONENT ID\\n   5655HAL00\\n   \\n   \\n\\nAPPLICABLE COMPONENT LEVELS\\n * R210 PSY UK94777 [HTTPS://WWW14.SOFTWARE.IBM.COM/WEBAPP/SET2/ORDERMEDIA/SHOPCART?PTFS=UK94777]\\n   UP13/06/21 P F306\\n   \\n   \\n\\nFIX IS AVAILABLE\\n * SELECT THE PTF APPROPRIATE FOR YOUR COMPONENT LEVEL. YOU WILL BE REQUIRED TO SIGN IN. DISTRIBUTION ON PHYSICAL MEDIA IS NOT AVAILABLE IN ALL COUNTRIES.', \"z/os  A FIX IS AVAILABLE\\nObtain the fix for this APAR.\\n\\n\\nSUBSCRIBE\\nYou can track all active APARs for this component.\\n\\n\\n\\nAPAR STATUS\\n * CLOSED AS PROGRAM ERROR.\\n    \\n   \\n   \\n\\nERROR DESCRIPTION\\n *  The problem is as follows:\\n   .\\n   Two queue managers (QMA and QMB) are members\\n   of a QSG and are also members of a cluster.\\n   The QSG has a shared queue (SQ1) which is defined\\n   as being in the cluster. This results in both\\n   queue managers advertising an instance of that\\n   queue to other members of the cluster.\\n   .\\n   SQ1 is then deleted. This should cause both\\n   queue managers to send an update to the cluster\\n   to notify other members that the queue manager\\n   no longer hosts an instance of that clustered\\n   queue. However, for shared queues this update\\n   does not happen (at least, not straight away).\\n   .\\n   The result of this is that the cluster cache\\n   on each qmgr has two records for the queue\\n   (one for each qmgr), but neither has an instance\\n   of the queue to put messages to.\\n   .\\n   When a message is put with a queue name\\n   SQ1 on QMA, it detects that there isn't a local\\n   queue instance, so it uses the cluster cache to\\n   resolve the location of the queue name.\\n   As no local instance exists, it selects the only\\n   other entry for the queue (QMB) and puts the\\n   message to the SYSTEM.CLUSTER.TRANSMIT.QUEUE to\\n   be sent to QMB.\\n   .\\n   When the message is sent over the channel,\\n   QMB also detects that there is no local instance\\n   of the queue, so goes to the cluster cache and\\n   determines that QMA is the only available instance.\\n   .\\n   The message loops between the two qmgrs. This\\n   causes high CPU, and if the message is persistent\\n   then it also causes the high logging volume\\n   seen by the customer.\\n   .\\n   Additional Symptom(s) Search Keyword(s):\\n   \\n   \\n    \\n   \\n   \\n\\nLOCAL FIX\\n *  Restart the QMQRs. The cache did get updated after the queue\\n   managers were restarted.\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM SUMMARY\\n *  ****************************************************************\\n   * USERS AFFECTED: All users of WebSphere MQ for z/OS Version 8 *\\n   *                 Release 0 Modification 0.                    *\\n   ****************************************************************\\n   * PROBLEM DESCRIPTION: Deleting a shared cluster queue may     *\\n   *                      result in the cluster definitions for   *\\n   *                      the shared queue remaining in the       *\\n   *                      cluster after a successful shared queue *\\n   *                      delete.                                 *\\n   ****************************************************************\\n   * RECOMMENDATION:                                              *\\n   ****************************************************************\\n   If multiple members of a QSG are also members of the same\\n   cluster, when a shared cluster queue is deleted, the cluster\\n   records for the queue may continue to exist in the cluster. This\\n   can result the cluster hosting records for queues which no\\n   longer are valid. If messages are put to one of these queues,\\n   cluster resolution will attempt to put the message to another\\n   QMGR in the cluster where the queue was previously hosted, which\\n   result in further cluster resolution and subsequent puts to\\n   other cluster QMGRs, which can result in infinite loop of\\n   cluster resolution and puts to other QMGRs. This is due to\\n   shared queue deletes not correctly broadcasting the delete of\\n   the cluster queue in this case.\\n   \\n   The looping between QMGRs can result in high CPU usage on all\\n   the QMGRs involved. If the message put was persistent, this will\\n   also result in high logging volumes. When this scenario is\\n   encountered, a cancel may be required to stop the QMGR.\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM CONCLUSION\\n *  Shared queue delete broadcast for cluster queues has been\\n   corrected to ensure cluster records are correctly deleted when a\\n   delete shared queue command is issued.\\n   000Y\\n   CSQMUQLC\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n *  *********\\n   * HIPER *\\n   *********\\n   \\n   \\n    \\n   \\n   \\n\\nCOMMENTS\\n\\nAPAR INFORMATION\\n * APAR NUMBER\\n   PI76942\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   WMQ Z/OS 8\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5655W9700\\n   \\n   \\n * REPORTED RELEASE\\n   000\\n   \\n   \\n * STATUS\\n   CLOSED PER\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   YesHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt / Xsystem\\n   \\n   \\n * SUBMITTED DATE\\n   2017-02-21\\n   \\n   \\n * CLOSED DATE\\n   2017-04-13\\n   \\n   \\n * LAST MODIFIED DATE\\n   2017-09-16\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n    PI79259 [http://www-01.ibm.com/support/docview.wss?uid=swg1PI79259] UI46399\\n   \\n   \\n\\nMODULES/MACROS\\n *  CSQMUQLC\\n   \\n   \\n    \\n   \\n   \\n\\nFIX INFORMATION\\n * FIXED COMPONENT NAME\\n   WMQ Z/OS 8\\n   \\n   \\n * FIXED COMPONENT ID\\n   5655W9700\\n   \\n   \\n\\nAPPLICABLE COMPONENT LEVELS\\n * R000 PSY UI46399 [HTTPS://WWW14.SOFTWARE.IBM.COM/WEBAPP/SET2/ORDERMEDIA/SHOPCART?PTFS=UI46399]\\n   UP17/06/06 P F706 \\n   \\n   \\n\\nFIX IS AVAILABLE\\n * SELECT THE PTF APPROPRIATE FOR YOUR COMPONENT LEVEL. YOU WILL BE REQUIRED TO SIGN IN. DISTRIBUTION ON PHYSICAL MEDIA IS NOT AVAILABLE IN ALL COUNTRIES.\", 'Performance Tuning; STERLINGNFX TECHNOTE (TROUBLESHOOTING)\\n\\nPROBLEM(ABSTRACT)\\n How do Sterling SCA/MCF/MCSF applications handle Integration Server JMS failover? \\n\\nSYMPTOM\\n\\n\\nProblem Statement: To achieve JMS failover in Integration Server configuration, so that messages do not backup in any particular queue. Problem Description: There are two JMS Servers forming a virtual cluster as in reality they are on independent machines. These servers have identical Queues, and a load balancer farms messages into either of the Queues. \\nAn Integration Server runs on each of these servers and they expect to read and process messages from both the queues, so that if any one of the queue goes down, then the JMSReceiver/Sterling service can continue to read from the other backup queue. \\nIn the service definition of the JMS Receiver component, the Provider URL is a comma-separated entry e.g. Provider URL = JMSServer1, JMSServer2 \\nRESOLVING THE PROBLEM\\n\\n\\nThe product does not support this configuration of comma-separated URLs for active-active failover.\\n\\n \\n\\n If the JMS Server is outside a cluster, the JMS Receiver Provider URL identifies one machine to which the Integration Server will connect. \\n(This configuration might work, in the sense, some threads might latch on and listen on Queue1, and some threads listen on Queue2. Once this happens, they will stay in that specific pattern/ratio for the lifetime of that Integration Server JVM. However, it is more of a lottery system than logic, the way the threads are farmed out. It therefore is not sensible to depend on this comma-separated URL logic to achieve division of labor between the threads.) \\n\\nThe CORRECT process configuration on how to achieve active-active JMS failover configuration for Integration Server is: Create a clone of the existing service. \\n\\n\\nService 1 will listen on JMSQueue1; \\nService 2 will listen on JMSQueue2. \\n\\nIf for any reason, Queue on JMSServer1 goes down, it is expected that the load balancer that feeds messages knows that Queue1 is down and to start pumping messages to Queue2. \\n\\nWith the new configuration, Service2 will now take the brunt of processing these messages at double the load.\\nTo implement the new configuration modify the existing service from\\n\\n \"JMSReceiver (1, 2) -> XSL -> api ->parse+manipulate+etc -> end,\\n\\nso that the processing part of the service is a Reusable Service (sync) \\nand \\nService 1 = JMSReceiver (1) -> Reusable SyncService -> End \\nService 2 = JMSReceiver (2) -> Reusable SyncService -> End \\n\\nWhy is failover required for Integration Server scenario? \\n\\n\\nFailover is required in an environment where two separate WAS instances (active-active, separate physical locations) exist, and WAS 1 is brought down, then the Integration services that were using the JMS destination associated with WAS 1 can use the WAS 2 JMS destination instead.\\n\\nHow, then is the failover scenario handled for Integration Servers by the Sterling SCA product?\\n\\nAn Integration Server, by nature, is always in an active-passive mode of failover. Sterling does not provide a setting or a property that can support an active-active failover mode like it does for agents. \\n\\nTo implement the failover scenario for Integration Servers, customers can duplicate the set of services that are running on their current environment and copy it over to the backup environment. Each duplicate service can point to a new queue that will receive the same messages that the original queue belonging to the original service was receiving. This will thus, result in an active-active failover scenario.\\n\\n \\n\\nWhy has Sterling not implemented Integration Server failover mechanism as for Agents through backup Provider URLs?\\n\\nIn case of Agent failover, all the active-active Agents must connect to the same JMS Queue. The JMS queue contains a unique message for each transaction that the Agent has to process. All threads of a particular Agent (across physical servers and JVMs) read off one message at a time from the queue - thus avoiding conflicting/overlapping transactions. \\n\\n\\nHence, the single point of failure in this solution is the Queue itself. If the queue fails, all instances of the agent will fail as well, with no option to handle failovers. To address this problem, Sterling provided a mechanism of assigning backup provider URLs to support failovers. \\nHowever, in the case of Integration Servers, one can pull the same message from multiple queues using duplicate services. Hence, there is a good option present to configure the failover scenario as previously described.\\n\\nWhat are the technical challenges of coming up with failover mechanism for Integration Servers similar to Agent Servers? \\n\\n\\nTechnically, one can configure Integration Servers to read off the backup provider URL in the same manner as Agent Servers. However, some inherent problems go along with it.\\nIn the case of Agent Servers, Sterling did not have a choice but to provide a fix because of the JMS queue being the single point of failure. In case of Integration services, however, one can configure multiple queues to work on incoming messages eliminating queues as a single point of failure. \\n\\nIf the change is to redirect all messages to a backup queue, then configure multiple services to receive from the same queue using individual message selectors. However, this can cause a drag on the system and result in performance issues.\\n\\nIn addition, in future Sterling would like to implement the Message Driven Beans (MDB) mechanism for pulling messages from the queues. Since this involves a third-party established standard for processing queues and the Application Server drives it, Sterling will have minimal control over it.\\n\\nHow can the customers best implement the workaround suggested by Sterling? \\n\\n\\nOne does not need to duplicate synchronous services. In this case, the Application Server will take care of the failover scenario. Apply this workaround only to mission-critical, asynchronous services since this is where the business logic will reside. \\n\\nThe best way to achieve the duplication would be abstract the services that contain complex business logic and model them as composite services within Sterling. This will make it easy for customers to get the duplication implemented since the crucial business logic will be independent of the queues narrowing down the components, which need change. Needless to state, this logic needs to be well tested before deployment.\\n\\nAre there any advantages of implementing the workaround as opposed to fixing it similar to Agent Server failover? \\n\\n\\nWith the duplication of the services workaround, customers will get an active-active failover mode as opposed to the active-passive mode when providing a backup provider URL.\\n\\n\\n\\nHISTORICAL NUMBER\\n NFX4092 \\n\\nPRODUCT ALIAS/SYNONYM\\n \\n\\nFunction Area\\n\\n\\nIntegration Server\\n\\n\\nSeverity\\n\\n\\nNormal\\n\\n\\nType\\n\\n\\nNormalFix']\n",
            "section_chunks>>>>>>> [['0a', 'HL083112 mqlpgrlg ZX000001 ExecCtrlrMain lpiRC_LOG_NOT_AVAILABLE mscs TECHNOTE (TROUBLESHOOTING)\\n\\nPROBLEM(ABSTRACT)\\n You attempt to failover from the primary to secondary node under MSCS.'], ['0b', 'Your WebSphere MQ queue manager fails to come up on the secondary node, and errors are generated.'], ['0c', 'SYMPTOM\\nThe sequence seen in the FDC files show:\\n\\n\\nProbe Id :- HL083112 \\nComponent :- mqlpgrlg \\nProcess Name :- D:\\\\Programs\\\\MQSeries\\\\bin\\\\amqzxma0.exe \\nMajor Errorcode :- hrcE_MQLO_UNEXPECTED_OS_ERROR \\nMQM Function Stack\\nkpiStartup\\napiStartup\\nalmPerformReDoPass\\nhlgScanLogBegin\\nmqlpgrlg\\nxcsFFST\\n\\n\\nProbe Id :- ZX000001\\nComponent :- ExecCtrlrMain \\nProcess Name :- D:\\\\Programs\\\\MQSeries\\\\bin\\\\amqzxma0.exe \\nMajor Errorcode :- xecF_E_UNEXPECTED_RC \\nMinor Errorcode :- lpiRC_LOG_NOT_AVAILABLE \\nProbe Description :- AMQ6118: An internal WebSphere MQ error has occurred \\n(7017) \\nArith1 :- 28695 7017 \\nMQM Function Stack\\nxcsFFST\\n\\n\\nCAUSE\\nThis is caused by a logger failure at restart due to missing or damaged logs.'], ['0d', 'RESOLVING THE PROBLEM\\nRename the file amqalchk.fil, which is found under mq\\\\qmgrs\\\\qmgrname\\\\ on the shared drive (to something like amqalchk.fil_OLD); then restart the queue manager.'], ['0e', 'PRODUCT ALIAS/SYNONYM\\n WMQ / MQ']]\n",
            "section_chunks>>>>>>> [['1a', ' SUBSCRIBE TO THIS APAR\\nBy subscribing, you receive periodic emails alerting you to the status of the APAR, along with a link to the fix after it becomes available.'], ['1b', 'You can track this item individually or track all items by product.'], ['1c', 'Notify me when this APAR changes.'], ['1d', 'Notify me when an APAR for this component changes.'], ['1e', 'APAR STATUS\\n * CLOSED AS PROGRAM ERROR.'], ['1f', 'ERROR DESCRIPTION\\n *  If the return value from onstat is used to determine when\\n   applications can be started in a hardware failover, the\\n   applications can be started prior to the engine allowing\\n   connections if ER needs to sync at start up.'], ['1g', 'In this case ,the\\n   application may hang requiring manual intervention in what\\n   should be an automated process which will cause a greater amount\\n   of downtime.'], ['1h', 'If the mode is not set until after ER has finished\\n   syncing and connections are accepted or a new return value is\\n   used to indicate that the instance is on-line and accepting\\n   connections this would resolve the problem.'], ['1i', 'LOCAL FIX\\n *  Use onstat -g ntd , grep for sqlexec client type and when the\\n   next column is \"yes\" the instance will be ready to accept\\n   connections.'], ['1j', 'PROBLEM SUMMARY\\n *  ****************************************************************\\n   * USERS AFFECTED:                                              *\\n   * Users with an HDR pair that is an ER participant             *\\n   ****************************************************************\\n   * PROBLEM DESCRIPTION:                                         *\\n   * After failover, the primary shows online mode but the        *\\n   * clients are not able to connect to the server.'], ['1k', '*\\n   ****************************************************************\\n   * RECOMMENDATION:                                              *\\n   * Upgrade to 11.50.xC7 and above.'], ['1l', '*\\n   ****************************************************************\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM CONCLUSION\\n *  Problem is first fixed in 11.50.xC7\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n\\nCOMMENTS\\n\\nAPAR INFORMATION\\n * APAR NUMBER\\n   IC64588\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   IBM IDS ENTRP E\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5724L2304\\n   \\n   \\n * REPORTED RELEASE\\n   B15\\n   \\n   \\n * STATUS\\n   CLOSED PER\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   NoHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt\\n   \\n   \\n * SUBMITTED DATE\\n   2009-11-16\\n   \\n   \\n * CLOSED DATE\\n   2010-10-01\\n   \\n   \\n * LAST MODIFIED DATE\\n   2010-10-01\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n\\nFIX INFORMATION\\n * FIXED COMPONENT NAME\\n   IBM IDS ENTRP E\\n   \\n   \\n * FIXED COMPONENT ID\\n   5724L2304\\n   \\n   \\n\\nAPPLICABLE COMPONENT LEVELS\\n * RB15 PSY\\n   UP']]\n",
            "section_chunks>>>>>>> [['2a', 'z/os  A FIX IS AVAILABLE\\nObtain the fix for this APAR.'], ['2b', 'SUBSCRIBE\\nYou can track all active APARs for this component.'], ['2c', 'APAR STATUS\\n * CLOSED AS UNREPRODUCIBLE IN NEXT RELEASE.'], ['2d', 'ERROR DESCRIPTION\\n *  Development Fixes\\n   \\n   \\n    \\n   \\n   \\n\\nLOCAL FIX\\n\\nPROBLEM SUMMARY\\n *  ****************************************************************\\n   * USERS AFFECTED:                                              *\\n   * All users of the IBM z/OS Communications Server for z/OS     *\\n   * Version 2 Release 1                                          *\\n   * E2827/K                                                      *\\n   ****************************************************************\\n   * PROBLEM DESCRIPTION:                                         *\\n   * 13245 EZBSRUTL(HIP6210 13.058)+00EE4A S0C4/00000010          *\\n   * 14704 AB/S0C4 EZBSRWCX +1D1E in TCPIP                        *\\n   * 14540 Stopped PFID(6) killed workloads running on PFID(5)    *\\n   * 14544 Symmetric links does not switch when primary PFID die  *\\n   * 13366 EZASATC2 EZASASUB PER DIRTSTOR ipsa sweden             *\\n   * 14347 FTP client connect fails when a link is available, but *\\n   * the fail over link is not correctly configured.'], ['2e', '*\\n   * 14487 AB/S00C4 IEACSS1 +0D9A EZBRCSTG AFTER P TCPSVT2        *\\n   * 14591 ABEND S4c5 EZBSRUTL(HIP6210 13.092)+007DC6             *\\n   * S4C5/74300402                                                *\\n   * 14820 invalid mtu value on accept and confirm                *\\n   * 15149 Urgent data broken                                     *\\n   * 14037 Java readUTF() failed                                  *\\n   * 14680 error detection                                        *\\n   * 15085 remove traps for 8481 and 8552                         *\\n   ****************************************************************\\n   * RECOMMENDATION:                                              *\\n   * Apply fix.'], ['2f', '*\\n   ****************************************************************\\n   13245 A 64-bit memory region associated with buffer was freed\\n   prior to the storage being de-registered to the devices.'], ['2g', \"This\\n   can cause result in an Abend in EZBSRUTL (TCP/IP stack) or a DC2\\n   Abend registered by IOS'\\n   14704 abend in EZBSRWCX caused by residual data in reg 15 during\\n   inline ITLOCK release which the downlevel SYSEVENT macro does\\n   not clear\\n   14540 - device outage caused stack to initiate failover.\"], ['2h', 'We\\n   first saw the error on a Test Link signal and, as part of\\n   failover, replayed the Test Link over the other link.'], ['2i', \"When we\\n   got a test link reply over the other link we weren't expecting\\n   it and failed that link also.\"], ['2j', '14544 The stack processing for an INOP is incorrect.'], ['2k', 'A link\\n   INOPed when the stack had an alternate.'], ['2l', 'The stack is incorrectly\\n   resetting the TCP connections associated with the failed link.'], ['2m', '13366 The SNMP TCP/IP subagent was not checking whether an\\n   instance value had been specified for an SNMP Getnext request.'], ['2n', 'If no instance value had been specified, the subagent to\\n   accessed low core when trying to use the instance value.'], ['2o', '14347 Timing window during link group establishment after\\n   alternate link fails due to a switch misconfiguration.'], ['2p', '14487 Abend S0C4 ocurrs when a STOP TCPIP is issued when tracing\\n   is active.'], ['2q', '14591Running short lived streaming jobs there were observed\\n   Abends during the de-activation of one or more of the links.'], ['2r', '14820 Packet trace is formatting the MTU field in all ACCEPT and\\n   CONFIRM messages.'], ['2s', 'However, only for the connection that causes\\n   the link to be set up is the MTU valid.'], ['2t', 'For cases where the MTU\\n   is not used packet trace should not format it.'], ['2u', '15149 The sender stopped sending data after sending urgent data\\n   because it did not recognize that the urgent data had been\\n   consumed by the receiver.'], ['2v', '14037 Code did not properly handle IOV64 structures passed from\\n   the application on send/receive calls.'], ['2w', '14680 New Function.'], ['2x', '15085 During the release, we had written several traps to catch\\n   particular problems that occur infrequently during stress runs.'], ['2y', 'Those traps were implemented with defects 8481 and 8552.'], ['2z', 'This\\n   defect is to remove those traps.'], ['2aa', 'PROBLEM CONCLUSION\\n *  13245 Code was changed in EZBSRUTL de-register only after a\\n   DM_Act_REQ Function(DEREGISTER) has been performed for each\\n   associated link.'], ['2ab', 'Additionally logic was added to make sure that\\n   when the VTAM had issues with the de-registration of a buffer\\n   that it is not freed until VTAM completes \"force close\"\\n   processing for the associated link.'], ['2ac', '14704 change EZBSRWCX to use out-of-line ITLOCK release instead\\n   14540 Change EZBSRUTL to not retransmit Test Link LLC signal\\n   during link failover processing.'], ['2ad', 'A Test Link is only meaningful\\n   over the link where it was originally sent so we should never\\n   retransmit these during failover.'], ['2ae', '14544 Change EZBSRUTL to allow link failover processing to occur\\n   after an INOP.'], ['2af', '13366 The SNMP TCP/IP subagent has been changed to verify that\\n   an instance value has been specified for an SNMP Getnext\\n   request, before using the instance value.'], ['2ag', '14347 Send a Delete Link LLC signal when cleaning up after an\\n   alternate link failure.'], ['2ah', '14487 There is a timing window where the SRB routine to copy\\n   trace data to user storage where\\n   the trace collection buffer has been freed.'], ['2ai', \"14591 Changed EZBSRUTL to correctly de-register buffers from\\n   links and IOS'.\"], ['2aj', 'Fixed race conditions where buffer pool\\n   expansion and link inactivation could be happening\\n   simultaneously.'], ['2ak', '14820 Packet trace will now bypass formatting the MTU field if\\n   it is not set (0).'], ['2al', 'Additionally,\\n   the psn field is valid only on first connection and will also be\\n   bypassed by packet\\n   trace when it is not set.'], ['2am', '15149 EZBSCINB is changed to check for urgent data being\\n   consumed when there is not data on the send queue.'], ['2an', '14037 EZBTSFWR and EZBTCFRD were updated to properly handle\\n   IOV64 structures.'], ['2ao', '14680 New Function.'], ['2ap', '15085 Removed 2 traps\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n\\nCOMMENTS\\n *  No additional comments.'], ['2aq', 'APAR INFORMATION\\n * APAR NUMBER\\n   PM88813\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   TCP/IP V3 MVS\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5655HAL00\\n   \\n   \\n * REPORTED RELEASE\\n   210\\n   \\n   \\n * STATUS\\n   CLOSED UR1\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   NoHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt\\n   \\n   \\n * SUBMITTED DATE\\n   2013-05-10\\n   \\n   \\n * CLOSED DATE\\n   2013-05-31\\n   \\n   \\n * LAST MODIFIED DATE\\n   2013-08-19\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n    UK94777\\n   \\n   \\n\\nMODULES/MACROS\\n *  EZBSRWCX EZBSCINB EZBCTFME EZBSRUTL EZASAIP  EZBRCINI EZASATCP\\n   EZASAUDP EZBRCSTG EZASATC2 EZASADV  EZASAIP2 EZASASYS EZBTSFWR\\n   EZASAINT EZBTSCON EZBSRLLC EZBPTSMC EZASAICM EZASAPOR EZBTCFRD\\n   EZBIFIUM EZBIFIUT\\n   \\n   \\n    \\n   \\n   \\n\\nFIX INFORMATION\\n * FIXED COMPONENT NAME\\n   TCP/IP V3 MVS\\n   \\n   \\n * FIXED COMPONENT ID\\n   5655HAL00\\n   \\n   \\n\\nAPPLICABLE COMPONENT LEVELS\\n * R210 PSY UK94777 [HTTPS://WWW14.SOFTWARE.IBM.COM/WEBAPP/SET2/ORDERMEDIA/SHOPCART?PTFS=UK94777]\\n   UP13/06/21 P F306\\n   \\n   \\n\\nFIX IS AVAILABLE\\n * SELECT THE PTF APPROPRIATE FOR YOUR COMPONENT LEVEL.'], ['2ar', 'YOU WILL BE REQUIRED TO SIGN IN.'], ['2as', 'DISTRIBUTION ON PHYSICAL MEDIA IS NOT AVAILABLE IN ALL COUNTRIES.']]\n",
            "section_chunks>>>>>>> [['3a', 'z/os  A FIX IS AVAILABLE\\nObtain the fix for this APAR.'], ['3b', 'SUBSCRIBE\\nYou can track all active APARs for this component.'], ['3c', 'APAR STATUS\\n * CLOSED AS PROGRAM ERROR.'], ['3d', 'ERROR DESCRIPTION\\n *  The problem is as follows:\\n   .'], ['3e', 'Two queue managers (QMA and QMB) are members\\n   of a QSG and are also members of a cluster.'], ['3f', 'The QSG has a shared queue (SQ1) which is defined\\n   as being in the cluster.'], ['3g', 'This results in both\\n   queue managers advertising an instance of that\\n   queue to other members of the cluster.'], ['3h', '.'], ['3i', 'SQ1 is then deleted.'], ['3j', 'This should cause both\\n   queue managers to send an update to the cluster\\n   to notify other members that the queue manager\\n   no longer hosts an instance of that clustered\\n   queue.'], ['3k', 'However, for shared queues this update\\n   does not happen (at least, not straight away).'], ['3l', '.'], ['3m', 'The result of this is that the cluster cache\\n   on each qmgr has two records for the queue\\n   (one for each qmgr), but neither has an instance\\n   of the queue to put messages to.'], ['3n', '.'], ['3o', \"When a message is put with a queue name\\n   SQ1 on QMA, it detects that there isn't a local\\n   queue instance, so it uses the cluster cache to\\n   resolve the location of the queue name.\"], ['3p', 'As no local instance exists, it selects the only\\n   other entry for the queue (QMB) and puts the\\n   message to the SYSTEM.CLUSTER.TRANSMIT.QUEUE to\\n   be sent to QMB.'], ['3q', '.'], ['3r', 'When the message is sent over the channel,\\n   QMB also detects that there is no local instance\\n   of the queue, so goes to the cluster cache and\\n   determines that QMA is the only available instance.'], ['3s', '.'], ['3t', 'The message loops between the two qmgrs.'], ['3u', 'This\\n   causes high CPU, and if the message is persistent\\n   then it also causes the high logging volume\\n   seen by the customer.'], ['3v', '.'], ['3w', 'Additional Symptom(s) Search Keyword(s):\\n   \\n   \\n    \\n   \\n   \\n\\nLOCAL FIX\\n *  Restart the QMQRs.'], ['3x', 'The cache did get updated after the queue\\n   managers were restarted.'], ['3y', 'PROBLEM SUMMARY\\n *  ****************************************************************\\n   * USERS AFFECTED: All users of WebSphere MQ for z/OS Version 8 *\\n   *                 Release 0 Modification 0.'], ['3z', '*\\n   ****************************************************************\\n   * PROBLEM DESCRIPTION: Deleting a shared cluster queue may     *\\n   *                      result in the cluster definitions for   *\\n   *                      the shared queue remaining in the       *\\n   *                      cluster after a successful shared queue *\\n   *                      delete.'], ['3aa', '*\\n   ****************************************************************\\n   * RECOMMENDATION:                                              *\\n   ****************************************************************\\n   If multiple members of a QSG are also members of the same\\n   cluster, when a shared cluster queue is deleted, the cluster\\n   records for the queue may continue to exist in the cluster.'], ['3ab', 'This\\n   can result the cluster hosting records for queues which no\\n   longer are valid.'], ['3ac', 'If messages are put to one of these queues,\\n   cluster resolution will attempt to put the message to another\\n   QMGR in the cluster where the queue was previously hosted, which\\n   result in further cluster resolution and subsequent puts to\\n   other cluster QMGRs, which can result in infinite loop of\\n   cluster resolution and puts to other QMGRs.'], ['3ad', 'This is due to\\n   shared queue deletes not correctly broadcasting the delete of\\n   the cluster queue in this case.'], ['3ae', 'The looping between QMGRs can result in high CPU usage on all\\n   the QMGRs involved.'], ['3af', 'If the message put was persistent, this will\\n   also result in high logging volumes.'], ['3ag', 'When this scenario is\\n   encountered, a cancel may be required to stop the QMGR.'], ['3ah', 'PROBLEM CONCLUSION\\n *  Shared queue delete broadcast for cluster queues has been\\n   corrected to ensure cluster records are correctly deleted when a\\n   delete shared queue command is issued.'], ['3ai', '000Y\\n   CSQMUQLC\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n *  *********\\n   * HIPER *\\n   *********\\n   \\n   \\n    \\n   \\n   \\n\\nCOMMENTS\\n\\nAPAR INFORMATION\\n * APAR NUMBER\\n   PI76942\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   WMQ Z/OS 8\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5655W9700\\n   \\n   \\n * REPORTED RELEASE\\n   000\\n   \\n   \\n * STATUS\\n   CLOSED PER\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   YesHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt / Xsystem\\n   \\n   \\n * SUBMITTED DATE\\n   2017-02-21\\n   \\n   \\n * CLOSED DATE\\n   2017-04-13\\n   \\n   \\n * LAST MODIFIED DATE\\n   2017-09-16\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n    PI79259 [http://www-01.ibm.com/support/docview.wss?uid=swg1PI79259] UI46399\\n   \\n   \\n\\nMODULES/MACROS\\n *  CSQMUQLC\\n   \\n   \\n    \\n   \\n   \\n\\nFIX INFORMATION\\n * FIXED COMPONENT NAME\\n   WMQ Z/OS 8\\n   \\n   \\n * FIXED COMPONENT ID\\n   5655W9700\\n   \\n   \\n\\nAPPLICABLE COMPONENT LEVELS\\n * R000 PSY UI46399 [HTTPS://WWW14.SOFTWARE.IBM.COM/WEBAPP/SET2/ORDERMEDIA/SHOPCART?PTFS=UI46399]\\n   UP17/06/06 P F706 \\n   \\n   \\n\\nFIX IS AVAILABLE\\n * SELECT THE PTF APPROPRIATE FOR YOUR COMPONENT LEVEL.'], ['3aj', 'YOU WILL BE REQUIRED TO SIGN IN.'], ['3ak', 'DISTRIBUTION ON PHYSICAL MEDIA IS NOT AVAILABLE IN ALL COUNTRIES.']]\n",
            "section_chunks>>>>>>> [['4a', 'Performance Tuning; STERLINGNFX TECHNOTE (TROUBLESHOOTING)\\n\\nPROBLEM(ABSTRACT)\\n How do Sterling SCA/MCF/MCSF applications handle Integration Server JMS failover?'], ['4b', 'SYMPTOM\\n\\n\\nProblem Statement: To achieve JMS failover in Integration Server configuration, so that messages do not backup in any particular queue.'], ['4c', 'Problem Description: There are two JMS Servers forming a virtual cluster as in reality they are on independent machines.'], ['4d', 'These servers have identical Queues, and a load balancer farms messages into either of the Queues.'], ['4e', 'An Integration Server runs on each of these servers and they expect to read and process messages from both the queues, so that if any one of the queue goes down, then the JMSReceiver/Sterling service can continue to read from the other backup queue.'], ['4f', 'In the service definition of the JMS Receiver component, the Provider URL is a comma-separated entry e.g.'], ['4g', 'Provider URL = JMSServer1, JMSServer2 \\nRESOLVING THE PROBLEM\\n\\n\\nThe product does not support this configuration of comma-separated URLs for active-active failover.'], ['4h', 'If the JMS Server is outside a cluster, the JMS Receiver Provider URL identifies one machine to which the Integration Server will connect.'], ['4i', '(This configuration might work, in the sense, some threads might latch on and listen on Queue1, and some threads listen on Queue2.'], ['4j', 'Once this happens, they will stay in that specific pattern/ratio for the lifetime of that Integration Server JVM.'], ['4k', 'However, it is more of a lottery system than logic, the way the threads are farmed out.'], ['4l', 'It therefore is not sensible to depend on this comma-separated URL logic to achieve division of labor between the threads.)'], ['4m', 'The CORRECT process configuration on how to achieve active-active JMS failover configuration for Integration Server is: Create a clone of the existing service.'], ['4n', 'Service 1 will listen on JMSQueue1; \\nService 2 will listen on JMSQueue2.'], ['4o', 'If for any reason, Queue on JMSServer1 goes down, it is expected that the load balancer that feeds messages knows that Queue1 is down and to start pumping messages to Queue2.'], ['4p', 'With the new configuration, Service2 will now take the brunt of processing these messages at double the load.'], ['4q', 'To implement the new configuration modify the existing service from\\n\\n \"JMSReceiver (1, 2) -> XSL -> api ->parse+manipulate+etc -> end,\\n\\nso that the processing part of the service is a Reusable Service (sync) \\nand \\nService 1 = JMSReceiver (1) -> Reusable SyncService -> End \\nService 2 = JMSReceiver (2) -> Reusable SyncService -> End \\n\\nWhy is failover required for Integration Server scenario?'], ['4r', 'Failover is required in an environment where two separate WAS instances (active-active, separate physical locations) exist, and WAS 1 is brought down, then the Integration services that were using the JMS destination associated with WAS 1 can use the WAS 2 JMS destination instead.'], ['4s', 'How, then is the failover scenario handled for Integration Servers by the Sterling SCA product?'], ['4t', 'An Integration Server, by nature, is always in an active-passive mode of failover.'], ['4u', 'Sterling does not provide a setting or a property that can support an active-active failover mode like it does for agents.'], ['4v', 'To implement the failover scenario for Integration Servers, customers can duplicate the set of services that are running on their current environment and copy it over to the backup environment.'], ['4w', 'Each duplicate service can point to a new queue that will receive the same messages that the original queue belonging to the original service was receiving.'], ['4x', 'This will thus, result in an active-active failover scenario.'], ['4y', 'Why has Sterling not implemented Integration Server failover mechanism as for Agents through backup Provider URLs?'], ['4z', 'In case of Agent failover, all the active-active Agents must connect to the same JMS Queue.'], ['4aa', 'The JMS queue contains a unique message for each transaction that the Agent has to process.'], ['4ab', 'All threads of a particular Agent (across physical servers and JVMs) read off one message at a time from the queue - thus avoiding conflicting/overlapping transactions.'], ['4ac', 'Hence, the single point of failure in this solution is the Queue itself.'], ['4ad', 'If the queue fails, all instances of the agent will fail as well, with no option to handle failovers.'], ['4ae', 'To address this problem, Sterling provided a mechanism of assigning backup provider URLs to support failovers.'], ['4af', 'However, in the case of Integration Servers, one can pull the same message from multiple queues using duplicate services.'], ['4ag', 'Hence, there is a good option present to configure the failover scenario as previously described.'], ['4ah', 'What are the technical challenges of coming up with failover mechanism for Integration Servers similar to Agent Servers?'], ['4ai', 'Technically, one can configure Integration Servers to read off the backup provider URL in the same manner as Agent Servers.'], ['4aj', 'However, some inherent problems go along with it.'], ['4ak', 'In the case of Agent Servers, Sterling did not have a choice but to provide a fix because of the JMS queue being the single point of failure.'], ['4al', 'In case of Integration services, however, one can configure multiple queues to work on incoming messages eliminating queues as a single point of failure.'], ['4am', 'If the change is to redirect all messages to a backup queue, then configure multiple services to receive from the same queue using individual message selectors.'], ['4an', 'However, this can cause a drag on the system and result in performance issues.'], ['4ao', 'In addition, in future Sterling would like to implement the Message Driven Beans (MDB) mechanism for pulling messages from the queues.'], ['4ap', 'Since this involves a third-party established standard for processing queues and the Application Server drives it, Sterling will have minimal control over it.'], ['4aq', 'How can the customers best implement the workaround suggested by Sterling?'], ['4ar', 'One does not need to duplicate synchronous services.'], ['4as', 'In this case, the Application Server will take care of the failover scenario.'], ['4at', 'Apply this workaround only to mission-critical, asynchronous services since this is where the business logic will reside.'], ['4au', 'The best way to achieve the duplication would be abstract the services that contain complex business logic and model them as composite services within Sterling.'], ['4av', 'This will make it easy for customers to get the duplication implemented since the crucial business logic will be independent of the queues narrowing down the components, which need change.'], ['4aw', 'Needless to state, this logic needs to be well tested before deployment.'], ['4ax', 'Are there any advantages of implementing the workaround as opposed to fixing it similar to Agent Server failover?'], ['4ay', 'With the duplication of the services workaround, customers will get an active-active failover mode as opposed to the active-passive mode when providing a backup provider URL.'], ['4az', 'HISTORICAL NUMBER\\n NFX4092 \\n\\nPRODUCT ALIAS/SYNONYM\\n \\n\\nFunction Area\\n\\n\\nIntegration Server\\n\\n\\nSeverity\\n\\n\\nNormal\\n\\n\\nType\\n\\n\\nNormalFix']]\n",
            "document>>>>>>> [' SUBSCRIBE TO THIS APAR\\nBy subscribing, you receive periodic emails alerting you to the status of the APAR, along with a link to the fix after it becomes available. You can track this item individually or track all items by product.\\n\\nNotify me when this APAR changes.\\n\\nNotify me when an APAR for this component changes.\\n\\n\\n\\nAPAR STATUS\\n * CLOSED AS PROGRAM ERROR.\\n    \\n   \\n   \\n\\nERROR DESCRIPTION\\n *  DASH menu hiding behind AEL in IE 11 Windows Server 2012 R2,\\n   Windows 2010\\n   \\n   Reproduced from DASH 3.1.1.x, DASH 3.1.2 including CP5 (WebGUI\\n   8.1 FP4). to DASH 3.1.3.0 but NOT on DASH 3.1.0.3 (WebGUI\\n   8.1.0)\\n   \\n   Per WebGUI L3, there are no changes in AEL html from 8.1 to 8.1\\n   FP4.\\n   \\n   \\n    \\n   \\n   \\n\\nLOCAL FIX\\n *  No workaround found.\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM SUMMARY\\n *  Please follow below link\\n   http://www-01.ibm.com/support/docview.wss?uid=swg22011801 [http://www-01.ibm.com/support/docview.wss?uid=swg22011801]\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM CONCLUSION\\n *  http://www-01.ibm.com/support/docview.wss?uid=swg22011801 [http://www-01.ibm.com/support/docview.wss?uid=swg22011801]\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n\\nCOMMENTS\\n\\nAPAR INFORMATION\\n * APAR NUMBER\\n   IV90226\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   JAZZ SM TIP DAS\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5724C04JD\\n   \\n   \\n * REPORTED RELEASE\\n   110\\n   \\n   \\n * STATUS\\n   CLOSED PER\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   NoHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt / Xsystem\\n   \\n   \\n * SUBMITTED DATE\\n   2016-10-26\\n   \\n   \\n * CLOSED DATE\\n   2017-12-26\\n   \\n   \\n * LAST MODIFIED DATE\\n   2017-12-26\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n\\nFIX INFORMATION\\n * FIXED COMPONENT NAME\\n   JAZZ SM TIP DAS\\n   \\n   \\n * FIXED COMPONENT ID\\n   5724C04JD\\n   \\n   \\n\\nAPPLICABLE COMPONENT LEVELS\\n * R110 PSY\\n   UP', 'jazzsm1120relnotes jazzsm1101relnotes jazzsm1102relnotes jazzsm1103relnotes jazzsm1110relnotes jazzsm1120relnotes DASH TECHNOTE (TROUBLESHOOTING)\\n\\nPROBLEM(ABSTRACT)\\n After rolling back an upgrade installation, the Dashboard Application Services Hub consolecli.sh command does not work on UNIX-based systems. \\n\\nCAUSE\\nWhen you roll back a Jazz for Service Management upgrade installation, which includes Dashboard Application Service Hub, a path variable contained in consoleSetupEnv.sh is not updated with the actual path value. \\n\\nENVIRONMENT\\nUNIX-based systems\\n\\nRESOLVING THE PROBLEM\\nThis issue will be resolved with the release of Dashboard Application Services Hub Version 3.1.2.1, which will be delivered in Jazz for Service Management 1.1.2.1. When rolling back from this release or later releases, the problem will not occur.\\n\\n\\n\\n\\nIf you roll back and then upgrade again, the problem is resolved. \\n\\nAlternatively, if you do not want to upgrade again to the new version, then to resolve the problem, do the following: \\n\\n 1. Open consoleSetupEnv.sh in a text editor. \\n 2. Locate the following line of code:\\n    TIP_HOME=@TIP_HOME@ \\n 3. Replace the @TIP_HOME@ string with the actual path to the Dashboard Application Services Hub. \\n 4. When you have completed your edits, the updated line would look similar to the following:\\n    TIP_HOME=/opt/IBM/JazzSM/ui \\n 5. Save the updated consoleSetupEnv.sh.', ' SUBSCRIBE\\nYou can track all active APARs for this component.\\n\\n\\n\\nAPAR STATUS\\n * CLOSED AS PERMANENT RESTRICTION.\\n    \\n   \\n   \\n\\nERROR DESCRIPTION\\n *  Issue on Rave Line Chart (Dash 3.1.2.1). All ascending\\n   and\\n   descending option is not working.\\n   \\n   For example\\n   \\n   \\n   Rave Line Chart released in Dash 3.1.2.1 is showing dates from\\n   18th May\\n   to 31st May then 1st and 2nd June. Client is not accepting this\\n   format when descending\\n   it should be like from 2nd June, 1st June, 31st May, 30th, May,\\n   29th May\\n   and so on.\\n   \\n   Data Model is showing descending order:\\n   \\n   \\n    \\n   \\n   \\n\\nLOCAL FIX\\n *  Change the date data type as varchar/string, which is not\\n   acceptable by all customer\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM SUMMARY\\n *  THis is the limitation with Rave feature. Also Rave is not in\\n   support.\\n   \\n   As alternative workaround is suggested in the published technote\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM CONCLUSION\\n *  Please check below technote for published technote.\\n   \\n   http://www.ibm.com/support/docview.wss?uid=swg21992959 [http://www.ibm.com/support/docview.wss?uid=swg21992959]\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n\\nCOMMENTS\\n\\nAPAR INFORMATION\\n * APAR NUMBER\\n   IV85353\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   JAZZ SM TIP DAS\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5724C04JD\\n   \\n   \\n * REPORTED RELEASE\\n   110\\n   \\n   \\n * STATUS\\n   CLOSED PRS\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   NoHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt / Xsystem\\n   \\n   \\n * SUBMITTED DATE\\n   2016-06-05\\n   \\n   \\n * CLOSED DATE\\n   2016-10-26\\n   \\n   \\n * LAST MODIFIED DATE\\n   2016-10-26\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n\\nFIX INFORMATION\\n\\nAPPLICABLE COMPONENT LEVELS', 'jazzsm1130relnotes TECHNOTE (TROUBLESHOOTING)\\n\\nPROBLEM(ABSTRACT)\\n When upgrading Jazz for Service Management to Version 1.1.3.0 using Installation Manager, the installation fails with the following error:\\n\\nCannot run program \"/space/IBM/JazzSM/ui/bin/wrapper.sh\" (in directory \"/space/IBM/JazzSM/ui/bin\"): error=13, Permission denied [/space/IBM/JazzSM/install/tip/tipWrapp\\nerInstall.xml:215] \\n\\nCAUSE\\nDuring the upgrade process the non-root user does not have the correct permissions to run the shell script. This is due to the following:\\n1. Jazz for Service Management is installed as a non-root user\\n2. Installation Manager is installed in user mode through root user\\n\\n\\nRESOLVING THE PROBLEM\\nThe upgrade must be initiated by using the attached script, which gives the non-root user (who originally installed this Jazz for Service Management instance) the correct permissions for the upgrade process. \\n\\n\\nThe script takes two mandatory arguments and one optional argument.\\n\\nUsage: ./JazzSMgrpModeUpgrade.sh \"IM_Install_Location\" \\n\"JazzSM_Install_Location [http://www.ibm.com/support/knowledgecenter/SSEKCU_1.1.3.0/com.ibm.psc.doc/ref/psc_r_pathnames.html]\"\"[Response_file_with_absolute_Path]\"\\n\\nFor example (showing default installation paths): ./JazzSMgrpModeUpgrade.sh \"/home/root/IBM/InstallManager/\" \"/opt/IBM/JazzSM/\" \"/opt/Download/dash_upgrade_rsp.xml\"\\n\\n\\nFor IM GUI mode installation, provide the 2 mandatory arguments; IM_Install_Location and JazzSM_Install_Location. \\nThis argument combination invokes Installation Manager in GUI mode and lead you through the rest of the upgrade process.\\n\\nFor IM Silent installation, provide all 3 arguments; IM_Install_Location , JazzSM_Install_Location, and Response_file_with_absolute_Path.\\nThis argument combination invokes Installation Manager in silent mode to upgrade JazzSM.\\n\\nJazzSMgrpModeUpgrade.sh [/support/docview.wss?uid=swg21985946&aid=2]JazzSMgrpModeUpgrade.sh [/support/docview.wss?uid=swg21985946&aid=1]', ' SUBSCRIBE TO THIS APAR\\nBy subscribing, you receive periodic emails alerting you to the status of the APAR, along with a link to the fix after it becomes available. You can track this item individually or track all items by product.\\n\\nNotify me when this APAR changes.\\n\\nNotify me when an APAR for this component changes.\\n\\n\\n\\nAPAR STATUS\\n * CLOSED AS PROGRAM ERROR.\\n    \\n   \\n   \\n\\nERROR DESCRIPTION\\n *  When the user creats and clones widgets in rapid succession,\\n   sometimes we get a widget with incomplete data (the \"mode\" is\\n   missing, and should typically be \"view\").\\n   \\n   \\n    \\n   \\n   \\n\\nLOCAL FIX\\n *  When the javascript widget object is created, we now check that\\n   its mode exists, and if not go ahead and create it as\\n   mode=\"view\".\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM SUMMARY\\n *  ****************************************************************\\n   * USERS AFFECTED:                                              *\\n   * All Jazz for SM users                                        *\\n   ****************************************************************\\n   * PROBLEM DESCRIPTION:                                         *\\n   * DASH widget not able to load or save                         *\\n   ****************************************************************\\n   * RECOMMENDATION:                                              *\\n   * Fixed issue by provind fix as a part of DASH 3.1.2.1         *\\n   ****************************************************************\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM CONCLUSION\\n *  Fixed issue by provind fix as a part of DASH 3.1.2.1\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n\\nCOMMENTS\\n\\nAPAR INFORMATION\\n * APAR NUMBER\\n   IV74740\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   JAZZ SM TIP DAS\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5724C04JD\\n   \\n   \\n * REPORTED RELEASE\\n   110\\n   \\n   \\n * STATUS\\n   CLOSED PER\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   NoHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt\\n   \\n   \\n * SUBMITTED DATE\\n   2015-07-01\\n   \\n   \\n * CLOSED DATE\\n   2015-08-03\\n   \\n   \\n * LAST MODIFIED DATE\\n   2015-08-03\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n\\nMODULES/MACROS\\n *  RAVE\\n   \\n   \\n    \\n   \\n   \\n\\nFIX INFORMATION\\n * FIXED COMPONENT NAME\\n   JAZZ SM TIP DAS\\n   \\n   \\n * FIXED COMPONENT ID\\n   5724C04JD\\n   \\n   \\n\\nAPPLICABLE COMPONENT LEVELS\\n * R110 PSY\\n   UP']\n",
            "section_chunks>>>>>>> [['0a', ' SUBSCRIBE TO THIS APAR\\nBy subscribing, you receive periodic emails alerting you to the status of the APAR, along with a link to the fix after it becomes available.'], ['0b', 'You can track this item individually or track all items by product.'], ['0c', 'Notify me when this APAR changes.'], ['0d', 'Notify me when an APAR for this component changes.'], ['0e', 'APAR STATUS\\n * CLOSED AS PROGRAM ERROR.'], ['0f', 'ERROR DESCRIPTION\\n *  DASH menu hiding behind AEL in IE 11 Windows Server 2012 R2,\\n   Windows 2010\\n   \\n   Reproduced from DASH 3.1.1.x, DASH 3.1.2 including CP5 (WebGUI\\n   8.1 FP4).'], ['0g', 'to DASH 3.1.3.0 but NOT on DASH 3.1.0.3 (WebGUI\\n   8.1.0)\\n   \\n   Per WebGUI L3, there are no changes in AEL html from 8.1 to 8.1\\n   FP4.'], ['0h', 'LOCAL FIX\\n *  No workaround found.'], ['0i', 'PROBLEM SUMMARY\\n *  Please follow below link\\n   http://www-01.ibm.com/support/docview.wss?uid=swg22011801 [http://www-01.ibm.com/support/docview.wss?uid=swg22011801]\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM CONCLUSION\\n *  http://www-01.ibm.com/support/docview.wss?uid=swg22011801 [http://www-01.ibm.com/support/docview.wss?uid=swg22011801]\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n\\nCOMMENTS\\n\\nAPAR INFORMATION\\n * APAR NUMBER\\n   IV90226\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   JAZZ SM TIP DAS\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5724C04JD\\n   \\n   \\n * REPORTED RELEASE\\n   110\\n   \\n   \\n * STATUS\\n   CLOSED PER\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   NoHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt / Xsystem\\n   \\n   \\n * SUBMITTED DATE\\n   2016-10-26\\n   \\n   \\n * CLOSED DATE\\n   2017-12-26\\n   \\n   \\n * LAST MODIFIED DATE\\n   2017-12-26\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n\\nFIX INFORMATION\\n * FIXED COMPONENT NAME\\n   JAZZ SM TIP DAS\\n   \\n   \\n * FIXED COMPONENT ID\\n   5724C04JD\\n   \\n   \\n\\nAPPLICABLE COMPONENT LEVELS\\n * R110 PSY\\n   UP']]\n",
            "section_chunks>>>>>>> [['1a', 'jazzsm1120relnotes jazzsm1101relnotes jazzsm1102relnotes jazzsm1103relnotes jazzsm1110relnotes jazzsm1120relnotes DASH TECHNOTE (TROUBLESHOOTING)\\n\\nPROBLEM(ABSTRACT)\\n After rolling back an upgrade installation, the Dashboard Application Services Hub consolecli.sh command does not work on UNIX-based systems.'], ['1b', 'CAUSE\\nWhen you roll back a Jazz for Service Management upgrade installation, which includes Dashboard Application Service Hub, a path variable contained in consoleSetupEnv.sh is not updated with the actual path value.'], ['1c', 'ENVIRONMENT\\nUNIX-based systems\\n\\nRESOLVING THE PROBLEM\\nThis issue will be resolved with the release of Dashboard Application Services Hub Version 3.1.2.1, which will be delivered in Jazz for Service Management 1.1.2.1.'], ['1d', 'When rolling back from this release or later releases, the problem will not occur.'], ['1e', 'If you roll back and then upgrade again, the problem is resolved.'], ['1f', 'Alternatively, if you do not want to upgrade again to the new version, then to resolve the problem, do the following: \\n\\n 1.'], ['1g', 'Open consoleSetupEnv.sh in a text editor.'], ['1h', '2.'], ['1i', 'Locate the following line of code:\\n    TIP_HOME=@TIP_HOME@ \\n 3.'], ['1j', 'Replace the @TIP_HOME@ string with the actual path to the Dashboard Application Services Hub.'], ['1k', '4.'], ['1l', 'When you have completed your edits, the updated line would look similar to the following:\\n    TIP_HOME=/opt/IBM/JazzSM/ui \\n 5.'], ['1m', 'Save the updated consoleSetupEnv.sh.']]\n",
            "section_chunks>>>>>>> [['2a', ' SUBSCRIBE\\nYou can track all active APARs for this component.'], ['2b', 'APAR STATUS\\n * CLOSED AS PERMANENT RESTRICTION.'], ['2c', 'ERROR DESCRIPTION\\n *  Issue on Rave Line Chart (Dash 3.1.2.1).'], ['2d', 'All ascending\\n   and\\n   descending option is not working.'], ['2e', 'For example\\n   \\n   \\n   Rave Line Chart released in Dash 3.1.2.1 is showing dates from\\n   18th May\\n   to 31st May then 1st and 2nd June.'], ['2f', 'Client is not accepting this\\n   format when descending\\n   it should be like from 2nd June, 1st June, 31st May, 30th, May,\\n   29th May\\n   and so on.'], ['2g', 'Data Model is showing descending order:\\n   \\n   \\n    \\n   \\n   \\n\\nLOCAL FIX\\n *  Change the date data type as varchar/string, which is not\\n   acceptable by all customer\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM SUMMARY\\n *  THis is the limitation with Rave feature.'], ['2h', 'Also Rave is not in\\n   support.'], ['2i', 'As alternative workaround is suggested in the published technote\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM CONCLUSION\\n *  Please check below technote for published technote.'], ['2j', 'http://www.ibm.com/support/docview.wss?uid=swg21992959 [http://www.ibm.com/support/docview.wss?uid=swg21992959]\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n\\nCOMMENTS\\n\\nAPAR INFORMATION\\n * APAR NUMBER\\n   IV85353\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   JAZZ SM TIP DAS\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5724C04JD\\n   \\n   \\n * REPORTED RELEASE\\n   110\\n   \\n   \\n * STATUS\\n   CLOSED PRS\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   NoHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt / Xsystem\\n   \\n   \\n * SUBMITTED DATE\\n   2016-06-05\\n   \\n   \\n * CLOSED DATE\\n   2016-10-26\\n   \\n   \\n * LAST MODIFIED DATE\\n   2016-10-26\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n\\nFIX INFORMATION\\n\\nAPPLICABLE COMPONENT LEVELS']]\n",
            "section_chunks>>>>>>> [['3a', 'jazzsm1130relnotes TECHNOTE (TROUBLESHOOTING)\\n\\nPROBLEM(ABSTRACT)\\n When upgrading Jazz for Service Management to Version 1.1.3.0 using Installation Manager, the installation fails with the following error:\\n\\nCannot run program \"/space/IBM/JazzSM/ui/bin/wrapper.sh\" (in directory \"/space/IBM/JazzSM/ui/bin\"): error=13, Permission denied [/space/IBM/JazzSM/install/tip/tipWrapp\\nerInstall.xml:215] \\n\\nCAUSE\\nDuring the upgrade process the non-root user does not have the correct permissions to run the shell script.'], ['3b', 'This is due to the following:\\n1.'], ['3c', 'Jazz for Service Management is installed as a non-root user\\n2.'], ['3d', 'Installation Manager is installed in user mode through root user\\n\\n\\nRESOLVING THE PROBLEM\\nThe upgrade must be initiated by using the attached script, which gives the non-root user (who originally installed this Jazz for Service Management instance) the correct permissions for the upgrade process.'], ['3e', 'The script takes two mandatory arguments and one optional argument.'], ['3f', 'Usage: ./JazzSMgrpModeUpgrade.sh \"IM_Install_Location\" \\n\"JazzSM_Install_Location [http://www.ibm.com/support/knowledgecenter/SSEKCU_1.1.3.0/com.ibm.psc.doc/ref/psc_r_pathnames.html]\"\"[Response_file_with_absolute_Path]\"\\n\\nFor example (showing default installation paths): ./JazzSMgrpModeUpgrade.sh \"/home/root/IBM/InstallManager/\" \"/opt/IBM/JazzSM/\" \"/opt/Download/dash_upgrade_rsp.xml\"\\n\\n\\nFor IM GUI mode installation, provide the 2 mandatory arguments; IM_Install_Location and JazzSM_Install_Location.'], ['3g', 'This argument combination invokes Installation Manager in GUI mode and lead you through the rest of the upgrade process.'], ['3h', 'For IM Silent installation, provide all 3 arguments; IM_Install_Location , JazzSM_Install_Location, and Response_file_with_absolute_Path.'], ['3i', 'This argument combination invokes Installation Manager in silent mode to upgrade JazzSM.'], ['3j', 'JazzSMgrpModeUpgrade.sh [/support/docview.wss?uid=swg21985946&aid=2]JazzSMgrpModeUpgrade.sh [/support/docview.wss?uid=swg21985946&aid=1]']]\n",
            "section_chunks>>>>>>> [['4a', ' SUBSCRIBE TO THIS APAR\\nBy subscribing, you receive periodic emails alerting you to the status of the APAR, along with a link to the fix after it becomes available.'], ['4b', 'You can track this item individually or track all items by product.'], ['4c', 'Notify me when this APAR changes.'], ['4d', 'Notify me when an APAR for this component changes.'], ['4e', 'APAR STATUS\\n * CLOSED AS PROGRAM ERROR.'], ['4f', 'ERROR DESCRIPTION\\n *  When the user creats and clones widgets in rapid succession,\\n   sometimes we get a widget with incomplete data (the \"mode\" is\\n   missing, and should typically be \"view\").'], ['4g', 'LOCAL FIX\\n *  When the javascript widget object is created, we now check that\\n   its mode exists, and if not go ahead and create it as\\n   mode=\"view\".'], ['4h', 'PROBLEM SUMMARY\\n *  ****************************************************************\\n   * USERS AFFECTED:                                              *\\n   * All Jazz for SM users                                        *\\n   ****************************************************************\\n   * PROBLEM DESCRIPTION:                                         *\\n   * DASH widget not able to load or save                         *\\n   ****************************************************************\\n   * RECOMMENDATION:                                              *\\n   * Fixed issue by provind fix as a part of DASH 3.1.2.1         *\\n   ****************************************************************\\n   \\n   \\n    \\n   \\n   \\n\\nPROBLEM CONCLUSION\\n *  Fixed issue by provind fix as a part of DASH 3.1.2.1\\n   \\n   \\n    \\n   \\n   \\n\\nTEMPORARY FIX\\n\\nCOMMENTS\\n\\nAPAR INFORMATION\\n * APAR NUMBER\\n   IV74740\\n   \\n   \\n * REPORTED COMPONENT NAME\\n   JAZZ SM TIP DAS\\n   \\n   \\n * REPORTED COMPONENT ID\\n   5724C04JD\\n   \\n   \\n * REPORTED RELEASE\\n   110\\n   \\n   \\n * STATUS\\n   CLOSED PER\\n   \\n   \\n * PE\\n   NoPE\\n   \\n   \\n * HIPER\\n   NoHIPER\\n   \\n   \\n * SPECIAL ATTENTION\\n   NoSpecatt\\n   \\n   \\n * SUBMITTED DATE\\n   2015-07-01\\n   \\n   \\n * CLOSED DATE\\n   2015-08-03\\n   \\n   \\n * LAST MODIFIED DATE\\n   2015-08-03\\n   \\n   \\n\\n * APAR IS SYSROUTED FROM ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n * APAR IS SYSROUTED TO ONE OR MORE OF THE FOLLOWING:\\n   \\n   \\n   \\n\\nMODULES/MACROS\\n *  RAVE\\n   \\n   \\n    \\n   \\n   \\n\\nFIX INFORMATION\\n * FIXED COMPONENT NAME\\n   JAZZ SM TIP DAS\\n   \\n   \\n * FIXED COMPONENT ID\\n   5724C04JD\\n   \\n   \\n\\nAPPLICABLE COMPONENT LEVELS\\n * R110 PSY\\n   UP']]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "624381b929444c309b853f19975cf29a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating embeddings: 100%|| 1/1 [00:03<00:00,  3.67s/it]\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "\n",
        "#datasets = ['pubmedqa','tatqa', 'techqa'] # d4\n",
        "\n",
        "datasets = ['techqa']\n",
        "\n",
        "# Initialize storage for documents, IDs, and metadata\n",
        "all_documents = []\n",
        "all_ids = []\n",
        "all_metadatas = []\n",
        "\n",
        "# Process each dataset\n",
        "doc_idx = 0  # Global document index for unique IDs\n",
        "for dataset in datasets:\n",
        "    data = load_dataset(\"rungalileo/ragbench\", dataset, split=\"train\")\n",
        "    #only select first 5 records for debugging duplicate records. **PLEASE REMOVE THIS AFTER DEBUGGING**\n",
        "    data = data.select(range(2))\n",
        "    for idx, row in tqdm(enumerate(data), desc=f\"Processing {dataset}\"):\n",
        "        # Extract document text\n",
        "        doc_text = row.get('documents', '')\n",
        "\n",
        "        # Skip if no documents found\n",
        "        if not doc_text:\n",
        "            continue\n",
        "\n",
        "        # Process the document\n",
        "        processed_output = process_document_with_identifiers(doc_text)\n",
        "        added_item_idxs = set()\n",
        "\n",
        "        # Populate the lists\n",
        "        for section_idx, section in enumerate(processed_output):\n",
        "            for item_idx, (prefix, content) in enumerate(section):\n",
        "                # Skip if this item_idx has already been processed\n",
        "                if item_idx in added_item_idxs:\n",
        "                    continue\n",
        "\n",
        "                # Add the item_idx to the set to track it\n",
        "                added_item_idxs.add(item_idx)\n",
        "\n",
        "                # Add the document\n",
        "                document = f\"[{prefix}] {content}\"\n",
        "                all_documents.append(document)\n",
        "\n",
        "                # Construct a globally unique ID\n",
        "                doc_id = f\"{dataset}_{doc_idx}_{section_idx}_{item_idx}\"\n",
        "                all_ids.append(doc_id)\n",
        "\n",
        "                # Construct metadata\n",
        "                metadata = {\n",
        "                    \"dataset\": dataset,\n",
        "                    \"global_index\": doc_idx,\n",
        "                    \"section_index\": section_idx,\n",
        "                    \"item_index\": item_idx,\n",
        "                    \"prefix\": prefix,\n",
        "                    \"type\": \"Title\" if prefix.endswith(\"a\") else \"Passage\",\n",
        "                }\n",
        "                all_metadatas.append(metadata)\n",
        "\n",
        "        doc_idx += 1  # Increment global document index\n",
        "\n",
        "# Step 4: Generate Embeddings\n",
        "#embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Pretrained sentence transformer\n",
        "embedder = SentenceTransformer(\"BAAI/LLM-Embedder\")  # Pretrained sentence transformer\n",
        "batch_size = 2500  # Adjust based on available memory\n",
        "\n",
        "# Generate embeddings in batches\n",
        "all_embeddings = []\n",
        "for i in tqdm(range(0, len(all_documents), batch_size), desc=\"Generating embeddings\"):\n",
        "    batch_docs = all_documents[i:i + batch_size]\n",
        "    batch_embeddings = embedder.encode(batch_docs, show_progress_bar=True)\n",
        "    all_embeddings.extend(batch_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98sCkvuELmm9"
      },
      "source": [
        "## **Store Embeddings into Milvus**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRKztXe6MQsR",
        "outputId": "20d87c9f-1b81-4164-b99d-400530daca90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymilvus in /usr/local/lib/python3.10/dist-packages (2.5.2)\n",
            "Requirement already satisfied: setuptools>69 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (75.1.0)\n",
            "Requirement already satisfied: grpcio<=1.67.1,>=1.49.1 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (1.67.1)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (5.29.2)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (1.0.1)\n",
            "Requirement already satisfied: ujson>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (5.10.0)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (2.2.2)\n",
            "Requirement already satisfied: milvus-lite>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (2.4.10)\n",
            "Requirement already satisfied: milvus-model>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus[model]) (0.2.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from milvus-lite>=2.4.0->pymilvus) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.36.0 in /usr/local/lib/python3.10/dist-packages (from milvus-model>=0.1.0->pymilvus[model]) (4.47.1)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (from milvus-model>=0.1.0->pymilvus[model]) (1.20.1)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from milvus-model>=0.1.0->pymilvus[model]) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from milvus-model>=0.1.0->pymilvus[model]) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (0.27.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (0.4.5)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime->milvus-model>=0.1.0->pymilvus[model]) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime->milvus-model>=0.1.0->pymilvus[model]) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime->milvus-model>=0.1.0->pymilvus[model]) (1.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (4.12.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime->milvus-model>=0.1.0->pymilvus[model]) (10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2024.12.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime->milvus-model>=0.1.0->pymilvus[model]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymilvus pymilvus[model]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SONQYc_teisO"
      },
      "source": [
        "# **Functions to check uniqueness of data being inserted to db**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yt80i3bjeisO"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "\n",
        "# Function to generate a hash based on content and key metadata\n",
        "def generate_hash(content, metadata):\n",
        "    \"\"\"Generate a unique hash for the document content and key metadata.\"\"\"\n",
        "    key_fields = f\"{content}|{metadata.get('item_index')}|{metadata.get('prefix')}\"\n",
        "    return hashlib.md5(key_fields.encode('utf-8')).hexdigest()\n",
        "\n",
        "# Function to retrieve existing hashes from the database\n",
        "def get_existing_hashes(collection):\n",
        "    \"\"\"Retrieve all existing hashes (IDs) currently in the database.\"\"\"\n",
        "    all_records = collection.get(include=[\"documents\", \"metadatas\"])  # Fetch documents and metadata\n",
        "    existing_hashes = set()\n",
        "    for doc, metadata in zip(all_records[\"documents\"], all_records[\"metadatas\"]):\n",
        "        doc_hash = generate_hash(doc, metadata)\n",
        "        existing_hashes.add(doc_hash)\n",
        "    return existing_hashes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uXpX60a5LyGG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pymilvus import connections\n",
        "from pymilvus import FieldSchema, CollectionSchema, DataType, Collection\n",
        "from pymilvus import MilvusClient\n",
        "from pymilvus import utility\n",
        "\n",
        "class VectorDataStore:\n",
        "    db_url = \"http://localhost:19530\"\n",
        "    #description = f\"collection created for {self.name}\"\n",
        "\n",
        "    def __init__(self, path=\"/content/ragbench.db\"):\n",
        "        self.client = MilvusClient(path)\n",
        "\n",
        "\n",
        "\n",
        "    def create_collection(self, name, vec_dim=128):\n",
        "        if self.client.has_collection(name):\n",
        "            self.default_collection_name = name\n",
        "\n",
        "        self.description = f\"collection to store {name}\"\n",
        "\n",
        "        index_params = self.client.prepare_index_params()\n",
        "        index_params.add_index(\n",
        "            field_name=\"embedding\",\n",
        "            index_type=\"AUTOINDEX\",\n",
        "            metric_type=\"COSINE\"\n",
        "        )\n",
        "        schema = self.client.create_schema(\n",
        "            auto_id=False,\n",
        "            enable_dynamic_fields=True,\n",
        "        )\n",
        "        schema.add_field(field_name=\"pk\", datatype=DataType.VARCHAR, max_length=64, is_primary=True)\n",
        "        schema.add_field(field_name=\"metadata\", datatype=DataType.JSON)\n",
        "        schema.add_field(field_name=\"documents\", datatype=DataType.VARCHAR, max_length=512)\n",
        "        schema.add_field(field_name=\"embedding\", datatype=DataType.FLOAT_VECTOR, dim=vec_dim)\n",
        "\n",
        "        collection = self.client.create_collection(collection_name=name,\n",
        "                                       schema=schema,\n",
        "                                       index_params=index_params)\n",
        "        self.current_collection = collection\n",
        "        return collection\n",
        "\n",
        "\n",
        "    def get_collection(self, name):\n",
        "        if not self.client.has_collection(name):\n",
        "            raise ValueError(f\"Collection '{name}' does not exist.\")\n",
        "        self.current_collection = Collection(name)\n",
        "        return self.current_collection\n",
        "\n",
        "    def get_all_records(self, collection):\n",
        "        self.client.query(\n",
        "            collection_name=collection,\n",
        "            filter=\"1 == 1\",\n",
        "            output_fields=[\"documents\", \"metadata\"],\n",
        "        )\n",
        "\n",
        "    def has_entities(self, name):\n",
        "        if not self.client.has_collection(name):\n",
        "            raise ValueError(f\"Collection '{name}' does not exists.\")\n",
        "        self.default_collection = name\n",
        "        collection_stats = self.client.get_collection_stats(collection_name)\n",
        "        count = collection_stats.get(\"row_count\", 0)  # Retrieve the number of entities\n",
        "        return count\n",
        "\n",
        "    def insert(self, collection_name: str, metadata: list[dict[str, any]],\n",
        "                documents: list[str], embeddings: np.ndarray, ids: list[int]):\n",
        "\n",
        "        if not self.client.has_collection(collection_name):\n",
        "            raise ValueError(f\"Collection '{collection_name}' does not exist. Create it first.\")\n",
        "\n",
        "        if len(metadata) != len(embeddings) != len(documents) != len(ids):\n",
        "           raise ValueError(\"Metadata, documnets, ids and embeddings must have the same length.\")\n",
        "\n",
        "        data = []\n",
        "        for meta, doc, emb, id in zip(metadata, documents, embeddings, ids):\n",
        "          datum = {\n",
        "              \"pk\": id,\n",
        "              \"metadata\": meta,\n",
        "              \"documents\": doc,\n",
        "              \"embedding\": emb.tolist(),\n",
        "          }\n",
        "          data.append(datum)\n",
        "\n",
        "        self.client.insert(collection_name, data)\n",
        "        print(f\"Inserted {len(metadata)} records into collection '{collection_name}'.\")\n",
        "\n",
        "    def drop_collection(self, collection_name: str):\n",
        "        if not self.client.has_collection(collection_name):\n",
        "            raise ValueError(f\"Collection '{collection_name}' does not exist.\")\n",
        "        self.client.drop_collection(collection_name)\n",
        "        print(f\"Dropped collection '{collection_name}'.\")\n",
        "\n",
        "    def delete_all(self, collection_name: str):\n",
        "        if not self.client.has_collection(collection_name):\n",
        "            raise ValueError(f\"Collection '{collection_name}' does not exist.\")\n",
        "        self.client.delete(collection_name, expr=\"pk >= 0\")\n",
        "        self.client.flush([collection_name])\n",
        "\n",
        "    def search(self, query_embedding: np.ndarray, top_k: int = 10) -> list[dict[str, any]]:\n",
        "        \"\"\"\n",
        "        Search across all collections for the top-k closest embeddings.\n",
        "        :param query_embedding: The embedding vector to search for.\n",
        "        :param top_k: Number of top results to retrieve.\n",
        "        :return: A list of dictionaries containing collection name, id, metadata, and distance.\n",
        "        \"\"\"\n",
        "        results = []\n",
        "        #collections = self.client.list_collections()\n",
        "        collections = [\"ragbench_collection_techqa_v09\"]\n",
        "        start_time = time.time()\n",
        "        for collection_name in collections:\n",
        "            if not self.client.has_collection(collection_name):\n",
        "                continue\n",
        "\n",
        "            # Set params to COSINE to match chromadb\n",
        "            search_params = {\"metric_type\": \"COSINE\", \"params\": {\"ef\": 128}}\n",
        "\n",
        "            search_results = self.client.search(\n",
        "                collection_name=collection_name,\n",
        "                data=[query_embedding],\n",
        "                anns_field=\"embedding\",\n",
        "                search_params=search_params,\n",
        "                limit=top_k,\n",
        "                output_fields=[\"metadata\", \"documents\"]\n",
        "            )\n",
        "\n",
        "            for hits in search_results:\n",
        "                for hit in hits:\n",
        "                    print(f\"Collection: {collection_name}, data: {str(hit)}\")\n",
        "                    results.append({\n",
        "                        \"collection\": collection_name,\n",
        "                        \"id\": hit[\"id\"],\n",
        "                        \"metadata\": hit[\"entity\"][\"metadata\"],\n",
        "                        \"distance\": hit[\"distance\"],\n",
        "                        \"documents\": hit[\"entity\"][\"documents\"]\n",
        "                      })\n",
        "\n",
        "        results = sorted(results, key=lambda x: x[\"distance\"])[:top_k]\n",
        "        end_time = time.time()\n",
        "        print(f\"Search completed. Found {len(results)} results. in {end_time - start_time} secs\")\n",
        "        return results\n",
        "\n",
        "    def extract_documents(self, search_results: list[dict[str, any]]) -> list[np.ndarray]:\n",
        "      \"\"\"\n",
        "      Extract embedding values from search results.\n",
        "      :param search_results: List of dictionaries containing search results.\n",
        "      :return: List of embedding vectors as NumPy arrays.\n",
        "      \"\"\"\n",
        "      return [np.array(result[\"documents\"]) for result in search_results if \"documents\" in result]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cULX75ApDqG-"
      },
      "source": [
        "## **Instantiate Milvus and add data to milvus db**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collection_name = \"ragbench_collection_techqa_v01\""
      ],
      "metadata": {
        "id": "a8t1l69JhPQ9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1-pYgIR8DpVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99e3948f-2efa-4bb9-bf37-f0c1f050ffae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count >>> 0 insert_data >>> True\n"
          ]
        }
      ],
      "source": [
        "datastor = VectorDataStore()\n",
        "\n",
        "insert_data = False\n",
        "store_client = \"Milvus\"\n",
        "num_records = 0\n",
        "\n",
        "if datastor.client.has_collection(collection_name):\n",
        "  num_records = datastor.has_entities(collection_name)\n",
        "  if num_records == 0:\n",
        "    insert_data = True\n",
        "else:\n",
        "  datastor.create_collection(collection_name, embedder.get_sentence_embedding_dimension())\n",
        "  insert_data = True\n",
        "\n",
        "print(f\"count >>> {num_records} insert_data >>> {insert_data}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13tCDq080UJx"
      },
      "source": [
        "# **Store Embeddings into a chroma DB and Milvus**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "BWQikq5mPehv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5932578-ab02-4b55-95c5-6622e610c04e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.10.3)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.7.4-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.29.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.29.0)\n",
            "Collecting tokenizers<=0.20.3,>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.68.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.12)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.27.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb) (0.27.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (2024.9.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.7.4-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=940699d8ee35135c48da77d392905bbdc14afee91fea19e9c9357389615a7774\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, coloredlogs, build, tokenizers, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.23 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.6 httptools-0.6.4 humanfriendly-10.0 kubernetes-31.0.0 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-instrumentation-0.50b0 opentelemetry-instrumentation-asgi-0.50b0 opentelemetry-instrumentation-fastapi-0.50b0 opentelemetry-proto-1.29.0 opentelemetry-util-http-0.50b0 overrides-7.7.0 posthog-3.7.4 protobuf-5.29.2 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.41.3 tokenizers-0.20.3 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUSdzcRo2_dR",
        "outputId": "3a8a8bec-7f07-425e-c22c-a016e3738020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count >>> 0\n"
          ]
        }
      ],
      "source": [
        "import chromadb\n",
        "\n",
        "client = chromadb.PersistentClient(path=\"./content/rag_chroma_db_d4\")\n",
        "\n",
        "# chromba_db_collection_name = \"ragbench_chroma_db_collection_techqa_v21\"\n",
        "chroma_db_collection = client.get_or_create_collection(name=collection_name)\n",
        "\n",
        "count = chroma_db_collection.count()\n",
        "print(\"count >>>\", count)\n",
        "store_client = \"Chromadb\"\n",
        "\n",
        "if count > 0:\n",
        "    insert_data = False\n",
        "else:\n",
        "    insert_data = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHlsh92reisR"
      },
      "source": [
        "## **Insert data into data base**\n",
        "### the store_client value stores if the code should call milvus or chromadb code\n",
        "#### if insert_data is set to true it means there is no data in the collection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmI_CeZaeisR",
        "outputId": "c7c27b02-5048-42fb-bedf-a70054ea5e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Adding data to DB: 100%|| 1/1 [00:00<00:00, 10.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding 65 documents to the database... Chromadb with True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Adding data to ChromaDB with enhanced duplicate check\n",
        "existing_hashes = get_existing_hashes(chroma_db_collection)\n",
        "\n",
        "for i in tqdm(range(0, len(all_documents), batch_size), desc=\"Adding data to DB\"):\n",
        "    batch_embeddings = all_embeddings[i:i + batch_size]\n",
        "    batch_metadatas = all_metadatas[i:i + batch_size]\n",
        "    batch_documents = all_documents[i:i + batch_size]\n",
        "    batch_ids = []\n",
        "\n",
        "    # Generate hashes for each document in the batch\n",
        "    for doc, metadata in zip(batch_documents, batch_metadatas):\n",
        "        doc_hash = generate_hash(doc, metadata)\n",
        "        if doc_hash not in existing_hashes:\n",
        "            batch_ids.append(doc_hash)\n",
        "            existing_hashes.add(doc_hash)  # Add hash to local set to avoid duplicates in the same batch\n",
        "        else:\n",
        "            print(f\"Skipping duplicate document: {doc[:50]}...\")  # Print a preview of the duplicate doc\n",
        "\n",
        "    # Add non-duplicate documents to the database\n",
        "    if batch_ids:  # Ensure there are non-duplicate documents to add\n",
        "        print(f\"Adding {len(batch_ids)} documents to the database... {store_client} with {insert_data}\")\n",
        "        if store_client == \"Chromadb\" and insert_data:\n",
        "            chroma_db_collection.add(\n",
        "                embeddings=batch_embeddings[:len(batch_ids)],  # Trim embeddings to match batch_ids\n",
        "                metadatas=batch_metadatas[:len(batch_ids)],    # Trim metadatas to match batch_ids\n",
        "                documents=batch_documents[:len(batch_ids)],    # Trim documents to match batch_ids\n",
        "                ids=batch_ids\n",
        "            )\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS8gN3oAeisR"
      },
      "source": [
        "# **Insert data to milvus**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "dfNYPJSxeisS",
        "outputId": "ce6caa1b-71c8-4619-984d-f18290144800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-12-28 19:10:23,161 [ERROR][handler]: RPC error: [query], <MilvusException: (code=1100, message=empty expression should be used with limit: invalid parameter)>, <Time:{'RPC start': '2024-12-28 19:10:23.158421', 'RPC error': '2024-12-28 19:10:23.161837'}> (decorators.py:140)\n",
            "2024-12-28 19:10:23,163 [ERROR][query]: Failed to query collection: ragbench_collection_techqa_v01 (milvus_client.py:483)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "MilvusException",
          "evalue": "<MilvusException: (code=1100, message=empty expression should be used with limit: invalid parameter)>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMilvusException\u001b[0m                           Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-9cded1865614>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Adding data to ChromaDB with enhanced duplicate check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexisting_hashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatastor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b7d51774ff26>\u001b[0m in \u001b[0;36mget_all_records\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_all_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         self.client.query(\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/milvus_client/milvus_client.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, collection_name, filter, output_fields, timeout, ids, partition_names, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to query collection: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/milvus_client/milvus_client.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, collection_name, filter, output_fields, timeout, ids, partition_names, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             res = conn.query(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mcollection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/decorators.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"RPC error: [{inner_name}], {e}, <Time:{record_dict}>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFutureTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/decorators.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mrecord_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"RPC start\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mMilvusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/decorators.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_onetime_request_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/decorators.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/decorators.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/client/grpc_handler.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, collection_name, expr, output_fields, partition_names, timeout, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m         \u001b[0mcheck_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/client/utils.py\u001b[0m in \u001b[0;36mcheck_status\u001b[0;34m(status)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMilvusException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMilvusException\u001b[0m: <MilvusException: (code=1100, message=empty expression should be used with limit: invalid parameter)>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mMilvusException\u001b[0m                           Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-9cded1865614>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Adding data to ChromaDB with enhanced duplicate check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexisting_hashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatastor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b7d51774ff26>\u001b[0m in \u001b[0;36mget_all_records\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_all_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         self.client.query(\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/milvus_client/milvus_client.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, collection_name, filter, output_fields, timeout, ids, partition_names, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to query collection: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/milvus_client/milvus_client.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, collection_name, filter, output_fields, timeout, ids, partition_names, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             res = conn.query(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mcollection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/decorators.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"RPC error: [{inner_name}], {e}, <Time:{record_dict}>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFutureTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/decorators.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mrecord_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"RPC start\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mMilvusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/decorators.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_onetime_request_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/decorators.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/decorators.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/client/grpc_handler.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, collection_name, expr, output_fields, partition_names, timeout, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m         \u001b[0mcheck_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/client/utils.py\u001b[0m in \u001b[0;36mcheck_status\u001b[0;34m(status)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMilvusException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMilvusException\u001b[0m: <MilvusException: (code=1100, message=empty expression should be used with limit: invalid parameter)>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mMilvusException\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-9cded1865614>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Adding data to ChromaDB with enhanced duplicate check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexisting_hashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatastor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Adding data to DB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b7d51774ff26>\u001b[0m in \u001b[0;36mget_all_records\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_all_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         self.client.query(\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/milvus_client/milvus_client.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, collection_name, filter, output_fields, timeout, ids, partition_names, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to query collection: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/milvus_client/milvus_client.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, collection_name, filter, output_fields, timeout, ids, partition_names, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             res = conn.query(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mcollection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mexpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/decorators.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mrecord_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"RPC error\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"RPC error: [{inner_name}], {e}, <Time:{record_dict}>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFutureTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mrecord_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gRPC timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/decorators.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mrecord_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"RPC start\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mMilvusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mrecord_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"RPC error\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/decorators.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreq_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_onetime_request_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/decorators.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m                         \u001b[0mback_off\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mback_off\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mback_off_multiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_back_off\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/decorators.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0;31m# Do not retry on these codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/client/grpc_handler.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, collection_name, expr, output_fields, partition_names, timeout, **kwargs)\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEMPTY_COLLECTION\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m         \u001b[0mcheck_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m         \u001b[0mnum_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymilvus/client/utils.py\u001b[0m in \u001b[0;36mcheck_status\u001b[0;34m(status)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mStatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMilvusException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMilvusException\u001b[0m: <MilvusException: (code=1100, message=empty expression should be used with limit: invalid parameter)>"
          ]
        }
      ],
      "source": [
        "# Adding data to ChromaDB with enhanced duplicate check\n",
        "existing_hashes = datastor.get_all_records(collection_name)\n",
        "\n",
        "for i in tqdm(range(0, len(all_documents), batch_size), desc=\"Adding data to DB\"):\n",
        "    batch_embeddings = all_embeddings[i:i + batch_size]\n",
        "    batch_metadatas = all_metadatas[i:i + batch_size]\n",
        "    batch_documents = all_documents[i:i + batch_size]\n",
        "    batch_ids = []\n",
        "\n",
        "    # Generate hashes for each document in the batch\n",
        "    for doc, metadata in zip(batch_documents, batch_metadatas):\n",
        "        doc_hash = generate_hash(doc, metadata)\n",
        "        if doc_hash not in existing_hashes:\n",
        "            batch_ids.append(doc_hash)\n",
        "            existing_hashes.add(doc_hash)  # Add hash to local set to avoid duplicates in the same batch\n",
        "        else:\n",
        "            print(f\"Skipping duplicate document: {doc[:50]}...\")  # Print a preview of the duplicate doc\n",
        "\n",
        "    # Add non-duplicate documents to the database\n",
        "    if batch_ids:  # Ensure there are non-duplicate documents to add\n",
        "        # Add the batch to the Milvus collection\n",
        "        if store_client == \"Milvus\" and insert_data:\n",
        "            datastor.insert(collection_name,\n",
        "                metadata=batch_metadatas,\n",
        "                documents=batch_documents,\n",
        "                embeddings=np.array(batch_embeddings),\n",
        "                ids=batch_ids\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcnwZToNE0Y2"
      },
      "source": [
        "## **Verifying retrival logic for the Relevant documents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oKJMfU1aZPFX",
        "outputId": "3aee0306-20b0-49ca-84dd-749f9e055626"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChromaDB - Search completed. Found 8 results. in 0.004831552505493164 secs\n",
            "Result 1:\n",
            "  Document: [0b] Your WebSphere MQ queue manager fails to come up on the secondary node, and errors are generated.\n",
            "  ID: 3683bbefd68a3161c00c001f3e58b2d2\n",
            "  Metadata: {'dataset': 'techqa', 'global_index': 0, 'item_index': 1, 'prefix': '0b', 'section_index': 0, 'type': 'Passage'}\n",
            "\n",
            "Result 2:\n",
            "  Document: [0d] RESOLVING THE PROBLEM\n",
            "Rename the file amqalchk.fil, which is found under mq\\qmgrs\\qmgrname\\ on the shared drive (to something like amqalchk.fil_OLD); then restart the queue manager.\n",
            "  ID: 5bb2a66f88c5070dd0f5d37785e3a748\n",
            "  Metadata: {'dataset': 'techqa', 'global_index': 0, 'item_index': 3, 'prefix': '0d', 'section_index': 0, 'type': 'Passage'}\n",
            "\n",
            "Result 3:\n",
            "  Document: [0a] HL083112 mqlpgrlg ZX000001 ExecCtrlrMain lpiRC_LOG_NOT_AVAILABLE mscs TECHNOTE (TROUBLESHOOTING)\n",
            "\n",
            "PROBLEM(ABSTRACT)\n",
            " You attempt to failover from the primary to secondary node under MSCS.\n",
            "  ID: c2b5c816355deb079e4290bd60b23860\n",
            "  Metadata: {'dataset': 'techqa', 'global_index': 0, 'item_index': 0, 'prefix': '0a', 'section_index': 0, 'type': 'Title'}\n",
            "\n",
            "Result 4:\n",
            "  Document: [1j] PROBLEM SUMMARY\n",
            " *  ****************************************************************\n",
            "   * USERS AFFECTED:                                              *\n",
            "   * Users with an HDR pair that is an ER participant             *\n",
            "   ****************************************************************\n",
            "   * PROBLEM DESCRIPTION:                                         *\n",
            "   * After failover, the primary shows online mode but the        *\n",
            "   * clients are not able to connect to the server.\n",
            "  ID: 8eb8cb34cf1ab14206438ad4f24b28ba\n",
            "  Metadata: {'dataset': 'techqa', 'global_index': 0, 'item_index': 9, 'prefix': '1j', 'section_index': 1, 'type': 'Passage'}\n",
            "\n",
            "Result 5:\n",
            "  Document: [1h] If the mode is not set until after ER has finished\n",
            "   syncing and connections are accepted or a new return value is\n",
            "   used to indicate that the instance is on-line and accepting\n",
            "   connections this would resolve the problem.\n",
            "  ID: 544e7d361d707762fb5692e2db83b574\n",
            "  Metadata: {'dataset': 'techqa', 'global_index': 0, 'item_index': 7, 'prefix': '1h', 'section_index': 1, 'type': 'Passage'}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Retrieve from Chroma DB\n",
        "import time\n",
        "\n",
        "question =\"Why does the other instance of my multi-instance qmgr seem to hang after a failover? Queue manager will not start after failover\"\n",
        "query_embedding = embedder.encode(question).tolist()\n",
        "\n",
        "# Search for relevant chunks in the vector database\n",
        "# Retrieve from ChromaDB\n",
        "start_time = time.time()\n",
        "results_chroma_db = chroma_db_collection.query(query_embeddings=[query_embedding], n_results=5)\n",
        "end_time = time.time()\n",
        "print(f\"ChromaDB - Search completed. Found {len(results_chroma_db)} results. in {end_time - start_time} secs\")\n",
        "\n",
        "for idx, (doc, doc_id, metadata) in enumerate(zip(results_chroma_db[\"documents\"][0], results_chroma_db[\"ids\"][0], results_chroma_db[\"metadatas\"][0])):\n",
        "    print(f\"Result {idx + 1}:\")\n",
        "    print(f\"  Document: {doc}\")\n",
        "    print(f\"  ID: {doc_id}\")\n",
        "    print(f\"  Metadata: {metadata}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgIjDq9peisT"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "question =\"Why does the other instance of my multi-instance qmgr seem to hang after a failover? Queue manager will not start after failover\"\n",
        "query_embedding = embedder.encode(question).tolist()\n",
        "\n",
        "# Retrieve from Milvus\n",
        "start_time = time.time()\n",
        "results_milvus = datastor.search(query_embedding, top_k=5)\n",
        "end_time = time.time()\n",
        "print(f\"Search completed. Found {len(results_milvus)} results. in {end_time - start_time} secs\")\n",
        "\n",
        "for doc in results_milvus:\n",
        "    print(\"Relevant Docs from Milvus:\\n\", doc['documents'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrOo-DUGFZ17"
      },
      "source": [
        "## **Retrival of Relevant Chunks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HZA8J-mhNEz"
      },
      "outputs": [],
      "source": [
        "# Function to retrieve relevant chunks\n",
        "def retrieve_docs_milvus(query, top_k=5):\n",
        "    # Generate embedding for the query\n",
        "    query_embedding = embedder.encode(query).tolist()\n",
        "    # Perform vector search to find relevant chunks\n",
        "    #results = datastor.extract_documents(datastor.search(query_embedding, top_k))\n",
        "    results = datastor.search(query_embedding, top_k)\n",
        "    print(f\"results: retrieve_docs_milvus >>>  {results}\")\n",
        "\n",
        "    # Extract 'documents' field\n",
        "    documents_list = [item['documents'] for item in results]\n",
        "\n",
        "    # Print the extracted documents\n",
        "    print(\"documents_list from retrieve_docs_milvus >>>>\", documents_list)\n",
        "\n",
        "    # Extract the retrieved chunks\n",
        "    chunks = documents_list\n",
        "    # should sort and push context - but later\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3C_WkW0aKL0e"
      },
      "outputs": [],
      "source": [
        "# Function to retrieve relevant chunks\n",
        "def retrieve_docs(query, top_k=5):\n",
        "    # Generate embedding for the query\n",
        "    query_embedding = embedder.encode(query).tolist()\n",
        "    # Perform vector search to find relevant chunks\n",
        "    results = chroma_db_collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
        "    # Extract the retrieved chunks\n",
        "    chunks = results[\"documents\"]\n",
        "    # should sort and push context - but later\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Axm8KpkheisU"
      },
      "outputs": [],
      "source": [
        "def retrieve_docs_query(query, top_k=5):\n",
        "    query_embedding = embedder.encode(query)\n",
        "\n",
        "    if store_client == 'Milvus':\n",
        "        results = datastor.search(query_embedding, top_k)\n",
        "        results = datastor.extract_documents(results)\n",
        "    elif store_client == \"Chromadb\":\n",
        "        results = chroma_db_collection.query(query_embeddings=[query_embedding.tolist()], n_results=top_k)\n",
        "        results = results['documents']\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7ZKEsHpjFwk"
      },
      "source": [
        "## **Query Classification**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yf3qk32bjEQF",
        "outputId": "fa023688-2cf6-4f3d-ecc6-c8c869d909bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itoeG1x2UOFp"
      },
      "outputs": [],
      "source": [
        "# Get the databricks dolly dataset (as mentioned in  \"Searching for Best Practices in Retrieval-Augmented Generation\" paper) for training the query classifer.\n",
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"databricks/databricks-dolly-15k\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P2gWc3znd4F"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "\n",
        "# Step 1: Load Pre-trained BERT and Tokenizer\n",
        "model_name = \"bert-base-multilingual-cased\"\n",
        "#model_name = \"distilbert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "# Step 2: Prepare the Dataset\n",
        "# Replace with your labeled data\n",
        "# Example data: {\"query\": [\"What is COVID19?\", \"What do the S1 and S2 subunits contain?\"], \"label\": [0, 1]}\n",
        "\n",
        "data = {\n",
        "    \"query\": [\n",
        "        \"What is SQLCODE=-1585\",\n",
        "        \"The configuration task database-transfer failed with DB2 SQL Error: SQLCODE=-1585, SQLSTATE=54048 While attempting to run the database-transfer task the following error is logged to the ConfigTrace.log: action-process-constraints: Fri Oct 10 13:20:34 CDT 2014 Target started: action-process-constraints [java] Executing java with empty input string [java] [10/10/14 13:20:35.877 CDT] Attempting to create a new Instance of com.ibm.db2.jcc.DB2Driver [java] [10/10/14 13:20:36.016 CDT] Instance of com.ibm.db2.jcc.DB2Driver created successfully [java] [10/10/14 13:20:36.016 CDT] Attempting to make connection using: jdbc:db2://:60500/:returnAlias=0; :: d2svc :: PASSWORD_REMOVED [java] [10/10/14 13:20:36.954 CDT] Connection successfully made [java] [10/10/14 13:20:37.073 CDT] ERROR: Error occurred gathering data from the source database [java] com.ibm.db2.jcc.am.SqlException: DB2 SQL Error: SQLCODE=-1585, SQLSTATE=54048, SQLERRMC=null, DRIVER=4.18.60 [java] at com.ibm.db2.jcc.am.kd.a(kd.java:752)\",\n",
        "        \"What is Websphere Application Server\",\n",
        "        \"How do I change from shared to unshared connection? in WAS, how do I change from shared to unshared connection. I am seeing connections max out and take a long time to release.\",\n",
        "        \"What is JMS\",\n",
        "        \"Why is my MQ Java / JMS application getting 2035 NOT_AUTHORIZED error after upgrade of MQ? Why is my MQ Java / JMS application getting 2035 NOT_AUTHORIZED error after upgrade of MQ?\",\n",
        "        \"What is TLS\",\n",
        "        \"TLS protocol with ITCAM for Datapower We have a DataPower appliance with TLS security protocol enabled. Can we configure ITCAM for DataPower appliance v7.1 to specifically use the TLS protocol v1.2 (not v1.0)?\"\n",
        "\n",
        "    ],\n",
        "    \"label\": [0, 1, 0, 1, 0, 1, 0, 1]  # 0: retrieval not needed, 1: retrieval needed\n",
        "}\n",
        "\n",
        "# Convert to Hugging Face Dataset\n",
        "dataset = Dataset.from_dict(data)\n",
        "\n",
        "#dataset = ds\n",
        "# Tokenize the Dataset\n",
        "def preprocess(data):\n",
        "    return tokenizer(data[\"query\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "encoded_dataset = dataset.map(preprocess, batched=True)\n",
        "encoded_dataset = encoded_dataset.train_test_split(test_size=0.2)\n",
        "\n",
        "# Step 3: Define the Training Loop\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./query_classifier_results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Custom Metric for Accuracy\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
        "    accuracy = (predictions == torch.tensor(labels)).float().mean().item()\n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Step 4: Train the Model\n",
        "trainer.train()\n",
        "\n",
        "# Step 5: Save the Model\n",
        "model.save_pretrained(\"./query_classifier\")\n",
        "tokenizer.save_pretrained(\"./query_classifier\")\n",
        "\n",
        "# Step 6: Inference Function\n",
        "def classify_query(query, model_path=\"./query_classifier\"):\n",
        "    # Load saved model and tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "    # Tokenize the input query\n",
        "    inputs = tokenizer(query, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        predicted_class = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    return predicted_class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9dPuLN7PoHW"
      },
      "source": [
        "# **LLM Inference with groq**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t3hArAT2KLpG",
        "outputId": "16ad7791-dd6e-4398-b8cc-5d39eeedf0ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.13.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.1)\n",
            "Downloading groq-0.13.1-py3-none-any.whl (109 kB)\n",
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/109.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.13.1\n"
          ]
        }
      ],
      "source": [
        "! pip install groq\n",
        "! pip install -q langchain langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vsitelPOYdh1"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Initializing the context variable which later gets populated with retrieved chunks\n",
        "context = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5Oxj_cJ8sFc4"
      },
      "outputs": [],
      "source": [
        "def query_response_from_llm(query: str):\n",
        "\n",
        "    # retrieve chunks from milvus db\n",
        "    chunks = retrieve_docs(query)\n",
        "    #print(\"chunks >>>query_response_from_llm>> \", chunks)\n",
        "\n",
        "    # retrieve chunks from chroma db\n",
        "    #chunks = retrieve_docs(query)\n",
        "\n",
        "    # Flatten the list if necessary\n",
        "    if any(isinstance(chunk, list) for chunk in chunks):\n",
        "      chunks = [item for sublist in chunks for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
        "\n",
        "    chat = ChatGroq(temperature=0.3, groq_api_key=\"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\", model_name=\"llama3-8b-8192\")\n",
        "\n",
        "    prompt=ChatPromptTemplate.from_template(\n",
        "      \"\"\"\n",
        "      Please provide a response to the query below, strictly adhering to the\n",
        "      information presented in the following documents.\n",
        "      Do not generate any text beyond what is explicitly stated in the documents.\n",
        "\n",
        "      Context: {context}\n",
        "\n",
        "      Question: {query}\n",
        "\n",
        "      Answer:\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    chain = prompt | chat\n",
        "\n",
        "    context = \"\".join(chunks)\n",
        "\n",
        "    print(\"context>>>from 1st RAG>>>>>> \",context)\n",
        "\n",
        "    groq_response = chain.invoke({\"context\": context, \"query\": query})\n",
        "\n",
        "    print(\"groq_response>>>from 1st RAG>>>>>> \",groq_response)\n",
        "\n",
        "    answer = groq_response\n",
        "    return answer, context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEXbOsWyoy89"
      },
      "outputs": [],
      "source": [
        "def query_response_from_llm_no_rag(query: str):\n",
        "\n",
        "    chat = ChatGroq(temperature=0.3, groq_api_key=\"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\", model_name=\"llama3-8b-8192\")\n",
        "\n",
        "    prompt=ChatPromptTemplate.from_template(\n",
        "      \"\"\"\n",
        "      Please provide a response to the query below\n",
        "\n",
        "      Question: {query}\n",
        "\n",
        "      Answer:\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    chain = prompt | chat\n",
        "\n",
        "    groq_response_no_rag = chain.invoke({\"query\": query})\n",
        "\n",
        "    print(\"groq_response_no_rag>>>no RAG>>>>>> \",groq_response_no_rag)\n",
        "\n",
        "    answer = groq_response_no_rag\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laVq8-s5Fu68"
      },
      "source": [
        "## **USER QUERY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4ju5adQj-i6H",
        "outputId": "3f4b5bf9-07db-44f8-ba9d-47e9ffa3efb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perform retrieval using RAG.\n",
            "context>>>from 1st RAG>>>>>>  [0b] Your WebSphere MQ queue manager fails to come up on the secondary node, and errors are generated.[0d] RESOLVING THE PROBLEM\n",
            "Rename the file amqalchk.fil, which is found under mq\\qmgrs\\qmgrname\\ on the shared drive (to something like amqalchk.fil_OLD); then restart the queue manager.[0a] HL083112 mqlpgrlg ZX000001 ExecCtrlrMain lpiRC_LOG_NOT_AVAILABLE mscs TECHNOTE (TROUBLESHOOTING)\n",
            "\n",
            "PROBLEM(ABSTRACT)\n",
            " You attempt to failover from the primary to secondary node under MSCS.[1j] PROBLEM SUMMARY\n",
            " *  ****************************************************************\n",
            "   * USERS AFFECTED:                                              *\n",
            "   * Users with an HDR pair that is an ER participant             *\n",
            "   ****************************************************************\n",
            "   * PROBLEM DESCRIPTION:                                         *\n",
            "   * After failover, the primary shows online mode but the        *\n",
            "   * clients are not able to connect to the server.[1h] If the mode is not set until after ER has finished\n",
            "   syncing and connections are accepted or a new return value is\n",
            "   used to indicate that the instance is on-line and accepting\n",
            "   connections this would resolve the problem.\n",
            "groq_response>>>from 1st RAG>>>>>>  content='According to the provided documents, the reason for the queue manager not starting after failover is due to a file named \"amqalchk.fil\" found under \"mq\\\\qmgrs\\\\qmgrname\\\\\" on the shared drive. Renaming this file to something like \"amqalchk.fil_OLD\" and then restarting the queue manager should resolve the issue.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 345, 'total_tokens': 420, 'completion_time': 0.0625, 'prompt_time': 0.041333136, 'queue_time': 0.019816205000000003, 'total_time': 0.103833136}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None} id='run-eb4c6f43-ac5e-4b06-accb-b03ae8944e3d-0' usage_metadata={'input_tokens': 345, 'output_tokens': 75, 'total_tokens': 420}\n",
            "context  >>from llm>>>  [0b] Your WebSphere MQ queue manager fails to come up on the secondary node, and errors are generated.[0d] RESOLVING THE PROBLEM\n",
            "Rename the file amqalchk.fil, which is found under mq\\qmgrs\\qmgrname\\ on the shared drive (to something like amqalchk.fil_OLD); then restart the queue manager.[0a] HL083112 mqlpgrlg ZX000001 ExecCtrlrMain lpiRC_LOG_NOT_AVAILABLE mscs TECHNOTE (TROUBLESHOOTING)\n",
            "\n",
            "PROBLEM(ABSTRACT)\n",
            " You attempt to failover from the primary to secondary node under MSCS.[1j] PROBLEM SUMMARY\n",
            " *  ****************************************************************\n",
            "   * USERS AFFECTED:                                              *\n",
            "   * Users with an HDR pair that is an ER participant             *\n",
            "   ****************************************************************\n",
            "   * PROBLEM DESCRIPTION:                                         *\n",
            "   * After failover, the primary shows online mode but the        *\n",
            "   * clients are not able to connect to the server.[1h] If the mode is not set until after ER has finished\n",
            "   syncing and connections are accepted or a new return value is\n",
            "   used to indicate that the instance is on-line and accepting\n",
            "   connections this would resolve the problem.\n",
            "answer  >>from llm>>>  content='According to the provided documents, the reason for the queue manager not starting after failover is due to a file named \"amqalchk.fil\" found under \"mq\\\\qmgrs\\\\qmgrname\\\\\" on the shared drive. Renaming this file to something like \"amqalchk.fil_OLD\" and then restarting the queue manager should resolve the issue.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 345, 'total_tokens': 420, 'completion_time': 0.0625, 'prompt_time': 0.041333136, 'queue_time': 0.019816205000000003, 'total_time': 0.103833136}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None} id='run-eb4c6f43-ac5e-4b06-accb-b03ae8944e3d-0' usage_metadata={'input_tokens': 345, 'output_tokens': 75, 'total_tokens': 420}\n"
          ]
        }
      ],
      "source": [
        "#query = \"What are the most frequent clinical manifestations of human adenovirus type 55 (HAdV-55) induced ARDS?\"\n",
        "#query =\"The configuration task database-transfer failed with DB2 SQL Error: SQLCODE=-1585, SQLSTATE=54048 While attempting to run the database-transfer task the following error is logged to the ConfigTrace.log: action-process-constraints: Fri Oct 10 13:20:34 CDT 2014 Target started: action-process-constraints [java] Executing java with empty input string [java] [10/10/14 13:20:35.877 CDT] Attempting to create a new Instance of com.ibm.db2.jcc.DB2Driver [java] [10/10/14 13:20:36.016 CDT] Instance of com.ibm.db2.jcc.DB2Driver created successfully [java] [10/10/14 13:20:36.016 CDT] Attempting to make connection using: jdbc:db2://:60500/:returnAlias=0; :: d2svc :: PASSWORD_REMOVED [java] [10/10/14 13:20:36.954 CDT] Connection successfully made [java] [10/10/14 13:20:37.073 CDT] ERROR: Error occurred gathering data from the source database [java] com.ibm.db2.jcc.am.SqlException: DB2 SQL Error: SQLCODE=-1585, SQLSTATE=54048, SQLERRMC=null, DRIVER=4.18.60 [java] at com.ibm.db2.jcc.am.kd.a(kd.java:752)\"\n",
        "query = \"Why does the other instance of my multi-instance qmgr seem to hang after a failover? Queue manager will not start after failover.\"\n",
        "\n",
        "#query = \"What is SQLCODE=-1585\"\n",
        "\n",
        "# Query Classification\n",
        "#classification = classify_query(query)\n",
        "\n",
        "classification = 1\n",
        "\n",
        "#print('classification >>>> ',classification)\n",
        "\n",
        "if classification == 1:\n",
        "    print(\"Perform retrieval using RAG.\")\n",
        "    # Call RAG pipeline for retrieval and response generation\n",
        "    answer,context = query_response_from_llm(query)\n",
        "else:\n",
        "    print(\"No RAG - only use LLM for response generation.\")\n",
        "    # Call LLM directly\n",
        "    answer = query_response_from_llm_no_rag(query)\n",
        "\n",
        "print(\"context  >>from llm>>> \", context)\n",
        "print(\"answer  >>from llm>>> \", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdKXQmBJGGcU"
      },
      "source": [
        "## **PROMPT for generating metrics as JSON response**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "3Zk3sAA4Kfej"
      },
      "outputs": [],
      "source": [
        "def generate_prompt():\n",
        "    \"\"\"\n",
        "    Generate a prompt template for assessing the support and relevance of an LLM-generated response.\n",
        "    \"\"\"\n",
        "    return \"\"\"\n",
        "    I asked someone to answer a question based on one or more documents.\n",
        "    Your task is to review their response and assess whether or not each sentence\n",
        "    in that response is supported by text in the documents. And if so, which\n",
        "    sentences in the documents provide that support. You will also tell me which\n",
        "    of the documents contain useful information for answering the question, and\n",
        "    which of the documents the answer was sourced from.\n",
        "    Here are the documents, each of which is split into sentences.Alongside each\n",
        "    sentence is associated key, such as [0a]. or [0b]. that you can use to refer\n",
        "    to it:\n",
        "\n",
        "    \n",
        "    {documents}\n",
        "    \n",
        "    The question was:\n",
        "    \n",
        "    {question}\n",
        "    \n",
        "\n",
        "    Here is their response, split into sentences. Alongside each sentence is\n",
        "    associated key, such as a. or b. that you can use to refer to it. Note\n",
        "    that these keys are unique to the response, and are not related to the keys\n",
        "    in the documents:\n",
        "    \n",
        "    {answer}\n",
        "    \n",
        "    You must respond with a JSON object matching this schema:\n",
        "    \n",
        "    {{\n",
        "    \"relevance_explanation\": string,\n",
        "    \"all_relevant_sentence_keys\": [string],\n",
        "    \"overall_supported_explanation\": string,\n",
        "    \"overall_supported\": boolean,\n",
        "    \"sentence_support_information\": [\n",
        "    {{\n",
        "    \"response_sentence_key\": string,\n",
        "    \"explanation\": string,\n",
        "    \"supporting_sentence_keys\": [string],\n",
        "    \"fully_supported\": boolean\n",
        "    }},\n",
        "    ],\n",
        "    \"all_utilized_sentence_keys\": [string]\n",
        "    }}\n",
        "    \n",
        "    The relevance_explanation field is a string explaining which documents\n",
        "    contain useful information for answering the question. Provide a step-by-step\n",
        "    breakdown of information provided in the documents and how it is useful for\n",
        "    answering the question.\n",
        "    The all_relevant_sentence_keys field is a list of all document sentences keys\n",
        "    (e.g. 0a) that are relevant to the question. Include every sentence that is\n",
        "    useful and relevant to the question, even if it was not used in the response,\n",
        "    or if only parts of the sentence are useful. Ignore the provided response when\n",
        "    making this judgement and base your judgement solely on the provided documents\n",
        "    and question. Omit sentences that, if removed from the document, would not\n",
        "    impact someones ability to answer the question.\n",
        "    The overall_supported_explanation field is a string explaining why the response\n",
        "    *as a whole* is or is not supported by the documents. In this field, provide a\n",
        "    step-by-step breakdown of the claims made in the response and the support (or\n",
        "    lack thereof) for those claims in the documents. Begin by assessing each claim\n",
        "    separately, one by one; dont make any remarks about the response as a whole\n",
        "    until you have assessed all the claims in isolation.\n",
        "    The overall_supported field is a boolean indicating whether the response as a\n",
        "    whole is supported by the documents. This value should reflect the conclusion\n",
        "    you drew at the end of your step-by-step breakdown in overall_supported_explanation.\n",
        "    In the sentence_support_information field, provide information about the support\n",
        "    *for each sentence* in the response.\n",
        "    The sentence_support_information field is a list of objects, one for each sentence\n",
        "    in the response. Each object MUST have the following fields:\n",
        "    - response_sentence_key: a string identifying the sentence in the response.\n",
        "    This key is the same as the one used in the response above.\n",
        "\n",
        "    - explanation: a string explaining why the sentence is or is not supported by the\n",
        "    documents.\n",
        "    - supporting_sentence_keys: keys (e.g. [0a]) of sentences from the documents that\n",
        "    support the response sentence. If the sentence is not supported, this list MUST\n",
        "    be empty. If the sentence is supported, this list MUST contain one or more keys.\n",
        "    In special cases where the sentence is supported, but not by any specific sentence,\n",
        "    you can use the string \"supported_without_sentence\" to indicate that the sentence\n",
        "    is generally supported by the documents. Consider cases where the sentence is\n",
        "    expressing inability to answer the question due to lack of relevant information in\n",
        "    the provided context as \"supported_without_sentence\". In cases where the sentence\n",
        "    is making a general statement (e.g. outlining the steps to produce an answer, or\n",
        "    summarizing previously stated sentences, or a transition sentence), use the\n",
        "    string \"general\". In cases where the sentence is correctly stating a well-known fact,\n",
        "    like a mathematical formula, use the string \"well_known_fact\". In cases where the\n",
        "    sentence is performing numerical reasoning (e.g. addition, multiplication), use\n",
        "    the string \"numerical_reasoning\".\n",
        "    - fully_supported: a boolean indicating whether the sentence is fully supported by\n",
        "    the documents.\n",
        "    - This value should reflect the conclusion you drew at the end of your step-by-step\n",
        "    breakdown in explanation.\n",
        "    - If supporting_sentence_keys is an empty list, then fully_supported must be false.\n",
        "    - Otherwise, use fully_supported to clarify whether everything in the response\n",
        "    sentence is fully supported by the document text indicated in supporting_sentence_keys\n",
        "    (fully_supported = true), or whether the sentence is only partially or incompletely\n",
        "    supported by that document text (fully_supported = false).\n",
        "    The all_utilized_sentence_keys field is a list of all sentences keys (e.g. 0a) that\n",
        "    were used to construct the answer. Include every sentence that either directly supported\n",
        "    the answer, or was implicitly used to construct the answer, even if it was not used\n",
        "    in its entirety. Omit sentences that were not used, and could have been removed from\n",
        "    the documents without affecting the answer.\n",
        "    You must respond with a valid JSON string. Use escapes for quotes, e.g. \\\\\"\\\\\", and\n",
        "    newlines, e.g. \\\\n. Do not write anything before or after the JSON string. Do not\n",
        "    wrap the JSON string in backticks like  or json.\n",
        "    As a reminder: your task is to review the response and assess which documents contain\n",
        "    useful information pertaining to the question, and how each sentence in the response\n",
        "    is supported by the text in the documents.\n",
        "    \"\"\".strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5S673smUR_4"
      },
      "source": [
        "## **Response generation using groq using llama3-70b-8192**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ppx9enUjP2N_",
        "outputId": "aa68f9a5-f503-488a-c069-050cc9d224f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context for groq >>>>  [0b] Your WebSphere MQ queue manager fails to come up on the secondary node, and errors are generated.[0d] RESOLVING THE PROBLEM\n",
            "Rename the file amqalchk.fil, which is found under mq\\qmgrs\\qmgrname\\ on the shared drive (to something like amqalchk.fil_OLD); then restart the queue manager.[0a] HL083112 mqlpgrlg ZX000001 ExecCtrlrMain lpiRC_LOG_NOT_AVAILABLE mscs TECHNOTE (TROUBLESHOOTING)\n",
            "\n",
            "PROBLEM(ABSTRACT)\n",
            " You attempt to failover from the primary to secondary node under MSCS.[1j] PROBLEM SUMMARY\n",
            " *  ****************************************************************\n",
            "   * USERS AFFECTED:                                              *\n",
            "   * Users with an HDR pair that is an ER participant             *\n",
            "   ****************************************************************\n",
            "   * PROBLEM DESCRIPTION:                                         *\n",
            "   * After failover, the primary shows online mode but the        *\n",
            "   * clients are not able to connect to the server.[1h] If the mode is not set until after ER has finished\n",
            "   syncing and connections are accepted or a new return value is\n",
            "   used to indicate that the instance is on-line and accepting\n",
            "   connections this would resolve the problem.\n",
            "query for groq >>>>  Why does the other instance of my multi-instance qmgr seem to hang after a failover? Queue manager will not start after failover\n",
            "answer for groq >>>>  content='According to the provided documents, the answer to the question is:\\n\\nRename the file amqalchk.fil, which is found under mq\\\\qmgrs\\\\qmgrname\\\\ on the shared drive (to something like amqalchk.fil_OLD); then restart the queue manager.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 345, 'total_tokens': 403, 'completion_time': 0.048333333, 'prompt_time': 0.042544745, 'queue_time': 0.019750975999999996, 'total_time': 0.090878078}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None} id='run-4e8704c1-0e6c-4f1e-83ec-ed0cdec3542f-0' usage_metadata={'input_tokens': 345, 'output_tokens': 58, 'total_tokens': 403}\n",
            "groq_response>>>>with context, query and answer>>>>>  content='{\\n\"relevance_explanation\": \"Document [0b] contains useful information for answering the question, specifically the solution to the problem of the queue manager failing to come up after a failover.\",\\n\"all_relevant_sentence_keys\": [\"[0b]\", \"[0d]\"],\\n\"overall_supported_explanation\": \"The response provides a solution to the problem of the queue manager failing to come up after a failover, which is supported by the document [0b]. The solution is to rename the file amqalchk.fil and then restart the queue manager. This solution is directly mentioned in the document.\",\\n\"overall_supported\": true,\\n\"sentence_support_information\": [\\n{\\n\"response_sentence_key\": \"a.\",\\n\"explanation\": \"The solution to the problem of the queue manager failing to come up after a failover is supported by the document [0b].\",\\n\"supporting_sentence_keys\": [\"[0b]\", \"[0d]\"],\\n\"fully_supported\": true\\n}\\n],\\n\"all_utilized_sentence_keys\": [\"[0b]\", \"[0d]\"]\\n}' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 219, 'prompt_tokens': 1868, 'total_tokens': 2087, 'completion_time': 0.625714286, 'prompt_time': 0.115138913, 'queue_time': 0.01948200500000001, 'total_time': 0.740853199}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-d1632834-af18-4d34-83ca-2f80a5ddc953-0' usage_metadata={'input_tokens': 1868, 'output_tokens': 219, 'total_tokens': 2087}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "chat = ChatGroq(temperature=0.3, groq_api_key=\"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\", model_name=\"llama3-70b-8192\")\n",
        "\n",
        "prompt_template_with_docs = PromptTemplate(\n",
        "    input_variables=[\"documents\", \"question\", \"answer\"],\n",
        "    template=generate_prompt(),\n",
        ")\n",
        "\n",
        "print('context for groq >>>> ', context)\n",
        "print('query for groq >>>> ', query)\n",
        "print('answer for groq >>>> ', answer)\n",
        "\n",
        "chain = prompt_template_with_docs | chat\n",
        "\n",
        "# if classification == 1:\n",
        "#  groq_response_with_context_qanda = chain.invoke({\"documents\": context, \"question\": query, \"answer\":groq_response})\n",
        "# else\n",
        "#  groq_response_with_out-rag = chain.invoke({\"documents\": \"\", \"question\": query, \"answer\":groq_response})\n",
        "\n",
        "groq_response_with_context_qanda = chain.invoke({\"documents\": context, \"question\": query, \"answer\":answer})\n",
        "\n",
        "print(\"groq_response>>>>with context, query and answer>>>>> \",groq_response_with_context_qanda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MeFdP7BpnC5"
      },
      "source": [
        "## **JSON Data parsing to retrieve metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "J8Bw2DP0eisb"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sjbjmmD6zQO4",
        "outputId": "27f5cd89-72ad-4ea3-f615-2347e915d7cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Content:\n",
            "{\\n\"relevance_explanation\": \"Document [0b] contains useful information for answering the question, specifically the solution to the problem of the queue manager failing to come up after a failover.\",\\n\"all_relevant_sentence_keys\": [\"[0b]\", \"[0d]\"],\\n\"overall_supported_explanation\": \"The response provides a solution to the problem of the queue manager failing to come up after a failover, which is supported by the document [0b]. The solution is to rename the file amqalchk.fil and then restart the queue manager. This solution is directly mentioned in the document.\",\\n\"overall_supported\": true,\\n\"sentence_support_information\": [\\n{\\n\"response_sentence_key\": \"a.\",\\n\"explanation\": \"The solution to the problem of the queue manager failing to come up after a failover is supported by the document [0b].\",\\n\"supporting_sentence_keys\": [\"[0b]\", \"[0d]\"],\\n\"fully_supported\": true\\n}\\n],\\n\"all_utilized_sentence_keys\": [\"[0b]\", \"[0d]\"]\\n}\n",
            "{\"relevance_explanation\": \"Document [0b] contains useful information for answering the question, specifically the solution to the problem of the queue manager failing to come up after a failover.\",\"all_relevant_sentence_keys\": [\"[0b]\", \"[0d]\"],\"overall_supported_explanation\": \"The response provides a solution to the problem of the queue manager failing to come up after a failover, which is supported by the document [0b]. The solution is to rename the file amqalchk.fil and then restart the queue manager. This solution is directly mentioned in the document.\",\"overall_supported\": true,\"sentence_support_information\": [{\"response_sentence_key\": \"a.\",\"explanation\": \"The solution to the problem of the queue manager failing to come up after a failover is supported by the document [0b].\",\"supporting_sentence_keys\": [\"[0b]\", \"[0d]\"],\"fully_supported\": true}],\"all_utilized_sentence_keys\": [\"[0b]\", \"[0d]\"]}\n",
            "Extracted JSON:\n",
            "{\n",
            "    \"relevance_explanation\": \"Document [0b] contains useful information for answering the question, specifically the solution to the problem of the queue manager failing to come up after a failover.\",\n",
            "    \"all_relevant_sentence_keys\": [\n",
            "        \"[0b]\",\n",
            "        \"[0d]\"\n",
            "    ],\n",
            "    \"overall_supported_explanation\": \"The response provides a solution to the problem of the queue manager failing to come up after a failover, which is supported by the document [0b]. The solution is to rename the file amqalchk.fil and then restart the queue manager. This solution is directly mentioned in the document.\",\n",
            "    \"overall_supported\": true,\n",
            "    \"sentence_support_information\": [\n",
            "        {\n",
            "            \"response_sentence_key\": \"a.\",\n",
            "            \"explanation\": \"The solution to the problem of the queue manager failing to come up after a failover is supported by the document [0b].\",\n",
            "            \"supporting_sentence_keys\": [\n",
            "                \"[0b]\",\n",
            "                \"[0d]\"\n",
            "            ],\n",
            "            \"fully_supported\": true\n",
            "        }\n",
            "    ],\n",
            "    \"all_utilized_sentence_keys\": [\n",
            "        \"[0b]\",\n",
            "        \"[0d]\"\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Extract the content field using regular expressions\n",
        "content_match = re.search(r\"content='(.*?)' additional_kwargs=\", str(groq_response_with_context_qanda), re.DOTALL)\n",
        "if content_match:\n",
        "    content = content_match.group(1)\n",
        "    print(\"Extracted Content:\")\n",
        "    print(content)\n",
        "\n",
        "    json_match = re.search(r\"\\{.*\\}\", content, re.DOTALL)\n",
        "    if json_match:\n",
        "      json_str = json_match.group(0)\n",
        "\n",
        "      json_str = json_str.replace(\"'\", '\"').replace(\"\\\\n\",\"\").replace(\"\\\\\",\"\")\n",
        "      print(json_str)\n",
        "      try:\n",
        "        # Parse the JSON\n",
        "        parsed_json = json.loads(json_str)\n",
        "        print(\"Extracted JSON:\")\n",
        "        print(json.dumps(parsed_json, indent=4))\n",
        "\n",
        "      except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON: {e}\")\n",
        "    else:\n",
        "      print(\"No JSON found in the provided string.\")\n",
        "\n",
        "else:\n",
        "    print(\"Content field not found in the provided string.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "N4sABSCq4alG"
      },
      "outputs": [],
      "source": [
        "data = parsed_json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtekJh8Lp2R1"
      },
      "source": [
        "## **Computation Metrics from JSON response in comparison with ground truth**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_cluMOyyqL7u"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "VxD6JHqFp8sS"
      },
      "outputs": [],
      "source": [
        "# Helper function for length computation (mocked as sentence count here)\n",
        "def compute_length(keys):\n",
        "    return len(keys)\n",
        "\n",
        "# Metrics Computation\n",
        "def compute_metrics(data):\n",
        "    all_relevant = data[\"all_relevant_sentence_keys\"]\n",
        "    all_utilized = data[\"all_utilized_sentence_keys\"]\n",
        "    sentences_info = data[\"sentence_support_information\"]\n",
        "\n",
        "    # Context Relevance\n",
        "    total_relevant_length = compute_length(all_relevant)\n",
        "    total_context_length = total_relevant_length  # Assuming all relevant are part of the context\n",
        "    context_relevance = total_relevant_length / total_context_length if total_context_length > 0 else 0\n",
        "\n",
        "    # Context Utilization\n",
        "    total_utilized_length = compute_length(all_utilized)\n",
        "    context_utilization = total_utilized_length / total_context_length if total_context_length > 0 else 0\n",
        "\n",
        "    # Completeness\n",
        "    total_relevant_utilized = sum(\n",
        "        1 for s in sentences_info if set(s[\"supporting_sentence_keys\"]).intersection(all_utilized)\n",
        "    )\n",
        "    completeness = total_relevant_utilized / total_relevant_length if total_relevant_length > 0 else 0\n",
        "\n",
        "    # Adherence\n",
        "    adherence = all(s[\"fully_supported\"] for s in sentences_info)\n",
        "\n",
        "    return {\n",
        "        \"Context Relevance\": context_relevance,\n",
        "        \"Context Utilization\": context_utilization,\n",
        "        \"Completeness\": completeness,\n",
        "        \"Adherence\": adherence\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "UIHVj_O7qBcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "accae326-d438-4cea-af0f-759275b474da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"Context Relevance\": 1.0,\n",
            "    \"Context Utilization\": 1.0,\n",
            "    \"Completeness\": 0.5,\n",
            "    \"Adherence\": true\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Compute and print metrics\n",
        "predicted_metrics = compute_metrics(data)\n",
        "print(json.dumps(predicted_metrics, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa16P5mdtnIK"
      },
      "source": [
        "## **Fetching the groud truth values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "WdYZVVQztrrS"
      },
      "outputs": [],
      "source": [
        "sub_dataset = load_dataset(\"rungalileo/ragbench\", \"techqa\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "-B67gUJ0t4D2"
      },
      "outputs": [],
      "source": [
        "def fetch_ground_truth(dataset, question):\n",
        "    for sample in dataset[\"train\"]:  # Change \"train\" to the correct split if needed\n",
        "        if sample[\"question\"] == question:\n",
        "            return {\n",
        "                \"Context Relevance\": sample[\"relevance_score\"],  # Adjust column name if needed\n",
        "                \"Context Utilization\": sample[\"utilization_score\"],  # Adjust column name if needed\n",
        "                \"Adherence\": sample[\"adherence_score\"]  # Adjust column name if needed\n",
        "            }\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "collapsed": true,
        "id": "qZxUZe9dt95y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ada6e68-c33e-4602-9433-8b14ad5a34da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query >>>> Why does the other instance of my multi-instance qmgr seem to hang after a failover? Queue manager will not start after failover.\n",
            "Ground Truth Values:\n",
            "{\n",
            "    \"Context Relevance\": 0.01411764705882353,\n",
            "    \"Context Utilization\": 0.009411764705882352,\n",
            "    \"Adherence\": true\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(f\"query >>>> {query}\")\n",
        "ground_truth = fetch_ground_truth(sub_dataset, query)\n",
        "\n",
        "if ground_truth:\n",
        "    print(\"Ground Truth Values:\")\n",
        "    print(json.dumps(ground_truth, indent=4))\n",
        "else:\n",
        "    print(f\"Question not found in the dataset: {query}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APVsAL8vDYHD"
      },
      "outputs": [],
      "source": [
        "## DONOT RUN THIS\n",
        "ground_truth = \"\"\"{\n",
        "    \"Context Relevance\": 0.6470588235294118,\n",
        "    \"Context Utilization\": 0.35294117647058826,\n",
        "    \"Adherence\": false\n",
        "}\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysMSBECpYx5h"
      },
      "outputs": [],
      "source": [
        "## DONOT RUN THIS\n",
        "predicted_metrics = \"\"\"{\n",
        "    \"Context Relevance\": 1.0,\n",
        "    \"Context Utilization\": 0.6,\n",
        "    \"Completeness\": 1.0,\n",
        "    \"Adherence\": true\n",
        "}\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2U_oj5-uJHL"
      },
      "source": [
        "## **Evaluation Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "GwUDwHuJuk5i"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
        "import numpy as np\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emcaX7ARfgyn"
      },
      "source": [
        "# **RMSE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "5tJun5FLa4Pt"
      },
      "outputs": [],
      "source": [
        "def compute_rmse(predicted, ground_truth):\n",
        "\n",
        "    # Extract true and predicted values\n",
        "    y_true_relevance = ground_truth[\"Context Relevance\"]\n",
        "    y_true_utilization = ground_truth[\"Context Utilization\"]\n",
        "\n",
        "    y_pred_relevance = predicted[\"Context Relevance\"]\n",
        "    y_pred_utilization = predicted[\"Context Utilization\"]\n",
        "\n",
        "    # Compute RMSE for Context Relevance and Context Utilization\n",
        "    rmse_relevance = np.sqrt((y_pred_relevance - y_true_relevance) ** 2)\n",
        "    rmse_utilization = np.sqrt((y_pred_utilization - y_true_utilization) ** 2)\n",
        "\n",
        "    return {\n",
        "        \"RMSE-Relevance\": rmse_relevance,\n",
        "        \"RMSE-Utililization\": rmse_utilization,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaLvigTyfoGF"
      },
      "source": [
        "# **AUCROC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "8Nk5GKXtdEy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3958143c-4455-4ba9-cf3a-2986180a2421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-ROC: 0.25\n"
          ]
        }
      ],
      "source": [
        "#The AUC-ROC is a metric for binary classification, but it requires:\n",
        "# 1) Both positive and negative classes in the ground truth.\n",
        "# 2) A set of predictions (not just a single value).\n",
        "# The AUR-ROC code that we have written earlier will always fail because at any given point of time only one class (either true or false) of ground truth and predicted value is\n",
        "# passed to the roc_auc_score library function. However, by definition, AUC-ROC requires a 'set of 2 class' values. Following is a toy example\n",
        "# TODO : For our project metric, we need to pass 2 sets of values to roc_auc_score function\n",
        "  # 1) multiple adherence values of ground truth queries\n",
        "  # 2) multiple adherence values from our predictions\n",
        "\n",
        "y_true = [\"true\",\"false\",\"false\",\"true\"]  # Ground truth with both classes\n",
        "y_pred = [\"true\",\"true\",\"true\",\"false\"]  # Model probabilities\n",
        "\n",
        "mapping = {\"true\": 1, \"false\": 0}\n",
        "y_true_numeric_alt = [mapping[val] for val in y_true]\n",
        "y_pred_numeric_alt = [mapping[val] for val in y_pred]\n",
        "\n",
        "auc_roc = roc_auc_score(y_true_numeric_alt, y_pred_numeric_alt)\n",
        "print(\"AUC-ROC:\", auc_roc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "collapsed": true,
        "id": "Cs6xv8tQuWnN"
      },
      "outputs": [],
      "source": [
        "evaluation_metrics = compute_rmse(predicted_metrics, ground_truth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYSdaPL_RPcC"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "piluWfdJxa0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c9d7b02-4bd4-4eaa-ffec-eb7fc58c4fcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth Values (JSON):\n",
            "{\n",
            "    \"Context Relevance\": 0.01411764705882353,\n",
            "    \"Context Utilization\": 0.009411764705882352,\n",
            "    \"Adherence\": true\n",
            "}\n",
            "\n",
            "Predicted Metrics:\n",
            "{\n",
            "    \"Context Relevance\": 1.0,\n",
            "    \"Context Utilization\": 1.0,\n",
            "    \"Completeness\": 0.5,\n",
            "    \"Adherence\": true\n",
            "}\n",
            "\n",
            "Evaluation Metrics (RMSE and AUC-ROC):\n",
            "{\n",
            "    \"RMSE-Relevance\": 0.9858823529411764,\n",
            "    \"RMSE-Utililization\": 0.9905882352941177\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Print Results\n",
        "print(\"Ground Truth Values (JSON):\")\n",
        "print(json.dumps(ground_truth, indent=4))\n",
        "print(\"\\nPredicted Metrics:\")\n",
        "print(json.dumps(predicted_metrics, indent=4))\n",
        "print(\"\\nEvaluation Metrics (RMSE and AUC-ROC):\")\n",
        "print(json.dumps(evaluation_metrics, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utk2VC69pbfT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "624381b929444c309b853f19975cf29a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89960f40d92d44ac87ca63087126314f",
              "IPY_MODEL_d72eef68e9974ae9865046ad2221ee7c",
              "IPY_MODEL_f5d957782ed54eeebe823b4b7ad7188a"
            ],
            "layout": "IPY_MODEL_41d676734897484d907f74160f3ad61d"
          }
        },
        "89960f40d92d44ac87ca63087126314f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_845cce0c0b404bb9b52906822318337e",
            "placeholder": "",
            "style": "IPY_MODEL_ecab979901b849c28e9f7a4667829434",
            "value": "Batches:100%"
          }
        },
        "d72eef68e9974ae9865046ad2221ee7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4c3dcd889cd49008d1fa9c961bffdd3",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a60c0cd3b0b4e378d02dc0b9f92b87c",
            "value": 3
          }
        },
        "f5d957782ed54eeebe823b4b7ad7188a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c45eff45c39470ea7b7ee804747e071",
            "placeholder": "",
            "style": "IPY_MODEL_41eaba06b7f940d0b812767d1242ec7d",
            "value": "3/3[00:03&lt;00:00,1.04it/s]"
          }
        },
        "41d676734897484d907f74160f3ad61d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "845cce0c0b404bb9b52906822318337e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecab979901b849c28e9f7a4667829434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4c3dcd889cd49008d1fa9c961bffdd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a60c0cd3b0b4e378d02dc0b9f92b87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c45eff45c39470ea7b7ee804747e071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41eaba06b7f940d0b812767d1242ec7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}